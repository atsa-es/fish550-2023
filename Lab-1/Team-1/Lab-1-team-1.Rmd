---
title: Lab 1 Forecasting with ARIMA models
author: Nick Chambers (SAFS), Liz Elmstrom (SAFS), Maria Kuruvilla (QERM)
date: March 22, 2023
output: 
  html_document:
    code-folding: true
    toc: true
    toc_float: true
---

```{r include=FALSE}
library(tidyverse)
library(tseries)
library(forecast)
library(zoo)

options(dplyr.summarise.inform = FALSE)
```

# Question your team will address

What will your team do with the data? You can do many things with the data. The only constraints are that you

<!-- * fit ARIMA models (note you'll want to log the abundance data). You can fit other models in addition ot ARIMA if you want. -->
<!-- * do diagnostics for ARIMA models -->
<!-- * make forecasts -->
<!-- * test how good your forecasts or compare forecasts (many options here) -->

<!-- We will look at the total forecasts for each river system.  -->

<!-- "Compare the accuracy of total abundance forecasts using ARIMA models for Bristol Bay sockeye rivers and compare to the AKFW and UW FRI forecasts." -->

<!-- Could also test accuracy based on training data length...  -->

<!-- "Compare the forecasts of total North Pacific pink and chum using 5, 10, 15, and 20 years of training data. Does forecast accuracy increase with more training data?" -->

We will fit multiple ARIMA models to the Bristol Bay sockeye data and compare forecasts among these models (using RMSE) and visually compare the forecasts against the FRI forecast. 

# Method you will use

## Initial plan

<!-- Describe what you plan to do to address your question. Note this example is with Ruggerone & Irvine data but your team will use the Bristol Bay data. -->

<!-- Example, "We will fit ARIMA models to 1960-1980 data on pink salmon in 2 regions in Alaska and 2 regions in E Asia. We will make 1981-1985  forecasts (5 year) and compare the accuracy of the forecasts to the actual values. We will measure accuracy with mean squared error. We will use the forecast package to fit the ARIMA models." -->

We divided the rivers among the team members to do the initial exploratory analysis and testing for stationarity. We then tried forecasting (5 years) for all rivers using the best model suggested by auto.arima. 

## What you actually did

<!-- Example, "We were able to do our plan fairly quickly, so after writing the basic code, we divided up all 12 regions in Ruggerone & Irvine and each team member did 4 regions. We compared the accuracy of forecasts for different time periods using 20-years for training and 5-year forecasts each time. We compared the RMSE, MAE, and MAPE accuracy measures." -->

We finally chose three rivers to work with - Kvichak, Wood and Nugashak. We split the data into training data (1963-2015) and testing data (2016-2020) and performed forecasts using the auto.arima function. In addition to forecasting with the model suggested by auto.arima, we explored additional top models suggested by the auto.arima function with trace == TRUE. We then compared the accuracy of these modeled forecasts using RMSE. We also plotted the FRI forecast to visually compare the model forecast to the FRI forecast. 

# START CODING

## Read in and explore data (LIZ)

Bristol Bay Data. Discuss what part of the data set you will work with.

Read in the data 
```{r}

bb_data <- readRDS(here::here("Lab-1", "Data_Images", "bristol_bay_data_plus_covariates.rds"))

cat("colnames: ", colnames(bb_data), "\n")
cat("system (river): ", unique(bb_data$system), "\n")
cat("age groups: ", unique(bb_data$age_group), "\n")

```

Explore the data 
```{r}
bb_data %>% 
  group_by(system, ret_yr) %>%
  summarize(total = sum(ret, na.rm=TRUE)) %>%
  ggplot(aes(x=ret_yr, y=log(total))) + 
    geom_line() + 
    ggtitle("log abundance by river") +
    facet_wrap(~system)

bb_data %>%
  group_by(system, ret_yr) %>%
  summarize(total = sum(forecast.adfw, na.rm=TRUE)) %>%
  ggplot(aes(x=ret_yr, y=log(total))) +
    geom_line() +
    ggtitle("ADFW log abundance by river") +
    facet_wrap(~system)

bb_data %>% 
  group_by(system, ret_yr) %>%
  summarize(total = sum(forecast.fri, na.rm=TRUE)) %>%
  ggplot(aes(x=ret_yr, y=log(total))) + 
    geom_line() + 
    ggtitle("FRI log abundance by river") +
    facet_wrap(~system)

```

Based on this, we chose to explore 1) total abundance, 2) compare ARIMA forecasts/accuracy, and 3) visually compare to these forecasts to forecasts from UW Fisheries Research Institute. 

# DIAGNOSTICS AND PRELIMARY EXPLORATION (LIZ)

## Plot the data

Plot the data and discuss any obvious problems with stationarity from your visual test.

```{r}

#Sum and log returns for each river and year
lndata <- bb_data %>%
  group_by(system, ret_yr) %>%
  summarize(lntotal = log(sum(ret, na.rm=TRUE)))

# Choosing sites CHANGE THIS BASED ON WHAT WE PICK
our_rivers <- filter(lndata, system %in% c('Kvichak', 'Wood', 'Nushagak'))

# Plotting three rivers
our_rivers %>% 
  ggplot(aes(x=ret_yr, y=lntotal)) + 
    geom_line() + 
    ggtitle("log abundance by river") +
    facet_wrap(~system)+theme_bw()

```

Based on these plots, we hypothesize that data will be non-stationary for the Kvichak and stationary for the Nushagak and the Wood around a trend. 

## Use ACF and PACF (MARIA)

Use the ACF and PACF plots to explore the time series. What did you learn? Also try decomposition.

```{r}


data_ts_Kv <- ts(our_rivers$lntotal[our_rivers$system == "Kvichak"],
                      start=our_rivers$ret_yr[our_rivers$system == "Kvichak"][1])

data_ts_Wood <- ts(our_rivers$lntotal[our_rivers$system == "Wood"],
                      start=our_rivers$ret_yr[our_rivers$system == "Wood"][1])

data_ts_Nu <- ts(our_rivers$lntotal[our_rivers$system == "Nushagak"],
                      start=our_rivers$ret_yr[our_rivers$system == "Nushagak"][1])



acf(data_ts_Wood)

pacf(data_ts_Wood)



acf(data_ts_Kv)

pacf(data_ts_Kv)


acf(data_ts_Nu)

pacf(data_ts_Nu)

```

The acf plots for Wood river is slowly decaying and the pacf plot shows significance at lag 1. There might be AR1 structure in the data.

The pacf plots for Kvichak river is slowly decaying and the pacf plot shows significance at lags 1,2,4, and 6. There might be MA structure in the data.

The acf plots for Nushagak river is slowly decaying and the pacf plot shows significance at lags 1 and 6. There might be AR structure in the data.

## Test for stationarity (NICK)

Run tests and discuss any stationarity issues and how these were addressed.

```{r}

```

## Difference tests (LIZ)

```{r}

kv <- filter(lndata, system %in% c("Kvichak"))
ndiffs(kv$lntotal, test='kpss')
ndiffs(kv$lntotal, test='adf')

nu <- filter(lndata, system %in% c("Nushagak"))
ndiffs(nu$lntotal, test='kpss')
ndiffs(nu$lntotal, test='adf')

wo <- filter(lndata, system %in% c("Wood"))
ndiffs(wo$lntotal, test='kpss')
ndiffs(wo$lntotal, test='adf')

```
The Kvichak does not need differencing. The Nushagak and the Wood should be differenced by 1. 

# MODELING AND RESULTS

## Dividing the data into test and train (MARIA)

```{r}


data_ts_Wood <- ts(our_rivers$lntotal[our_rivers$system == "Wood"],
                      start=our_rivers$ret_yr[our_rivers$system == "Wood"][1])

train_Wood <- window(data_ts_Wood, 1963, 2015)
test_Wood <- window(data_ts_Wood, 2016, 2020)

data_ts_Kv <- ts(our_rivers$lntotal[our_rivers$system == "Kvichak"],
                      start=our_rivers$ret_yr[our_rivers$system == "Kvichak"][1])


train_Kv <- window(data_ts_Kv, 1963, 2015)
test_Kv <- window(data_ts_Kv, 2016, 2020)


data_ts_Nu <- ts(our_rivers$lntotal[our_rivers$system == "Nushagak"],
                      start=our_rivers$ret_yr[our_rivers$system == "Nushagak"][1])

train_Nu <- window(data_ts_Nu, 1963, 2015)
test_Nu <- window(data_ts_Nu, 2016, 2020)

```

## Fit ARIMA models (MARIA)
Fit a model with `auto.arima()` in the forecast package.

```{r}

mod_Kv <- auto.arima(train_Kv)
mod_Kv

mod_Nu <- auto.arima(train_Nu)
mod_Nu

mod_Wood <- auto.arima(train_Wood)
mod_Wood
#mod_Wood <- auto.arima(data_ts_Wood)
```

## Plot forecasts from auto.arima (LIZ)

```{r}

fri_fore <- bb_data %>%
  group_by(system, ret_yr) %>%
  summarize(lntotal = log(sum(forecast.fri, na.rm=TRUE)))%>%
  filter(ret_yr %in% 2015:2020)

kv_fri_fore <- fri_fore %>% filter(system %in% 'Kvichak')
kv_fr <- forecast(mod_Kv, h=5)
autoplot(kv_fr) + geom_point(aes(x=x, y=y), data=fortify(test_Kv))+
  geom_point(aes(x=ret_yr, y=lntotal), data = kv_fri_fore, col = "red")

nu_fri_fore <- fri_fore %>% filter(system %in% 'Nushagak')
nu_fr <- forecast(mod_Nu, h=5)
autoplot(nu_fr) + geom_point(aes(x=x, y=y), data=fortify(test_Nu))+
  geom_point(aes(x=ret_yr, y=lntotal), data = nu_fri_fore, col='red')

wo_fri_fore <- fri_fore %>% filter(system %in% 'Wood')
wo_fr <- forecast(mod_Wood, h=5)
autoplot(wo_fr) + geom_point(aes(x=x, y=y), data=fortify(test_Wood))+
  geom_point(aes(x=ret_yr, y=lntotal), data = wo_fri_fore, col = "red")

```

## Chosing our own ARIMA structure 

Here we play around with different ARIMA structures. We tested the three top models for the Kvichak. For the Nushagak and the Wood, we tested the two top models, plus the best model with an added drift component. 

```{r}
# Chosing our own arima structure in a for loop. Probably a cleaner way to do this. 

kv_mod_list <- list(c(0,0,1), c(1,0,1), c(0,0,2))## List of mods to test. First option is what auto.arima chose
kv_fits <- kv_fore <- kv_plots <- list()# lists to store things in
kv_err_list <- list(0)

nu_mod_list <- list(c(0,1,1), c(0,1,1), c(1,1,1))
nu_fits <- nu_fore <- nu_plots <- list()
nu_err_list <- list(0)

wo_mod_list <- list(c(0,1,1), c(0,1,1), c(1,1,1))
wo_fits <- wo_fore <- wo_plots <- list()
wo_err_list <- list(0)

drift <- list(FALSE, TRUE, FALSE)## adding drift

for(i in 1:3){
  #Kvichak
  kv_fits[[i]] <- Arima(train_Kv, order = kv_mod_list[[i]])# loops through list, fits model, and stores in 'fits'
  kv_fore[[i]] <- forecast(kv_fits[[i]], h=5) # forecasts
  kv_plots[[i]] <- (autoplot(kv_fore[[i]]) + geom_point(aes(x=x, y=y), data=fortify(test_Kv))+ #forecast plots
          geom_point(aes(x=ret_yr, y=lntotal), data = kv_fri_fore, col = "red"))
  kv_err_list[[i]] <- accuracy(forecast(kv_fore[[i]], h = 5), test_Kv) # puts accuracy data into list

  #Nushagak
  nu_fits[[i]] <- Arima(train_Nu, order = nu_mod_list[[i]], include.drift = drift[[i]])
  nu_fore[[i]] <- forecast(nu_fits[[i]], h=5)
  nu_plots[[i]] <- (autoplot(nu_fore[[i]]) + geom_point(aes(x=x, y=y), data=fortify(test_Nu))+ #forecast plots
          geom_point(aes(x=ret_yr, y=lntotal), data = nu_fri_fore, col = "red"))
  nu_err_list[[i]] <- accuracy(forecast(nu_fore[[i]], h = 5), test_Nu) 

  #Wood
  wo_fits[[i]] <- Arima(train_Wood, order = wo_mod_list[[i]], include.drift = drift[[i]])
  wo_fore[[i]] <- forecast(wo_fits[[i]], h=5)
  wo_plots[[i]] <- (autoplot(wo_fore[[i]]) + geom_point(aes(x=x, y=y), data=fortify(test_Wood))+
          geom_point(aes(x=ret_yr, y=lntotal), data = wo_fri_fore, col = "red"))
  wo_err_list[[i]] <- accuracy(forecast(wo_fore[[i]], h = 5), test_Wood)  
}

library(ggpubr)
ggarrange(plotlist = kv_plots, ncol = 2, nrow =2)
ggarrange(plotlist = nu_plots, ncol = 2, nrow =2)
ggarrange(plotlist = wo_plots, ncol = 2, nrow =2)

```

Based on these plots we might decide to alter our model selection for the Nushagak and the Wood and change our chosen model to ARIMA(0,1,1) *with drift*. 

We also could change our model for the Kvichak, although the model chosen by auto.arima (ARIMA(0,0,1)) behaves essentially the same as the other top models.

Before this decision, below we check the accuracies and the residuals for each of the models (n = 9).

## Check accuracy (NICK)
```{r}
#lists from forecast::accuracy for each river
names(kv_err_list) <- c("Kvichak (0,0,1)", "Kvichak (1,0,1) drift", "Kvichak (0,0,2)")
kv_err_list
kv_RMSE <- matrix(data =c(kv_err_list[[1]][4],kv_err_list[[2]][4],kv_err_list[[3]][4]))

#best model is model 1 - (0,0,1) with non zero mean

names(nu_err_list) <- c("Nushagak (0,1,1)", "Nushagak (0,1,1) drift", "Nushagak (1,1,1)")
nu_err_list
nu_RMSE <- matrix(data =c(nu_err_list[[1]][4],nu_err_list[[2]][4],nu_err_list[[3]][4]))

# best model is model 1 - (0,1,1)

names(wo_err_list) <- c("Wood (0,1,1)", "Wood (0,1,1) drift", "Wood (1,1,1)")
wo_err_list
wo_RMSE <- matrix(data =c(wo_err_list[[1]][4],wo_err_list[[2]][4],wo_err_list[[3]][4]))

#best model is model 2 - (0,1,1) with drift

```
Best model is the one with the lowest RMSE.

## Check residuals (NICK)

We chose the model with the lower RMSE moving forward. 

```{r}
#kvichak
#select model 1
forecast::checkresiduals(kv_fore[[1]]) # plots the residuals, acf and histogram

forecast::checkresiduals(kv_fore[[1]], plot = FALSE) #runs the Ljung- Box test

#The null hypothesis for this test is no autocorrelation. We do not want to reject the null.
#we fail to reject the null if p>.05

 ### Kvichak Results ###
#p-value for ARIMA(0,0,1) with non zero mean is .00141 so we reject the null

#Nushagak
#select model 1
forecast::checkresiduals(nu_fore[[1]]) 

forecast::checkresiduals(nu_fore[[1]], plot = FALSE) 

### Nushagak Results ###
#p-value for ARIMA(0,1,1) is .032 so we reject the null

#Wood
#Select model 2
forecast::checkresiduals(wo_fore[[2]]) 

forecast::checkresiduals(wo_fore[[2]], plot = FALSE) 

### Wood Results ###
#p-value for ARIMA(0,1,1) drift is .23 so we fail to reject the null

```

The residuals for the Kvichak River are significantly auto-correlated even though only two lags show significance on the correlogram. The Nushagak also has significantly auto correlated residuals and only the Wood passes the Ljung-Box test for having non auto correlated residuals. 

The best models for each river were selected derived by choosing the model with the lowest RMSE value. The best model for the Kvichak was an ARIMA(0,0,1) with non zero mean, the best model for the Nushagak was ARIMA(0,1,1) and the best model for the Wood was ARIMA(0,1,1) with drift. 

# DISCUSSION

The ARIMA models tested produced reasonable estimates for roughly one to three years but tended to miss long term trends in the data. This was especially true for the Wood and Nushagak which had sharp upward trends in abundance after 2015 that our forecasts did not predict. For the Wood River the auto.arima function chose a model without drift as the best fit, however when we compared the three best models using the accuracy function a model with drift ws chosen based on its lower RMSE value. This model with drift produced a somewhat better visual fit to the data but still resulted in underestimates of the run size in all years during the forecasting period. The model selected for the Kvichak produced a much better visual fit to the data than in the other two rivers. This may be because the run size in the Kvichak has remained relatively stable without the obvious increasing trend visible in the other two rivers. 

The FRI forecasts were better than those generated by our ARIMA models in the Wood and Nushagak Rivers yet still under predicted the actual run size in most years. Our models for the Kvichak were much closer to both the FRI forecasts and actual run sizes, yet similar to the other rivers were lower than the FRI forecasts and under predicted the actual run sizes. 

The autocorrelation present in the residuals for the Kvichak indicates that some structure still exists in the data which is not explained by our models. While few lags are significant there appears to be a repeating sinusoidal pattern in the correlogram for the three models tested. A similar pattern may be present in the Nushagak but it is less apparent in the correlogram, however the Nushagak residuals still show significant autocorrelation. The Wood river has no significant autocorrelation in the residuals and there appears to be the least amount of structure present in the correlogram of any of the rivers tested. This suggests that the ARIMA model may be a better fit to the Wood River system, which is a surprising result as the Kvichak has the best visual fit of the three systems tested. 

# Description of each team member's contributions

Example: "All team members helped decide on the goal and ran the analyses for the individual regions. Team members 2 & 3 wrote most of the code for the analysis of the regions. Team member 4 researched approaches for measuring accuracy of forecasts in [Hyndman & Athanasopoulos[OTexts.com/fpp2] and team member 2 added code for that to the methods. Team member 4 also researched tests for stationarity and worked with team member 2 to code that up. Team member 1 worked on the plotting section of the report using and adapting code that team member 3 wrote. All team members helped edit the report and wrote the discussion together."

