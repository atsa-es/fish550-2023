---
title: "Lab 4 - Hidden Markov Models"
author: "Nick Chambers, Madison Shipley, Karl Veggerby"
date: May 9, 2023
output: 
  html_document:
    code-folding: true
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
options(dplyr.summarise.inform = FALSE)
```


# Data

When visually plotting copepod richness versus several predictors, PDO stood out as seemingly having a very strong correlative pattern with copepod richness that was worth further exploration.
    
## Load the data
```{r load_data}

library(hmmTMB)
library(depmixS4)
library(tidyverse)


stoplight <- read.csv(here::here("Lab-4", "stoplight.csv"))

head(stoplight)
names(stoplight)

```

## Wrangle the data

```{r}
# Reference slides 55-60
# ecosystem indicators

stoplight[,1]  
years<-seq(1998,2021,1)

# Here we select several ecosystem indicators to examine
PDO_DecMarch<-unlist(as.vector(stoplight[1,3:26])) 
SST<-unlist(as.vector(stoplight[4,3:26])) 
Copepod_richness<-unlist(as.vector(stoplight[9,3:26])) 
Ichthy_community_index<-unlist(as.vector(stoplight[14,3:26]))

dat<-matrix(nrow=length(years), ncol=5)
dat[,1]<-years
dat[,2]<-PDO_DecMarch
dat[,3]<-SST
dat[,4]<-Copepod_richness
dat[,5]<-Ichthy_community_index
colnames(dat)<-c("years","PDO", "SST", "CopeRich", "FishInx")
rownames(dat)<-seq(1,24,1)

dat<-as.data.frame(dat)
print(dat)
#five times series in response and keep things to your block 


#exploring the data more 
#rule 1 plot your data 

ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting all
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(aes(y = FishInx, color = "FishInx"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting Coperich and env cov
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting Coperich and env cov
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# PDO states 
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  geom_hline(yintercept = 0, linetype = "dotted") +
  geom_hline(yintercept = 2.5, linetype = "dotted") +
  geom_hline(yintercept = -2.5, linetype = "dotted") +
  theme_minimal()

#Think of weak vs strong PDO?

#CopeRichness tracks very closely with PDO
#SST seems to have a negligible correlation 

ggplot(dat, aes(x = PDO, y = CopeRich, color = CopeRich < 0)) +
  geom_point() +
  geom_line(aes(x = PDO, y = CopeRich)) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  scale_color_manual(values = c("red", "blue"), labels = c("Above 0", "Below 0")) +
  labs(x = "PDO", y = "CopeRich") +
  theme_minimal()
  
#fish index is all over the place, let's not use it. 
```


# Methods
    
We fit models with different numbers of PDO states to determine whether PDO seems to have 2 or 3 states. There appears to be high and low states but it is unclear if there is a 'neutral' state that modulates copepod richness in addition to the hot and cool phases. 
    
We also set the transition equation equal to ~1 in addition to ~ PDO to explore if PDO was more effective than several simple numeric options for controlling transition dynamics.

We assumed the familys were gaussian for all models tested. 

We plotted the fit of all models to copepod richness and PDO data from the stoplight dataset. We then also compared model fits with AIC in an attempt to select the best model. 

   
```{r}
# Model 1
mod1 = depmix(CopeRich ~1,
                   nstates = 2, 
                   transition = ~1, 
                   family = gaussian(),
                   data=dat)

fitmod1 = fit(mod1)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best1 <- 1e10
best_model1 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod1 <- fit(mod1)
  if(AIC(fitmod1)< best1){
    best_model1 <- fitmod1
    best1 <- AIC(fitmod1)
  }
}

plot(ts(posterior(best_model1, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates <- apply(posterior(best_model1)[,c("S1", "S2")],1, which.max)
mu <- summary(best_model1)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])

#predicted values
pred1<-pred %>% 
  pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
  geom_line(data = pred1, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 1 - Two States", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Model 1 produces a reasonably good fit to the data. 

```{r}
# Model 2
mod2 = depmix(CopeRich ~1,
                   nstates = 3, 
                   transition = ~1, 
                   family = gaussian(),
                   data=dat)

fitmod2 = fit(mod2)
summary(fitmod2)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best2 <- 1e10
best_model2 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod2 <- fit(mod2)
  if(AIC(fitmod2)< best2){
    best_model2 <- fitmod2
    best2 <- AIC(fitmod2)
  }
}

# plot(ts(posterior(best_model1, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
#      main="Posterior probability of state 1 (copepods good?).",
#      frame=FALSE)

prstates <- apply(posterior(best_model2)[,c("S1", "S2")],1, which.max)
mu <- summary(best_model2)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])

#predicted values
pred2 <- pred %>% 
  pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred2, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 2 - Three States", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Compared to model 1, model two produces a poor visual fit to the data. Because of this we assumed 2 states in the other models we tested. 

```{r} 

############## The plot here needs work ##############


#Copepods and PDO as intercepts 
mod3 = depmix(list(CopeRich ~1, PDO~1),
             nstates = 2, 
             transition = ~1, 
             family = list(gaussian(),gaussian()),
             data=dat)

fitmod3 = fit(mod3)
summary(fitmod3)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best3 <- 1e10
best_model3 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod3 <- fit(mod3)
  if(AIC(fitmod3)< best3){
    best_model3 <- fitmod3
    best3 <- AIC(fitmod3)
  }
}

plot(ts(posterior(best_model3, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model3)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model3)[,1]
mu3<-summary(best_model3)[,3]
pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates],"PDO" = mu3[prstates])
pred3<-pred %>% pivot_longer(-Year, names_to = "Covariates", values_to = "Fit")

ggplot() +
  geom_line(data = pred3, aes(x = Year, y = Fit, group = Covariates, color = Covariates)) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 3 - Transition ~ 1", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()


```

```{r}

#Copepods and PDO as intercepts where the transition is informed by PDO
mod4 = depmix(list(CopeRich ~1, PDO~1),
              nstates = 2, 
              transition = ~PDO, 
              family = list(gaussian(),gaussian()),
              data=dat)
fitmod4 = fit(mod4)
summary(fitmod4)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best4 <- 1e10
best_model4 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod4 <- fit(mod4)
  if(AIC(fitmod4)< best4){
    best_model4 <- fitmod4
    best4 <- AIC(fitmod4)
  }
}

plot(ts(posterior(best_model4, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model4)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model4)[,1]
mu4<-summary(best_model4)[,3]
pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates],"PDO" = mu4[prstates])
pred4<-pred %>% pivot_longer(-Year, names_to = "Covariates", values_to = "Fit")

ggplot() +
  geom_line(data = pred4, aes(x = Year, y = Fit, group = Covariates, color = Covariates)) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 4 - Transition ~ PDO", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Models 3 and 4 produce similar fits to the data, the only obvious difference is that model 4 spends less time in the higher state than model 3 in the later time periods. 


```{r}

#Copepods as they relate to PDO
mod5 = depmix(list(CopeRich ~PDO),
              nstates = 2, 
              transition = ~1, 
              family = list(gaussian()),
              data=dat)
fitmod5 = fit(mod5)
summary(fitmod5)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best5 <- 1e10
best_model5 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod5 <- fit(mod5)
  if(AIC(fitmod5)< best5){
    best_model5 <- fitmod5
    best5 <- AIC(fitmod5)
  }
}

plot(ts(posterior(best_model5, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model5)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model5)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])
pred5<-pred %>% pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred5, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 5 - Copepod Richness ~ PDO , Transition ~1", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```

For the intercept we chose to model Copepod Richness ~ PDO. These data sets have the closest correlation and so this was done to test if the fit could be improved by modeling the variation of Copepod Richness as a function of PDO. Admittedly, we are not sure if this is a appropriate entry to the `depmix()` function but the results for models 5 and 6 were interesting so we included them. 

# Model 6
```{r}

#Copepods as they relate to PDO where the transition is informed by PDO
mod6 = depmix(list(CopeRich ~PDO),
              nstates = 2, 
              transition = ~PDO, 
              family = list(gaussian()),
              data=dat)
fitmod6 = fit(mod6)
summary(fitmod6)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best6 <- 1e10
best_model6 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod6 <- fit(mod6)
  if(AIC(fitmod6)< best6){
    best_model6 <- fitmod6
    best6 <- AIC(fitmod6)
  }
}

plot(ts(posterior(best_model6, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model6)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model6)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])
pred6<-pred %>% pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred6, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 6 - Copepod Richness ~ PDO, Transition ~ PDO", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()


```

Model 6 produced the worst visual fit to the data. This model suggests there is a dominant state near the mean of the data and the second state is only marginally different. 

#model selection with AIC
```{r}
mods <- c("1","2","3","4","5","6")
aic <- c(AIC(best_model1), AIC(best_model2), AIC(best_model3), AIC(best_model4), AIC(best_model5),AIC(best_model6))
delta.aic <- aic-min(aic)
tab <- cbind.data.frame(mods, aic, delta.aic)

tab

```
AIC tells us that the best model would be model 6, although it is marginally better than model 5 with a delta AIC of just over 2. The delta AIC values are only about 2 different between models 1-2 and 3-4 and 5-6 respectively. Each set of models are the most similar to each other within the models tested and these AIC values indicate little to no support for one approach within each group to be significantly better than the other. AIC values do indicate significantly better performance between these sets of models, however this support is not supported by looking at visual fits of the data. The two best models, 5 and 6, produce the worst visual fits to the data of any models tested. It is unclear why AIC is selecting these models as the best, but it does seem that AIC favors the simple models with only one intercept rather than models with two intercepts. Because of the apparent poor fit of models 5 and 6, it seems other methods of model selection such as Cross Validation or leave One Out may be more appropriate here than AIC. 

# More model diagnostics
```{r}
#create a funciton to help build transition matrices
convert_probs <- function(fit, coef_value = 0) {
  # extract coefficients
  p1 <- fit@transition[[1]]@parameters$coefficients
  p2 <- fit@transition[[2]]@parameters$coefficients
  
  # assemble transition matrix in mlogit space
  m <- matrix(0, 2, 2)
  m[1,] <- p1[1,] + p1[2,] * coef_value #intercept + slope * coefficient
  m[2,] <- p2[1,] + p2[2,] * coef_value
  
  # exponentiate
  m <- exp(m)
  
  # normalize
  m[1,] <- m[1,] / sum(m[1,])
  m[2,] <- m[2,] / sum(m[2,])
  return(m)
}
```


```{r}

#Look at the transition matrices and variance
summary(fitmod1)
summary(fitmod2)
summary(fitmod3)
summary(fitmod4) # no transition matrix
summary(fitmod5)
summary(fitmod6) # no transition matrix

#get the transition matrices
convert_probs(fitmod4)
convert_probs(fitmod6)

```

State 3 in model 2 appears to be fairly unstable as its state 3 to state 3 transition probability is 0, and it has a fairly low probability of other states transitioning to state 3, outside of state 2 to state 3. Our best model run did not generate any observations in state 3 so it is unclear if this is a middle state as we hypothesized or not. 

The state 1 transition probabilities in models 3 and 4 showed an opposite pattern, yet produced very similar fits to the data. The difference appeared to only be shown in the most recent years, where in model 4 there was a more rapid shift out of the higher state. This aligns with what we would expect with the change in transition probabilities from state 1 to state 2. 

Model 5 appeared to have smaller intercept values which makes sense as the predicted states were closer to 0 than in the other models. 

The transition matrix for model 6 was the most unique with a high likelihood that the model will transition to and stay in state 2. This is another good indication that the model is a poor fit to the data as the data visually appears to have at least two states, and the other models produced good visual fits with a two state approach. 


# Results

Summarize the model you've created. Specifically,

-   Does it converge?

All the models converged even when running the for loop over various seeds, however visual inspection of model fits revealed that several fits were quite poor, including our top model ranked by AICc.

-   How many states seem to be most supported?

Compared to model 1, model two with 3 states produced a poor visual fit to the data. Because of this we assumed 2 states in the other models we tested. This aligned with our visual estimates of two states.

-   Plot the time series of estimated states. What does this mean?

The plots of estimated states show the underlying pattern that may exist if there is in fact a shift between states. The variation in the data from this pattern would be related to unexplained error related to covariates other than the underlying states. Visually there appears to be good support for two underlying states, however the estimated states in our top AICc ranked model do not appear to fit the data well, indicating that AICc may not be the best metric to use here. It definitely highlights the dangers of blindly trusting AIC without further model checks.


# Discussion
PDO is an indice of ocean conditions that is generally thought to act as a driver for abundance and richness of organisms in the North Pacific. Here we predicted that PDO would be a driver of copepod richness. The two time series of data appear to closely co-vary and seem to show a pattern of a high and low state with rapid swings between the two. Our models using 2 states produced good visual fits and we found little support for three states. AIC appears to be a relatively poor choice for model selection in this instance although it is unclear if that is specific to HMM models or if there was a programming error. Other types of model selection would likely increase our understanding of model performance. We saw no obvious difference between a rapid shift in states , `transition = ~1` and a shift proportional to the PDO data set. This suggests that there is in fact a very rapid shift between states, which aligns with our expected result based on the general lack of observations near neutral conditions. 


## what we are still confused about
One question we had is that our 'best' model based on AICc values did not appear to be a good fit to the data visually. When this is the case, what should our next steps be? Visually confirming model fit seems to overrule AICc values when those diagnsotics are contradictory, is this true?

We didn't have a good handle on how the 'nstates' and 'transitions' inputs to the models interacted and what type of model diagnostics would help us quantify underlying relationships. 

PDO has a very strong correlative pattern with copepod richness. We ran several combinations of model to examine the strength of this relationship. We produced some models with decent looking fits, but these models were not as highly ranked by AICc as other, seeminly less well fitting models. Is AIC a poor choice? We have a suspicion this question will be anwered in the next lecture(s)...

# Team contributions

Madison took point on coding, Nick helped with coding and compiled it into the final rmd, and Nick and Karl did writing and .Rmd organizing. 
