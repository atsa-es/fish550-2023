---
title: "Lab 4 - Hidden Markov Models"
author: "Nick Chambers, Madison Shipley, Karl Veggerby"
date: May 9, 2023
output: 
  html_document:
    code-folding: true
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
options(dplyr.summarise.inform = FALSE)
```


# Data

    When visually plotting copepod richness versus several predictors, PDO stood out as seemingly having a very strong correlative pattern with copepod richness that was worth further exploration.
    
## Load the data

We have included the `stoplight.csv` dataset for this week. One of the
columns divides indicators into groups (e.g. Local Physical, Local
Biological, etc). 

```{r load_data}

library(hmmTMB)
library(depmixS4)

stoplight <- read.csv(here::here("Lab-4", "stoplight.csv"))

head(stoplight)
names(stoplight)

```

## Wrangle the data

```{r}

#ecosystem indicators
stoplight[,1]  
years<-seq(1998,2021,1)

#ecosystem indicators to pull
PDO_DecMarch<-unlist(as.vector(stoplight[1,3:26])) 
SST<-unlist(as.vector(stoplight[4,3:26])) 
Copepod_richness<-unlist(as.vector(stoplight[9,3:26])) 
Ichthy_community_index<-unlist(as.vector(stoplight[14,3:26]))

dat<-matrix(nrow=length(years), ncol=5)
dat[,1]<-years
dat[,2]<-PDO_DecMarch
dat[,3]<-SST
dat[,4]<-Copepod_richness
dat[,5]<-Ichthy_community_index
colnames(dat)<-c("years","PDO", "SST", "CopeRich", "FishInx")
rownames(dat)<-seq(1,24,1)

dat<-as.data.frame(dat)
print(dat)
#five times series in response and keep things to your block 


#exploring the data more 
#rule 1 plot your data 

ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting all
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(aes(y = FishInx, color = "FishInx"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting Coperich and env cov
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = SST, color = "SST"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# Plotting Coperich and env cov
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  geom_line(aes(y = CopeRich, color = "CopeRich"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

# PDO states 
ggplot(dat, aes(x = years)) +
  geom_line(aes(y = PDO, color = "PDO"), size = 1) +
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green", FishInx = "purple")) +
  labs(x = "Year", y = "Value", color = "Variable") +
  geom_hline(yintercept = 0, linetype = "dotted") +
  geom_hline(yintercept = 2.5, linetype = "dotted") +
  geom_hline(yintercept = -2.5, linetype = "dotted") +
  theme_minimal()

#Think of weak vs strong PDO?

#CopeRichness tracks very closely with PDO
#SST seems to have a negligible correlation 

ggplot(dat, aes(x = PDO, y = CopeRich, color = CopeRich < 0)) +
  geom_point() +
  geom_line(aes(x = PDO, y = CopeRich)) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  scale_color_manual(values = c("red", "blue"), labels = c("Above 0", "Below 0")) +
  labs(x = "PDO", y = "CopeRich") +
  theme_minimal()
  

#fish index is all over the place, let's not use it. 

```


### Objective tips 

Keep this relatively simple. select five times series pick some responses, pick some drivers.

Pass the model responses in as list of formulas-- family also has to be in the list 

* Reference slides 55-60



# General tasks

Each group has the same general tasks, but you will adapt them as you work on the data.

Please pick a type of indicators, and develop a 2- or 3-state multivariate HMM. 

# Methods

A few tips:

-   Assume all responses are Gaussian.

-   You're welcome to include covariates (year? Climate variables?) --
    but fitting a simple model without covariates is also totally fine
    
    
    We fit models with different numbers of PDO states to determine whether PDO seems to have 2 or 3 states. It's unclear if there is a 'neutral' state that modulates copepod richness in addition to the hot and cool phases. 
    
   We also used a few options for the transition equation in addition to PDO to explore if PDO was more effective than several simple numeric options for controlling transition dynamics.
   
```{r}
# Model 1
mod1 = depmix(CopeRich ~1,
                   nstates = 2, 
                   transition = ~1, 
                   family = gaussian(),
                   data=dat)

fitmod1 = fit(mod1)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best1 <- 1e10
best_model1 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod1 <- fit(mod1)
  if(AIC(fitmod1)< best1){
    best_model1 <- fitmod1
    best1 <- AIC(fitmod1)
  }
}

plot(ts(posterior(best_model1, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates <- apply(posterior(best_model1)[,c("S1", "S2")],1, which.max)
mu <- summary(best_model1)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])

#predicted values
pred1<-pred %>% 
  pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
  geom_line(data = pred1, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 1 - Two States", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Model 1 produces a reasonably good fit to the data. 

```{r}
# Model 2
mod2 = depmix(CopeRich ~1,
                   nstates = 3, 
                   transition = ~1, 
                   family = gaussian(),
                   data=dat)

fitmod2 = fit(mod2)
summary(fitmod2)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best2 <- 1e10
best_model2 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod2 <- fit(mod2)
  if(AIC(fitmod2)< best2){
    best_model2 <- fitmod2
    best2 <- AIC(fitmod2)
  }
}

# plot(ts(posterior(best_model1, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
#      main="Posterior probability of state 1 (copepods good?).",
#      frame=FALSE)

prstates <- apply(posterior(best_model2)[,c("S1", "S2")],1, which.max)
mu <- summary(best_model2)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])

#predicted values
pred2 <- pred %>% 
  pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred2, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 2 - Three States", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Compared to model 1, model two produces a poor visual fit to the data. Because of this we assumed 2 states in the other models we tested. 

```{r} 

############## The plot here needs work ##############


#Copepods and PDO as intercepts 
mod3 = depmix(list(CopeRich ~1, PDO~1),
             nstates = 2, 
             transition = ~1, 
             family = list(gaussian(),gaussian()),
             data=dat)

fitmod3 = fit(mod3)
summary(fitmod3)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best3 <- 1e10
best_model3 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod3 <- fit(mod3)
  if(AIC(fitmod3)< best3){
    best_model3 <- fitmod3
    best3 <- AIC(fitmod3)
  }
}

plot(ts(posterior(best_model3, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model3)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model3)[,1]
mu3<-summary(best_model3)[,3]
pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates],"PDO" = mu3[prstates])
pred3<-pred %>% pivot_longer(-Year, names_to = "Covariates", values_to = "Fit")

ggplot() +
  geom_line(data = pred3, aes(x = Year, y = Fit, group = Covariates, color = Covariates)) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 3 - Transition ~ 1", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()


```

```{r}

#Copepods and PDO as intercepts where the transition is informed by PDO
mod4 = depmix(list(CopeRich ~1, PDO~1),
              nstates = 2, 
              transition = ~PDO, 
              family = list(gaussian(),gaussian()),
              data=dat)
fitmod4 = fit(mod4)
summary(fitmod4)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best4 <- 1e10
best_model4 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod4 <- fit(mod4)
  if(AIC(fitmod4)< best4){
    best_model4 <- fitmod4
    best4 <- AIC(fitmod4)
  }
}

plot(ts(posterior(best_model4, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model4)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model4)[,1]
mu4<-summary(best_model4)[,3]
pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates],"PDO" = mu4[prstates])
pred4<-pred %>% pivot_longer(-Year, names_to = "Covariates", values_to = "Fit")

ggplot() +
  geom_line(data = pred4, aes(x = Year, y = Fit, group = Covariates, color = Covariates)) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 4 - Transition ~ PDO", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```
Models 3 and 4 produce similar fits to the data, the only obvious difference is that model 4 spends less time in the higher state than model 3. 


```{r}

#Copepods as they relate to PDO
mod5 = depmix(list(CopeRich ~PDO),
              nstates = 2, 
              transition = ~1, 
              family = list(gaussian()),
              data=dat)
fitmod5 = fit(mod5)
summary(fitmod5)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best5 <- 1e10
best_model5 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod5 <- fit(mod5)
  if(AIC(fitmod5)< best5){
    best_model5 <- fitmod5
    best5 <- AIC(fitmod5)
  }
}

plot(ts(posterior(best_model5, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model5)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model5)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])
pred5<-pred %>% pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred5, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 5 - Copepod Richness ~ PDO , Transition ~1", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()

```

For the intercept we chose to model Copepod Richness ~ PDO. These data sets have the closest correlation and so this was done to test of the fit could be improved by modeling the variation of Copepod Richness as a function of PDO. Admittedly, we are not sure if this is a appropriate entry to the `depmix()` function but the results for models 5 and 6 were interesting so we included them. 

# Model 6
```{r}

#Copepods as they relate to PDO where the transition is informed by PDO
mod6 = depmix(list(CopeRich ~PDO),
              nstates = 2, 
              transition = ~PDO, 
              family = list(gaussian()),
              data=dat)
fitmod6 = fit(mod6)
summary(fitmod6)

#Find best fit 
iter <-100
seeds<-sample(100:1000, size = iter, replace = F)
best6 <- 1e10
best_model6 <- NA
for(i in 1:iter){
  set.seed(seeds[i])
  fitmod6 <- fit(mod6)
  if(AIC(fitmod6)< best6){
    best_model6 <- fitmod6
    best6 <- AIC(fitmod6)
  }
}

plot(ts(posterior(best_model6, type="smoothing")[,1], start=c(2003,5), deltat=1/12),ylab="probability",
     main="Posterior probability of state 1 (copepods good?).",
     frame=FALSE)

prstates<-apply(posterior(best_model6)[,c("S1", "S2")],1, which.max)
mu<-summary(best_model6)[,1]

pred <- tibble("Year" = dat$years, "Copepod Richness" = mu[prstates])
pred6<-pred %>% pivot_longer(-Year, names_to = "Copepod Richness", values_to = "Fit")

ggplot() +
   geom_line(data = pred6, aes(x = years, y = Fit, color = "predicted_states"), size = 1) +
  geom_line(data = dat, aes(x = years, y = CopeRich, color = "CopeRich"), size = 1) +
  geom_line(data = dat, aes(x = years, y = PDO_DecMarch, color = "PDO" ), size = 1)+
  scale_color_manual(values = c(PDO = "blue", SST = "red", CopeRich = "green",
                                FishInx = "purple", predicted_states = "orange")) +
  labs(title = " Model 6 - Copepod Richness ~ PDO, Transition ~ PDO", x = "Year", y = "Value", color = "Variable") +
  theme_minimal()


```

Model 6 produced the worst visual fit to the data. This model suggests there is a dominant state near the mean of the data and the second state is only marginally different. 

#model selection with AIC
```{r}
mods <- c("1","2","3","4","5","6")
aic <- c(AIC(best_model1), AIC(best_model2), AIC(best_model3), AIC(best_model4), AIC(best_model5),AIC(best_model6))
delta.aic <- aic-min(aic)
tab <- cbind.data.frame(mods, aic, delta.aic)

tab

```
AIC tells us that the best model would be model 6, although it is marginally better than model 5 with a delta AIC of just over 2. The delta AIC values are only about 2 different between models 1-2 and 3-4 and 5-6 respectively. Each set of models are the most similar to each other within the models tested and these AIC values indicate little to no support for one approach within each group to be significantly better than the other. AIC values do indicate significantly better performance between these sets of models, however this support is not supported by looking at visual fits of the data. The two best models, 5 and 6, produce the worst visual fits to the data of any models tested. It is unclear why AIC is selecting these models as the best, but it does seem that AIC favors the simple models with only one intercept rather than models with two intercepts. Because of the apparent poor fit of models 5 and 6, it seems other methods of model selection such as Cross Validation or leave One Out may be more appropriate here than AIC. 

# More model diagnostics
```{r}
#create a funciton to help build transition matrices
convert_probs <- function(fit, coef_value = 0) {
  # extract coefficients
  p1 <- fit@transition[[1]]@parameters$coefficients
  p2 <- fit@transition[[2]]@parameters$coefficients
  
  # assemble transition matrix in mlogit space
  m <- matrix(0, 2, 2)
  m[1,] <- p1[1,] + p1[2,] * coef_value #intercept + slope * coefficient
  m[2,] <- p2[1,] + p2[2,] * coef_value
  
  # exponentiate
  m <- exp(m)
  
  # normalize
  m[1,] <- m[1,] / sum(m[1,])
  m[2,] <- m[2,] / sum(m[2,])
  return(m)
}
```


```{r}

#Look at the transition matrices and variance
summary(fitmod1)
summary(fitmod2)
summary(fitmod3)
summary(fitmod4) # no transition matrix
summary(fitmod5)
summary(fitmod6) # no transition matrix

#get the transition matrices
convert_probs(fitmod4)
convert_probs(fitmod6)

```




# Results

Summarize the model you've created. Specifically,

-   Does it converge?

The models converged, however visual inspection of model fits revealed that several fits were quite poor, including our top model ranked by AICc.

-   How many states seem to be most supported?

Compared to model 1, model two with 3 states produced a poor visual fit to the data. Because of this we assumed 2 states in the other models we tested. 

-   Plot the time series of estimated states. What does this mean?

The estimated states in our top AICc ranked model do not appear to fit the data well, indicating that AICc may not be the best metric to use here. It definitely highlights the dangers of blindly trusting AIC without further model checks.

-   What are the transition probabilities?

We fit models that had transitions of 1, as well as transitions mediated by PDO. 



# Discussion

## what we are still confused about
One question we had is that our 'best' model based on AICc values did not appear to be a good fit to the data visually. When this is the case, what should our next steps be? Visually confirming model fit seems to overrule AICc values when those diagnsotics are contradictory, is this true?

We didn't have a good handle on how the 'nstates' and 'transitions' inputs to the models interacted. 

PDO has a very strong correlative pattern with copepod richness. We ran several combinations of model to examine the strength of this relationship. We produced some models with decent looking fits, but these models were not as highly ranked by AICc as other, seeminly less well fitting models. 



# Team contributions

Madison took point on coding, Nick did some coding too, and Nick and Karl did writing and .Rmd organizing. 
