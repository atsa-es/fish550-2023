[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fish 550 Spring 2023",
    "section": "",
    "text": "1 Labs\n\nLab 1: Forecasting with ARIMA models\nLab 2: Interpolating with MARSS models"
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#teams",
    "href": "Lab-1/Lab1-ARIMA.html#teams",
    "title": "2  Lab Intro",
    "section": "2.1 Teams",
    "text": "2.1 Teams\n\nBristol Bay Data: Nick Chambers (SAFS), Liz Elmstrom (SAFS), Maria Kuruvilla (QERM)\nBristol Bay Data: Eric French (Civil), Dylan Hubl (ESRM), Miranda Mudge (Molecular & Cell Bio)\nRuggerone & Irvine Data: Zoe Rand (QERM), Madison Shipley (SAFS), Emma Timmins-Schiffman (Genome Sci)\nRuggerone & Irvine Data: Terrance Wang (SAFS), Josh Zahner (SAFS), Karl Veggerby (SAFS)"
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#references",
    "href": "Lab-1/Lab1-ARIMA.html#references",
    "title": "2  Lab Intro",
    "section": "2.2 References",
    "text": "2.2 References\nHolmes, E. E. (2020) Fisheries Catch Forecasting https://fish-forecast.github.io/Fish-Forecast-Bookdown\nHyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia. https://otexts.com/fpp2/.\nPlus the lecture material on the ATSA website."
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#type-of-questions-you-might-ask",
    "href": "Lab-1/Lab1-ARIMA.html#type-of-questions-you-might-ask",
    "title": "2  Lab Intro",
    "section": "2.3 Type of questions you might ask",
    "text": "2.3 Type of questions you might ask\n“Compare the accuracy of forecasts using best fit ARIMA models for pink salmon using the different regions in the Ruggerone & Irvine data. Is forecast accuracy is different for different regions?”\n“Compare the accuracy of total abundance forecasts using ARIMA models for Bristol Bay sockeye rivers and compare to the AKFW and UW FRI forecasts.”\n“Compare the accuracy of age-group forecasts using ARIMA models for Bristol Bay sockeye and compare to the AKFW and UW FRI forecasts.”\n“Use the Ruggerone & Irvine data and ARIMA models to study the autoregressive structure of pink, chum and sockeye. Are there differences by region (AK verus E Asia)?”\n“Compare the forecasts of total North Pacific pink and chum using 5, 10, 15, and 20 years of training data. Does forecast accuracy increase with more training data?”\n“Create 1-year forecasts of total North Pacific pink salmon using 20 years of training data for all of the Ruggerone and Irvine data. Is forecast error correlated with the PDO?”"
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#bristol-bay-sockeye-data",
    "href": "Lab-1/Lab1-ARIMA.html#bristol-bay-sockeye-data",
    "title": "2  Lab Intro",
    "section": "2.4 Bristol Bay Sockeye data",
    "text": "2.4 Bristol Bay Sockeye data\nThe bristol_bay_data_plus_covariates.rds file has Bristol Bay sockeye abundance for 9 rivers for 4 age-groups. The data are from Ovando et al 2021 Improving forecasts of sockeye salmon (Oncorhynchus nerka) with parametric and nonparametric models DOI: 10.1139/cjfas-2021-0287. You’ll find a copy in the lab folder. The data file also has the covariates for year that the smolts enter the ocean as used in Ovando et al. \nLoad the data.\n\n\n\nThe data you will most likely want are\n\nret_yr The year the spawners return to the spawning grounds\nret The returns (number of fish in 1000s)\nsystem The river name\nage_group The age_group\nforecast.adfw The forecast from AK Fish and Wildlife\nforecast.fri The forecast from UW Fisheries Research Institute\nenv_* are some covariates at the year the age group entered the ocean\n\nIn the data file, the age group designation is “a.b” where “a” is number of years in freshwater and “b” is number of years in the ocean. The age of the spawners in then a+b.\n\nThe data\n\n\ncolnames:  brood_yr ret_yr system fw_age o_age age_group ret forecast.adfw forecast.fri env_pdo env_sst env_slp env_upstr \n\n\nsystem (river):  Igushik Wood Nushagak Kvichak Naknek Egegik Ugashik \n\n\nage groups:  \n\n\nSome plots of the Bristol Bay data. Hmm there is a NA that was replaced with 0 it looks like.\n\n\n\n\n\nplotted by age group\n\n\n\n\n\n\n\n\n\ntotal across all 4 ages\n\n\n\n\n\n2.4.1 Some subsets of the data\nHere are some subsets of the data that you might want to use.\nLog total by age group\n\n\n# A tibble: 6 × 3\n# Groups:   age_group [1]\n  age_group ret_yr lntotal\n  <chr>      <dbl>   <dbl>\n1 1.2         1963    7.49\n2 1.2         1964    8.50\n3 1.2         1965    7.22\n4 1.2         1966    7.18\n5 1.2         1967    6.88\n6 1.2         1968    8.11\n\n\nLog total by river\n\n\n# A tibble: 6 × 3\n# Groups:   system [1]\n  system ret_yr lntotal\n  <chr>   <dbl>   <dbl>\n1 Egegik   1963    7.54\n2 Egegik   1964    7.55\n3 Egegik   1965    8.55\n4 Egegik   1966    7.95\n5 Egegik   1967    7.41\n6 Egegik   1968    6.88\n\n\nCompare fish that spend 2 years in ocean versus those that spend 3 years.\n\n\n# A tibble: 6 × 4\n# Groups:   system, ocean_years [1]\n  system ocean_years ret_yr lntotal\n  <chr>  <chr>        <dbl>   <dbl>\n1 Egegik 2-yr-ocean    1963    7.02\n2 Egegik 2-yr-ocean    1964    7.29\n3 Egegik 2-yr-ocean    1965    8.34\n4 Egegik 2-yr-ocean    1966    5.96\n5 Egegik 2-yr-ocean    1967    6.58\n6 Egegik 2-yr-ocean    1968    6.35\n\n\nGet one time series and split into train and test. Each with 10 years."
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#ruggerone-irvine-salmon-in-the-north-pacific",
    "href": "Lab-1/Lab1-ARIMA.html#ruggerone-irvine-salmon-in-the-north-pacific",
    "title": "2  Lab Intro",
    "section": "2.5 Ruggerone & Irvine: Salmon in the North Pacific",
    "text": "2.5 Ruggerone & Irvine: Salmon in the North Pacific\nThe data set Data_Images/ruggerone_data.rds has total abundance of natural spawners (not hatchery) from 15 regions in the N Pacific. These are data provided with Ruggerone, G. and Irvine, J. 2018. Numbers and biomass of natural- and hatchery-origin Pink, Chum, and Sockeye Salmon in the North Pacific Ocean, 1925-2015. Marine and Coastal Fisheries: Dynamics, Management, and Ecosystem Science 10. DOI: 10.1002/mcf2.10023. Open Access.\nLoad the data\n\n\n\n\n\n\nFigure 1. The approximate geographic locations of regional stock groups. Region 1, Washington State, including the Columbia River. Region 2, Southern British Columbia (BC) south of the central coast of British Columbia (~51°N). . Region 3, Northern BC including central and northern British Columbia. Region 4, Southeast Alaska (AK) including the Yakutat coast. The Central Alaska region extends from the Bering River (~60°N), near Prince William Sound in Region 5, westward to Unimak Island (~166°W), thereby including Regions 5 through 8. Western Alaska includes Regions 9 through 12, i.e., all North American drainages flowing into the Bering Sea from Unimak Island to Kotzebue. Data for eastern and western Kamchatka (Regions 14 and 15) are separated from data for the Russian mainland and islands (called “Mainland & Islands” here, which includes the Okhotsk coast, Amur River, Primorye, Sakhalin and Kurile Islands, and relatively small runs to the Anadyr). Region 20, Japan, includes the islands of Hokkaido and Honshu. South Korea (Region 21) not shown.\n\n\n\n\n\n\n\n\n\n\nregion in data file\ndesciption\nregions in map\n\n\n\n\njapan\nJapan & South Korea\n20 and 21\n\n\nm_i\nRussian Mainland & Islands\n13, 16, 17 18, 19\n\n\nw_kam\nWestern Kamchatka\n15\n\n\ne_kam\nEastern Kamchatka\n14\n\n\nwak\nWestern Alaska\n9, 10, 11, 12\n\n\ns_pen\nSouthern Alaska Peninsula\n8\n\n\nkod\nKodiak\n7\n\n\nci\nCook Inlet\n6\n\n\npws\nPrince William Sound\n5\n\n\nseak\nSoutheast Alaska\n4\n\n\nnbc\nNorthern British Columbia\n3\n\n\nsbc\nSouthern British Columbia\n2\n\n\nwa\nWashington State\n1\n\n\nwc\nWest Coast USA\nmislabeled on map\n\n\ncak (not in data file)\nCentral Alaska\n5, 6, 7, 8\n\n\n\n\n2.5.1 Ruggerone and Irvine data\n\n\ncolnames:  year region returns species \n\n\nspecies:  pink chum sockeye \n\n\nregions:  ci e_kam japan kod korea m_i nbc pws sbc seak s_pen wa wak w_kam wc \n\n\n\n\n2.5.2 Some plots of the Ruggerone and Irvine data.\n\n\n\n\n\npink salmon by regions\n\n\n\n\n\n\n\n\n\ntotal by species\n\n\n\n\n\n\n2.5.3 Some subsets of the data\nHere are some subsets of the data that you might want to use.\nLog total North Pacific pink, chum, sockeye\n\n\n# A tibble: 6 × 3\n# Groups:   species [1]\n  species  year lntotal\n  <chr>   <dbl>   <dbl>\n1 chum     1952    3.91\n2 chum     1953    3.88\n3 chum     1954    4.20\n4 chum     1955    4.28\n5 chum     1956    4.38\n6 chum     1957    4.08\n\n\nLog North Pacific pink\n\n\n# A tibble: 6 × 5\n   year region returns species lnreturns\n  <dbl> <chr>    <dbl> <chr>       <dbl>\n1  1952 ci       4.36  pink        1.47 \n2  1953 ci       1.30  pink        0.264\n3  1954 ci       4.67  pink        1.54 \n4  1955 ci       2.67  pink        0.981\n5  1956 ci       3.57  pink        1.27 \n6  1957 ci       0.804 pink       -0.218\n\n\nTotal in some bigger areas\n\n\n# A tibble: 6 × 4\n# Groups:   area, species [1]\n  area   species  year lntotal\n  <chr>  <chr>   <dbl>   <dbl>\n1 Alaska chum     1952    2.83\n2 Alaska chum     1953    2.77\n3 Alaska chum     1954    2.92\n4 Alaska chum     1955    2.47\n5 Alaska chum     1956    2.81\n6 Alaska chum     1957    2.89"
  },
  {
    "objectID": "Lab-1/Lab1-ARIMA.html#example-analysis",
    "href": "Lab-1/Lab1-ARIMA.html#example-analysis",
    "title": "2  Lab Intro",
    "section": "2.6 Example analysis",
    "text": "2.6 Example analysis\nGet one time series out of ruggerone_data\n\n\n# A tibble: 6 × 2\n   year lnreturns\n  <dbl>     <dbl>\n1  1952      1.40\n2  1953     -1.24\n3  1954      1.40\n4  1955     -1.24\n5  1956      1.40\n6  1957     -1.24\n\n\nMake a time series object and divide into train and test data.\n\n\n\nFit a model with auto.arima() in the forecast package.\n\n\nSeries: train \nARIMA(1,0,0) with zero mean \n\nCoefficients:\n          ar1\n      -0.9293\ns.e.   0.0725\n\nsigma^2 = 0.3815:  log likelihood = -19.22\nAIC=42.45   AICc=43.15   BIC=44.44\n\n\nPlot a 30-year forecast against the test data.\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric"
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html",
    "title": "3  Team 1",
    "section": "",
    "text": "4 Question your team will address\nIn this report we sought to explore how ARIMA models perform when forecasting fish abundance in the near term (5-year forecasts).\nMore specifically, we ask do ARIMA models produce more accurate 5-year forecasts than the Fisheries Research Institute (FRI) for Sockeye in select Bristol Bay Rivers?\nWe will fit multiple ARIMA models to the Bristol Bay sockeye data and compare forecasts among these models (using RMSE) and visually compare the forecasts against the FRI forecast.\nThe ARIMA models we tested produced reasonable estimates for one to three years but tended to miss long term trends in the data. This was especially true for the Wood and Nushagak Rivers which had sharp upward trends in abundance after 2015 that our forecasts did not predict. Rather, our models underpredicted the actual run size in each river. The FRI forecasts were notably better than those generated by our ARIMA models in the Wood and Nushagak Rivers but were unable to capture the large increase in run sizes in recent years. Our forecasts for the Kvichak were much closer to both the FRI forecasts and estimated run sizes, although still generally under predicted across the years tested.\nFor the Wood and Nushagak Rivers the auto.arima function selected a model without drift as the best fit using AIC. When we compared the three best models for each river using the accuracy function a model with drift was chosen based on its lower RMSE value. These models with drift produced a somewhat better visual fit than those chosen by auto.arima but still resulted in underestimates of the run size in all years during the forecasting period. The better visual fit or our model in the Kvichak may be because the run size in the Kvichak has remained relatively stable without the increasing trend visible in the other two rivers. Both the Nushagak and Wood required differencing to remove an increasing trend in the data and this appeared to have a smoothing effect on longer forecasts vs non-differenced model runs. This smoothing may have contributed to the models for the Wood and Nushagak Rivers missing the increasing trend that occurred after 2015. This is also likely driven by the order of our ARIMA models, which only consider the previous time step to create forecasts, and thus do not perform well when predicting across multiple years (particularly when trends starkly increase or decrease). Further, these models neglect to include any environmental covariates that may help predict interannual variation at longer time steps. Had we run the models to only predict one time step forward the models likely would have performed better than relying on multiple year predictions.\nThe autocorrelation present in the residuals for the Kvichak indicates that some structure still exists in the data which is not explained by our models. While few lags are significant there appears to be a repeating sinusoidal pattern in the correlogram. A similar pattern may be present in the Nushagak but it is less apparent in the correlogram, however the Nushagak residuals still show significant autocorrelation. The Wood river has no significant autocorrelation in the residuals and there appears to be the least amount of structure present in the correlogram of any of the rivers tested. This suggests that the ARIMA model may be a better fit to the Wood River system, which is a surprising result as the Kvichak has the best visual fit of the three systems tested.\nBased on our tests here ARIMA models seem best suited to predict short term changes in abundance and were poorly suited for estimating long term trends. As a management tool for Bristol Bay Sockeye they may still be appropriate for establishing annual biological goals for fishery management as only one time step forward would be needed.\nAll team members looked at the data and worked together to decide on a question to answer. The code was split up into several sections and each team member had specific sections to write, although there was a lot of collaboration in drafting these sections. Liz and Maria went to office hours for trouble shooting of code and to ask questions. All team members contributed to accuracy tests and model selection. Nick wrote a first draft of the discussion and all team members provided helpful edits."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#initial-plan",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#initial-plan",
    "title": "3  Team 1",
    "section": "5.1 Initial plan",
    "text": "5.1 Initial plan\n\n\nWe divided the rivers among the team members to do the initial exploratory analysis and testing for stationarity. We then tried forecasting (5 years) for all rivers using the best model suggested by auto.arima()."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#what-you-actually-did",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#what-you-actually-did",
    "title": "3  Team 1",
    "section": "5.2 What you actually did",
    "text": "5.2 What you actually did\n\nWe finally chose three rivers to work with - Kvichak, Wood and Nugashak. We split the data into training data (1963-2015) and testing data (2016-2020) and performed forecasts using the auto.arima function. In addition to forecasting with the model suggested by auto.arima, we explored additional top models suggested by the auto.arima function with trace == TRUE. We then compared the accuracy of these modeled forecasts using RMSE. We also plotted the FRI forecast to visually compare the model forecast to the FRI forecast."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#read-in-and-explore-data-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#read-in-and-explore-data-liz",
    "title": "3  Team 1",
    "section": "6.1 Read in and explore data (Liz)",
    "text": "6.1 Read in and explore data (Liz)\n\n\n\n\n\n\n\n\n\n\n\nAfter exploring the larger dataset, we chose to explore temporal sockeye dynamics (specifically, total sockeye abundance) in three rivers– the Kvichak, the Nushagak, and the Wood.\nSpecifically, we seek to – 1) identify autocorrelation structures and stationarity for each of the total sockeye abundance time series, 2) compare ARIMA models, forecasts, and forecast accuracies for 5 year forecasts from 2015-2020, and 3) visually compare to these forecasts to forecasts from UW Fisheries Research Institute.\nWe did not compare our models to ADFW forecasts since the ADFW forecasts occur prior to our 5-year forecasts (2015-2020)."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#plot-the-data-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#plot-the-data-liz",
    "title": "3  Team 1",
    "section": "7.1 Plot the data (Liz)",
    "text": "7.1 Plot the data (Liz)\nPlot the data and discuss any obvious problems with stationarity from your visual test.\n\n\n\n\n\nBased on these plots, we hypothesize that data will be non-stationary for the Kvichak and stationary for the Nushagak and the Wood around a trend."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#use-acf-and-pacf-maria",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#use-acf-and-pacf-maria",
    "title": "3  Team 1",
    "section": "7.2 Use ACF and PACF (Maria)",
    "text": "7.2 Use ACF and PACF (Maria)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe acf plots for Wood river is slowly decaying and the pacf plot shows significance at lag 1. There might be AR1 structure in the data.\nThe pacf plots for Kvichak river is slowly decaying and the pacf plot shows significance at lags 1,2,4, and 6. There might be MA structure in the data.\nThe acf plots for Nushagak river is slowly decaying and the pacf plot shows significance at lags 1 and 6. There might be AR structure in the data."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#test-for-stationarity-nick-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#test-for-stationarity-nick-liz",
    "title": "3  Team 1",
    "section": "7.3 Test for stationarity (Nick & Liz)",
    "text": "7.3 Test for stationarity (Nick & Liz)\n\n\n          adf kpss_level kpss_trend\nKvichak  0.01       0.10        0.1\nNushagak 0.01       0.01        0.1\nWood     0.01       0.01        0.1\n\n\nThe stationarity tests show that the Kvichak River time series is stationary.\nWhen testing for stationarity around a level using the KPSS test, the Nushagak and the Wood test as non-stationary. However, when we change the null to include a trend, we find that both of these rivers test as stationary around a trend."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#difference-tests-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#difference-tests-liz",
    "title": "3  Team 1",
    "section": "7.4 Difference tests (Liz)",
    "text": "7.4 Difference tests (Liz)\n\n\n[1] 0\n\n\n[1] 0\n\n\n[1] 1\n\n\n[1] 1\n\n\n[1] 1\n\n\n[1] 1\n\n\nAccording to these tests, The Kvichak does not need differencing. The Nushagak and the Wood should be differenced by 1. This level of differencing should remove the upward trend or “bias” in the Nushagak and Wood Rivers."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#dividing-the-data-into-test-and-train-maria",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#dividing-the-data-into-test-and-train-maria",
    "title": "3  Team 1",
    "section": "8.1 Dividing the data into test and train (Maria)",
    "text": "8.1 Dividing the data into test and train (Maria)"
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#fit-arima-models-maria",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#fit-arima-models-maria",
    "title": "3  Team 1",
    "section": "8.2 Fit ARIMA models (Maria)",
    "text": "8.2 Fit ARIMA models (Maria)\n\n\nSeries: train_Kv \nARIMA(0,0,1) with non-zero mean \n\nCoefficients:\n         ma1    mean\n      0.4784  8.8150\ns.e.  0.1166  0.1922\n\nsigma^2 = 0.9421:  log likelihood = -72.73\nAIC=151.47   AICc=151.96   BIC=157.38\n\n\nSeries: train_Nu \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.5194\ns.e.   0.1324\n\nsigma^2 = 0.5102:  log likelihood = -55.94\nAIC=115.88   AICc=116.13   BIC=119.79\n\n\nSeries: train_Wood \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.5434\ns.e.   0.1460\n\nsigma^2 = 0.2091:  log likelihood = -32.77\nAIC=69.54   AICc=69.78   BIC=73.44\n\n\nThe best model according to model selection criterion (AICc) for the Kvichak river is an ARIMA(0,0,1) with a non-zero mean. The best model for the Nushagak and the Wood river is an ARIMA (0,1,1)."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#plot-forecasts-from-auto.arima-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#plot-forecasts-from-auto.arima-liz",
    "title": "3  Team 1",
    "section": "8.3 Plot forecasts from auto.arima (Liz)",
    "text": "8.3 Plot forecasts from auto.arima (Liz)\nBelow are plots of the total abundance measurements and their 5-year forecasts. The red points refer to Fishery Research Institutes model forecasts. The black points refer to actual data.\n\n\n\n\n\n\n\n\n\n\n\nThough these test as the best models using the auto.arima() function, we can clearly see that these models do not necessarily provide the best forecasts for the rivers of study. This is particularly apparent for the Nushagak and for the Wood River– the two rivers that include an upward trend or “bias”."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#chosing-our-own-arima-structure-liz",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#chosing-our-own-arima-structure-liz",
    "title": "3  Team 1",
    "section": "8.4 Chosing our own ARIMA structure (Liz)",
    "text": "8.4 Chosing our own ARIMA structure (Liz)\nHere we play around with different ARIMA structures on our own. Though not shown in the code, we investigated other top models using the auto.arima() function with trace = TRUE. We then tested the three top models based on AICc for the Kvichak. For the Nushagak and the Wood, we tested the two top models based on AICc, plus the best model with an added drift component.\n\n\n\n\n\n\n\n\n\n\n\nBased on these plots, we might decide to alter our model selection for the Nushagak and the Wood and change our chosen model to ARIMA(0,1,1) with drift.\nThough we could change our model for the Kvichak, the model chosen by auto.arima (ARIMA(0,0,1)) seems to behave (at least visually) essentially the same as the other top models.\nTO better inform this decision, below we check the accuracies for each of the models (n = 9)."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#check-accuracy-nick",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#check-accuracy-nick",
    "title": "3  Team 1",
    "section": "8.5 Check accuracy (Nick)",
    "text": "8.5 Check accuracy (Nick)\n\n\n                     [,1]\nKvichak (0,0,1) 0.2717361\nKvichak (1,0,1) 0.2814976\nKvichak (0,0,2) 0.3125752\n\n\n                               [,1]\nNushagak (0,1,1)          1.1181456\nNushagak (0,1,1) w/ drift 0.9992743\nNushagak (1,1,1)          1.1409033\n\n\n                           [,1]\nWood (0,1,1)          0.8953588\nWood (0,1,1) w/ drift 0.8143552\nWood (1,1,1)          0.8689846\n\n\nThe best models for each river were selected by choosing the model with the lowest RMSE. The best model for the Kvichak was an ARIMA(0,0,1) with non zero mean, the best model for the Nushagak was ARIMA(0,1,1) with drift and the best model for the Wood was ARIMA(0,1,1) with drift."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#check-residuals-nick",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-1_final.html#check-residuals-nick",
    "title": "3  Team 1",
    "section": "8.6 Check residuals (Nick)",
    "text": "8.6 Check residuals (Nick)\nWe used the model with the lower RMSE moving forward.\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with non-zero mean\nQ* = 26.979, df = 9, p-value = 0.00141\n\nModel df: 1.   Total lags used: 10\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with non-zero mean\nQ* = 26.979, df = 9, p-value = 0.00141\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 18.363, df = 9, p-value = 0.03119\n\nModel df: 1.   Total lags used: 10\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 18.363, df = 9, p-value = 0.03119\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 11.626, df = 9, p-value = 0.2352\n\nModel df: 1.   Total lags used: 10\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 11.626, df = 9, p-value = 0.2352\n\nModel df: 1.   Total lags used: 10\n\n\nThe residuals for the Kvichak River are significantly auto-correlated even though only two lags show significance on the correlogram. The Nushagak also has significantly auto correlated residuals and only the Wood passes the Ljung-Box test for having non auto correlated residuals."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html",
    "title": "4  Team 2",
    "section": "",
    "text": "5 Lab 1: ARIMA models\nTeam member names: Eric French (Civil), Dylan Hubl (ESRM), Miranda Mudge (Molecular & Cell Bio)\nWe will be working with the Bristol Bay data set. Our focus will be on 4-year-old Sockeye in the Wood, Kvichak, and Ugashik regions.\nOur group decided to compare how accurate the forecasts of best fit ARIMA models were for the populations of 4 year old salmon (1.3 and 2.2 age groups) were in the Wood, Kvichak, and Ugashik regions of the Bristol Bay data. Our questions were the following:\nWe will fit ARIMA models to each region and age group and compare the model structures. Then compare the forecast results of each model and comment on the accuracy of each.\nWe examined if fish which spent longer in the ocean were more or less predictable than fish of the same age which spent less time in the ocean. We found in the Wood and Kvichak systems that models trained on data for four year old fish which spent longer in the ocean (3 years vs 2 years) made more accurate forecasts as indicated by smaller RMSE values.\nThe predictions for the Wood and Kvichak systems were straight line predictions as the models that were selected either only had a MA component or, in the case of the Wood 2.2 age group where the observations were considered white noise already, had neither and AR or MA component. In the Ugashik system, the models fitted both had AR components and thus we see the predicted mean line has a bit of structure to it as each prediction relies on the value of the previous prediction.\nWe found that in the Ugashik system, removing the data prior to 1980 to remove increased variance in the data improved predictions from the model. This could be a good step to investigate doing for the other river systems as well which also show some unusual activity prior to 1980.\nDylan wrote the code for the Wood and Kvichak regions, Miranda wrote the code for the Ugashik region, and Eric and Dylan wrote sections of the report with input continued from Miranda."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#initial-plan",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#initial-plan",
    "title": "4  Team 2",
    "section": "8.1 Initial plan",
    "text": "8.1 Initial plan\nUsing the forecast package, we plan to fit ARIMA models to the 1960-2010 data on 4 yr old fish in the Wood and Ugashik systems. Then forecast to 2020. We will separate the fish by time spent in freshwater and time in the ocean. These age groups are labeled 1.3 (1 year in freshwater, 3 years in the ocean) and 2.2 (2 years in freshwater, 2 years in the ocean). We will measure accuracy by the comparing the RMS error of each model."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#what-you-actually-did",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#what-you-actually-did",
    "title": "4  Team 2",
    "section": "8.2 What you actually did",
    "text": "8.2 What you actually did\nWe were able to enact our plan with a few modifications. Instead of modeling all the 4 year old salmon together, we separated and compared them by age group from the outset. Additionally, we added the Kvichak region to our analysis. We also examined the accuracy of the forecast if we removed the years prior to 1980 from the training data for the 1.3 age group in the Ugashik river. We did this as there was increased variance in the observed data if we included 1960 - 1980. We thought that removing the variance may improve the accuracy of the forecast, so we fit a second model to the data starting at the year 1980 and compared its forecast to the original model’s."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#plot-the-data",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#plot-the-data",
    "title": "4  Team 2",
    "section": "9.1 Plot the data",
    "text": "9.1 Plot the data\n\n9.1.1 Ugashik Region\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.1.2 Wood Region\n\n\n\n\n\n\n\n\n\n\n9.1.3 Kvichak Region\n\n\n\n\n\n\n\n\nUvashik: Upon observing the 1.3 time series, there is a clear outlier value at 1977. To remove the negative value, we re-plotted the data starting at 1980 instead of 1967. The new time series seems to show variance around a mean of 7. The 2.2 group appears to show variance around a mean of 5. Differencing the data will likely show stationarity\nWood: The 1.3 age group appears to have a positive trend, so it is likely not stationary. It could be stationary around a trend. The 2.2 age group does not seem to have any trends, and could be stationary around a mean of 4.\nKvichak: There is another negative outlier in the 1.3 age group, otherwise the data appears to be stationary around a mean of 7. We will have to see how much influence the outlier has on the ARIMA model. The 2.2 age group does not show any obvious trends and seems to be stationary around a mean of 7."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#testing-for-stationarity",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#testing-for-stationarity",
    "title": "4  Team 2",
    "section": "9.2 Testing for Stationarity",
    "text": "9.2 Testing for Stationarity\n\n9.2.1 Ugashik\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Ugashik_1.3.ts\nDickey-Fuller = -3.1174, Lag order = 3, p-value = 0.1236\nalternative hypothesis: stationary\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Ugashik_1.3.ts\nKPSS Level = 0.54744, Truncation lag parameter = 3, p-value = 0.03098\n\n\nWarning in tseries::kpss.test(Ugashik_1.3.ts, null = \"Trend\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Ugashik_1.3.ts\nKPSS Trend = 0.075997, Truncation lag parameter = 3, p-value = 0.1\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Ugashik_1.3.ts_out\nDickey-Fuller = -3.4337, Lag order = 3, p-value = 0.06582\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Ugashik_1.3.ts_out, null = \"Level\"): p-value\ngreater than printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Ugashik_1.3.ts_out\nKPSS Level = 0.26391, Truncation lag parameter = 3, p-value = 0.1\n\n\nWarning in tseries::kpss.test(Ugashik_1.3.ts_out, null = \"Trend\"): p-value\ngreater than printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Ugashik_1.3.ts_out\nKPSS Trend = 0.065518, Truncation lag parameter = 3, p-value = 0.1\n\n\n\n\n\n\n\n\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Ugashik_2.2.ts\nDickey-Fuller = -2.0383, Lag order = 3, p-value = 0.5592\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Ugashik_2.2.ts, null = \"Level\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Ugashik_2.2.ts\nKPSS Level = 0.21297, Truncation lag parameter = 3, p-value = 0.1\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Ugashik_2.2.ts\nKPSS Trend = 0.184, Truncation lag parameter = 3, p-value = 0.022\n\n\n\n\n\nStationairity test for the full Ugashik 1.3 group were in disagreement indicating that a single difference should be taken to get them to agree on stationairity. The same is true for the 2.2 group, we again see disagreement in the tests. The truncated dataset of the 1.3 group shows full agreement on non-stationairity. Thus a first difference needs to be taken on all of them.\n\n\n9.2.2 Wood\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Wood_1.3.ts\nDickey-Fuller = -3.1466, Lag order = 3, p-value = 0.1118\nalternative hypothesis: stationary\n\n\nWarning in tseries::adf.test(Wood_1.3.ts, k = 0): p-value smaller than printed\np-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Wood_1.3.ts\nDickey-Fuller = -6.5462, Lag order = 0, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Wood_1.3.ts, null = \"Level\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Wood_1.3.ts\nKPSS Level = 1.1774, Truncation lag parameter = 3, p-value = 0.01\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Wood_1.3.ts\nKPSS Trend = 0.14659, Truncation lag parameter = 3, p-value = 0.04951\n\n\n[1] 1\n\n\n[1] 0\n\n\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Wood_2.2.ts\nDickey-Fuller = -3.7358, Lag order = 3, p-value = 0.02957\nalternative hypothesis: stationary\n\n\nWarning in tseries::adf.test(Wood_2.2.ts, k = 0): p-value smaller than printed\np-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Wood_2.2.ts\nDickey-Fuller = -7.91, Lag order = 0, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Wood_2.2.ts, null = \"Level\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Wood_2.2.ts\nKPSS Level = 0.076509, Truncation lag parameter = 3, p-value = 0.1\n\n\nWarning in tseries::kpss.test(Wood_2.2.ts, null = \"Trend\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Wood_2.2.ts\nKPSS Trend = 0.058765, Truncation lag parameter = 3, p-value = 0.1\n\n\n[1] 0\n\n\n[1] 0\n\n\nThe Wood River 1.3 showed disagreement in the outcome of the stationairity tests this indicates that a difference is required to reach stationairity. The ndiff() function disagrees based on test used but the kpss test indicates a single differencing is required. In contrast the Wood River 2.2 group has full agreement from all tests for stationairity. The ndiff() function also indicates that no differencing is required for this dataset.\n\n\n9.2.3 Kvichak\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Kvichak_1.3.ts\nDickey-Fuller = -3.5126, Lag order = 3, p-value = 0.04835\nalternative hypothesis: stationary\n\n\nWarning in tseries::adf.test(Kvichak_1.3.ts, k = 0): p-value smaller than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Kvichak_1.3.ts\nDickey-Fuller = -7.0898, Lag order = 0, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Kvichak_1.3.ts, null = \"Level\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Kvichak_1.3.ts\nKPSS Level = 0.87527, Truncation lag parameter = 3, p-value = 0.01\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Kvichak_1.3.ts\nKPSS Trend = 0.16823, Truncation lag parameter = 3, p-value = 0.03147\n\n\n[1] 1\n\n\n[1] 0\n\n\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Kvichak_2.2.ts\nDickey-Fuller = -3.0401, Lag order = 3, p-value = 0.1548\nalternative hypothesis: stationary\n\n\nWarning in tseries::adf.test(Kvichak_2.2.ts, k = 0): p-value smaller than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  Kvichak_2.2.ts\nDickey-Fuller = -5.4257, Lag order = 0, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWarning in tseries::kpss.test(Kvichak_2.2.ts, null = \"Level\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  Kvichak_2.2.ts\nKPSS Level = 0.33673, Truncation lag parameter = 3, p-value = 0.1\n\n\nWarning in tseries::kpss.test(Kvichak_2.2.ts, null = \"Trend\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  Kvichak_2.2.ts\nKPSS Trend = 0.08168, Truncation lag parameter = 3, p-value = 0.1\n\n\n[1] 0\n\n\n[1] 0\n\n\nThe Kvichak 1.3 group showed disagreement between stationairity tests indicating that a differencing is needed. The ndiff() function also disagrees but that is a reflection of the difference between the results of the adf and kpss stationairity tests. A single difference is needed to get the tests into agreement. The Kvichak 2.2 group shows an interesting disagreement between the two adf tests and ndiff() is in agreement that no differencing is needed to reach stationairity which is interesting because the adf and kpss tests were in disagreement as well. We will examine the ACF and PACF plots of both a differenced and non-differenced Kvichak 2.2 group."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#acf-and-pacf",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#acf-and-pacf",
    "title": "4  Team 2",
    "section": "9.3 ACF and PACF",
    "text": "9.3 ACF and PACF\n\n9.3.1 Ugashik\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUgashik:\nThe PACF plot of the full differenced 1.3 age group tails off slowly, which indicates an MA() model. The ACF cuts off at 1, which further reinforces idea that this is an MA(1) model.\nThe truncated 1.3 group shows significance at a lag of 2 for both the ACF and a slow decay for the PACF. This again indicates that it will be an MA() model of MA(2)\nThe 2.2 age group has an ACF that looks like it may not have any significant lags besides the one at 5 which we are taking to indicate a cyclic nature to the data which again we will ignore in this experiment. The PACF looks to be a slow decline again. The model selection is a little more unclear in these plots.\n\n\n9.3.2 Wood\n\n\n\n\n\n\n\n\n\n\nWood:\nACF for the 1.3 data seems to cut off at 2. It also shows significance at lags of 5 and 10 which may indicate seasonality. The PACF appears to slowly taper off. This is likely an MA() model\nThe 2.2 age group does not show significance in either plot, so this is most likely white noise already.\n\n\n9.3.3 Kvichak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKvichak:\nThe ACF and PACF for the 1.3 group both showed a barely significant lag at 1. The stationairity tests for this dataset were in disagreement so we will look to see what differencing does. After differencing the ACF cuts off at 1 and the PACF seems to slowly taper. This data may be an ARIMA(0,1,1).\nThe 2.2 group does not show any patterns that line up with an AR or MA model. It may be an ARMA model of some sort."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#checking-residuals",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#checking-residuals",
    "title": "4  Team 2",
    "section": "9.4 Checking Residuals",
    "text": "9.4 Checking Residuals\n\n9.4.1 Ugashik\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with zero mean\nQ* = 4.5946, df = 9, p-value = 0.8681\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with zero mean\nQ* = 24.804, df = 8, p-value = 0.001678\n\nModel df: 0.   Total lags used: 8\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,2) with zero mean\nQ* = 12.936, df = 8, p-value = 0.1141\n\nModel df: 2.   Total lags used: 10\n\n\nThe Box tests for the residuals from the fitted models of Ugashik only reject the null hypothesis of non-autocorrelation for the truncated data. This may be a result of the cyclic nature of the salmon data. Tests for the full 1.3 and 2.2 datasets are good as they do not indicate autocorrelation in the residuals.\n\n\n9.4.2 Wood\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 14.665, df = 9, p-value = 0.1006\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 9.6642, df = 10, p-value = 0.4704\n\nModel df: 0.   Total lags used: 10\n\n\nBoth fitted models for the Wood River datasets pass the residuals check. Both fail to reject the null hypothesis of non-auto correlated residuals. Indicating the residuals are white noise.\n\n\n9.4.3 Kvichak\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 2.4224, df = 9, p-value = 0.9829\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with non-zero mean\nQ* = 32.184, df = 9, p-value = 0.0001851\n\nModel df: 1.   Total lags used: 10\n\n\nThe fitted model for the 1.3 dataset does fail to reject the null hypothesis of non-autocorrelation indicating the residuals are white noise. In contrast, the fitted model for the 2.2 dataset does reject the null hypothesis of non-autocorrelation. This is likely another reflection of the cyclic nature of the data."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#fit-models-to-the-training-data",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#fit-models-to-the-training-data",
    "title": "4  Team 2",
    "section": "9.5 Fit Models to the training data",
    "text": "9.5 Fit Models to the training data\n\n9.5.1 Ugashik\n\n\nSeries: train_Ugashik_1.3 \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.7305\ns.e.   0.1400\n\nsigma^2 = 18.34:  log likelihood = -134.93\nAIC=273.86   AICc=274.13   BIC=277.56\n\n\nSeries: train_Ugashik_1.3_out \nARIMA(2,0,0) with non-zero mean \n\nCoefficients:\n         ar1      ar2    mean\n      0.3818  -0.5662  6.9256\ns.e.  0.1506   0.1451  0.0890\n\nsigma^2 = 0.365:  log likelihood = -27.2\nAIC=62.41   AICc=63.94   BIC=68.14\n\n\nSeries: train_Ugashik_2.2 \nARIMA(1,0,0) with non-zero mean \n\nCoefficients:\n         ar1    mean\n      0.4545  5.9958\ns.e.  0.1268  0.3373\n\nsigma^2 = 1.753:  log likelihood = -80.67\nAIC=167.34   AICc=167.88   BIC=172.95\n\n\n\n\n9.5.2 Wood\n\n\nSeries: train.Wood_1.3 \nARIMA(0,1,1) \n\nCoefficients:\n          ma1\n      -0.7441\ns.e.   0.0919\n\nsigma^2 = 0.3482:  log likelihood = -41.8\nAIC=87.59   AICc=87.87   BIC=91.29\n\n\nSeries: train.Wood_2.2 \nARIMA(0,0,0) with non-zero mean \n\nCoefficients:\n        mean\n      4.6370\ns.e.  0.1742\n\nsigma^2 = 1.488:  log likelihood = -77.14\nAIC=158.29   AICc=158.56   BIC=162.03\n\n\n\n\n9.5.3 Kvichak\n\n\nSeries: train.Kvichak_1.3 \nARIMA(0,1,1) with drift \n\nCoefficients:\n          ma1   drift\n      -0.8462  0.1083\ns.e.   0.1057  0.0662\n\nsigma^2 = 6.13:  log likelihood = -108.91\nAIC=223.82   AICc=224.38   BIC=229.37\n\n\nSeries: train.Kvichak_2.2 \nARIMA(0,0,1) with non-zero mean \n\nCoefficients:\n         ma1    mean\n      0.3950  7.4654\ns.e.  0.1391  0.3395\n\nsigma^2 = 3.002:  log likelihood = -93.56\nAIC=193.11   AICc=193.66   BIC=198.73"
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#plotting-best-fit-results-and-determining-model-accuracy",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-2_final.html#plotting-best-fit-results-and-determining-model-accuracy",
    "title": "4  Team 2",
    "section": "10.1 Plotting Best Fit Results and Determining Model Accuracy",
    "text": "10.1 Plotting Best Fit Results and Determining Model Accuracy\n\n10.1.1 Ugashik 1.3, Starting from 1980\n\n\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(2,0,0) with non-zero mean\nQ* = 3.6115, df = 4, p-value = 0.4611\n\nModel df: 2.   Total lags used: 6\n\n\n                      ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set 0.003492142 0.5741439 0.4709198 -0.6636186 6.883224 0.6078635\nTest set     0.212738213 0.6585916 0.5680040  2.2757596 8.236443 0.7331798\n                    ACF1 Theil's U\nTraining set -0.03470095        NA\nTest set      0.09450154  0.877926\n\n\nThe model itself seems to fit the data well based on the visual fit and the residuals.\nThe model forecast centers around the mean of the train data, predicting that 2010 will drop which fits the first few actual data points well, but doesn’t do as good of a job of predicting that the data from 2015-2020 look closer to the more recent years than further out (prior to 2005). Data are included in the confidence interval though which is great.\n\n\n10.1.2 Ugashik 2.2\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 13.211, df = 9, p-value = 0.1533\n\nModel df: 1.   Total lags used: 10\n\n\n                       ME     RMSE       MAE       MPE     MAPE      MASE\nTraining set -0.001068187 1.295973 1.0706311 -6.326379 21.04040 0.8937811\nTest set     -0.314622455 1.051713 0.7971697 -9.454614 16.49798 0.6654909\n                    ACF1 Theil's U\nTraining set -0.01828833        NA\nTest set      0.31998321 0.9446332\n\n\nThe model fits the timeseries train data pretty well, matching the overall change in curve. The residuals show the ACF plot has 1 significant lag reflecting the ARIMA (1,0,0) model, the histogram is fairly centered as expected, and model fails to reject Ljung-Box test.\nModel forecast doesn’t look great. The forecast flatlines while the real data from 2011-2020 have much higher variance. This reflects the high AICc from the model. But the data are contained within the predicted confidence interval which is good. ### Wood 2.2\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 9.263, df = 10, p-value = 0.5073\n\nModel df: 0.   Total lags used: 10\n\n\n                       ME      RMSE       MAE         MPE     MAPE      MASE\nTraining set 2.309264e-14 1.2071244 0.9243868 -13.5400802 29.21208 0.6715881\nTest set     8.382150e-02 0.7310041 0.6710780  -0.6671193 14.53788 0.4875535\n                    ACF1 Theil's U\nTraining set -0.06265894        NA\nTest set     -0.33015036 0.6419835\n\n\nThe model fit the training data well as indicated by the Box test’s failure to reject the null hypothesis. The actual observations do fall within the 80% prediction interval This data is treated as white noise with the ARIMA(0,0,0) model so we predict the prediction intervals are tied very closely to the variance of the residuals themselves.The RMSE = 0.731\n\n\n10.1.3 Wood 1.3\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)\nQ* = 12.184, df = 9, p-value = 0.2032\n\nModel df: 1.   Total lags used: 10\n\n\n                     ME      RMSE       MAE       MPE     MAPE      MASE\nTraining set  0.1476159 0.5776702 0.4685250  1.486566 6.564567 0.8028471\nTest set     -0.4034734 0.5321656 0.4363825 -5.476881 5.876250 0.7477688\n                   ACF1 Theil's U\nTraining set -0.1061270        NA\nTest set     -0.1945305   1.02589\n\n\nAgain we see that the model fit the training dataset well. The box test fails to reject the null hypotheis. We see that the prediction intervals widen as the forecast moves forward likely due to the autocorrelation of the errors, because this is an MA(1) model, which the model has to estimate with each successive prediction. The fitted points are a flat line again because this is an MA(1) model, we would write the model as Xt = Xt-1 + error. When we fitted a model to the entire dataset, auto.arima() selected an ARIMA(0,1,1) with drift, however with just the training data auto.arima() selected an ARIMA(0,1,1) because the model does not have drift, the predictions stay as a flat line rather than having a trend.\nthe Root Mean Squared Error for this model is 0.532. This value is less than the value for the Wood_2.2 model. This is a bit surprising as they both put a straight line on the graph for predictions. These values indicate that the model for wood_1.3 was more accurate at predicting future observations. The returns of fish that spent less time in fresh water and longer in the ocean were more accurately predicted than of the fish who spent two years in both freshwater and the ocean.\n\n\n10.1.4 Kvichak 2.2\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,1) with non-zero mean\nQ* = 36.296, df = 9, p-value = 3.513e-05\n\nModel df: 1.   Total lags used: 10\n\n\n                       ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set  0.008535118 1.696210 1.414096  -6.374419 21.61987 0.8022279\nTest set     -0.649087674 2.088137 1.751880 -21.121893 33.24484 0.9938554\n                    ACF1 Theil's U\nTraining set -0.02884552        NA\nTest set      0.65396329   1.93424\n\n\nHere we see the cyclic nature of the data reflected in the residual’s ACF plot and the rejection of the Box test. This may have affected the model’s ability to predict. The RMSE = 2.088. The actual data points fell outside of the prediction intervals with this model. We observe the same straight line provided by the MA() model but there was more variance in this data which corresponds to the poor prediction performance ### Kvichak 1.3\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 1.9103, df = 9, p-value = 0.9928\n\nModel df: 1.   Total lags used: 10\n\n\n                     ME     RMSE      MAE       MPE      MAPE      MASE\nTraining set  0.1613506 2.397324 1.399125  7.802140 22.591779 0.9296851\nTest set     -0.4366868 0.650266 0.553364 -5.920379  7.288404 0.3676971\n                      ACF1 Theil's U\nTraining set -0.0007066869        NA\nTest set     -0.4030463679 0.7920795\n\n\nThe model fit the training data well again based on the failure to reject the Box test and did a good job forecasting future observation. The RMSE = 0.65 for this forecast’s accuracy, we see the prediction line with a positive trend which results because the model is ARIMA(0,1,1) with drift. Due to the smaller amount of variance in this data set the points fall much closer to the straight line prediction. Again we see that returns for fish that spent longer in the ocean were more accurately predicted in this system."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html",
    "title": "5  Team 3",
    "section": "",
    "text": "6 Team Members\nTeam member names: Zoe Rand (QERM), Madison Shipley (SAFS), Emma Timmins-Schiffman (Genome Sci)\nWe chose to work with all data to compare ability of the ARIMA models to forecast across different patterns of population dynamics and different sizes of training data sets.\nFor each species we will subset by region and test for stationarity. Then for forecast levels of 5, 10, and 20 years for each region, we will run auto-arima. We will look at forecasts and accuracy using RMSE to determine what level of for asting could be appropriate when considering management utility.\nWe will pick a couple of regions for each species to demonstrate ACF and PACF, and look through model results for any residuals.\nIt was harder to compare models across species and regions than we assumed. We created functions to help streamline this process. Also after researching forecast accuracy metrics, we decided to use MASE as a metric instead of RMSE. It was difficult to decipher why some regions were more easily forecasted and others returned unreliable results. Additionally, each species had different dynamics, and some variable methods were applied in order to find a model that worked.\nBecause of pink salmon life history, for regional models, models with even and odd years were considered separately.\nTo test stationarity outside the auto.arima function , the ADF and KPSS tests were compared for all years, and even and odd years. Note for the ADF null hypothesis is that the system is non-stationary (we want to reject), and the KPSS test null hypothesis is that there is stationarity.\nA complication is that the data sets split by even and odd years were not passing the tests of stationarity. Perhaps other steps should have been taken.\nNext step is to then define the regions\nLets look at the regional breakdowns of ACF and PACF, first for all years:\nThe ACFs for regions show different levels of lag or total correlation. Let’s look for even years:\nAnd then for odd years:\nThe next step is to look at the ARIMA models for regions by all years, even and odd years, and define forecast levels. Let’s start with all years.\nNow let’s consider even years.\nNow let’s consider odd years.\nNow, we’re extracting the MASE and creating our final model tables\nComparing the models across the three forecasts for SBC underlines that the data chosen for a forecast matters. Not only is the estimated ARIMA a better fit for a shorter forecast (and is trained on more data), but the training data for the model for the 20 year forecast is not stationary so the ARIMA parameters are very different from the parameters estimated for the 5 and 10 year forecasts.\nFor sockeye, six regions had at least one forecast with a well performing model (MASE < 1); however, six regions did not have MASE < 1 for even the 5 year forecast model. None of the 20 year forecasts resulted in MASE < 1. This suggests that our data are so stochastic that it is difficult to forecast more than 5 years into the future. Another hypothesis could be that the training data set isn’t long enough to generate a good model for the 20 year forecast, but from looking at the data we think the large inter-year variability in returns makes it difficult to fit an accurate model. In general, the models that fit the data better (lower MASE) tended to include differencing and were more likely to have higher order parameters.\nModels fit to Chum do better than models fit to Sockeye. There may be something about the patterns of chum population fluctuations that are more amenable to being modeled with ARIMA.\nModel fits to pink depended on data assumptions given their cyclic life history, and while the MASE results were lower than the other stock, ARIMA models are likely not the appropriate method for assessing or predicting pinnk returns with any level of certainty.\nAll team members helped decide on the goal and ran the analyses for the individual species and all regions. All team members wrote the code and created the results for one species. ZR researched approaches for measuring accuracy of forecasts and created functions to run the ARIMA models over multiple regions and select the best model (even if it was different than selected by auto.arima). ETS and MS modified this code to work with their own species. All team members helped write and edit the report."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#sockeye-combined-regions",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#sockeye-combined-regions",
    "title": "5  Team 3",
    "section": "10.1 Sockeye: Combined Regions",
    "text": "10.1 Sockeye: Combined Regions\nSubset and format the data to analyze just sockeye.\n\n\nCode\nSockByRegion<-ruggerone_data %>%\n  filter(region != \"japan\") %>%\n  filter(region != \"korea\") %>%\n  group_by(species, region, year) %>%\n  summarize(total = sum(returns, na.rm=TRUE)) %>% \n  mutate(lnreturns = log(total)) %>%\n  filter(species == \"sockeye\")\n\n\n`summarise()` has grouped output by 'species', 'region'. You can override using\nthe `.groups` argument.\n\n\nCreate a time series object and train the data on the first 59 years of data; forecast the last 5 years.\n\n\nCode\nsockeye.ts<-ts(SockByRegion$lnreturns, start=SockByRegion$year[1])\n\ntrain.sockeye<-window(sockeye.ts, start=1952, end=2010)\ntest.sockeye<-window(sockeye.ts, start=2011, end=2015)\n\n\nAssess the ACF and PACF of the training data set.\n\n\n\n\n\n\n\n\nLook at the options for fitting an ARIMA to the data and then choose a final model. The best model for both of these is ARIMA(0,1,2); however, a comparison with other models suggests that ARIMA(1,1,1) is also a good fit with AIC within 0.3 of the ARIMA(0,1,2). The full dataset requires differencing (d=1).\n\n\nCode\nfit <- forecast::auto.arima(train.sockeye, trace=T)\n\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 61.95027\n ARIMA(1,1,0) with drift         : 60.11204\n ARIMA(0,1,1) with drift         : 57.27974\n ARIMA(0,1,0)                    : 59.87487\n ARIMA(1,1,1) with drift         : Inf\n ARIMA(0,1,2) with drift         : 57.23854\n ARIMA(1,1,2) with drift         : Inf\n ARIMA(0,1,3) with drift         : Inf\n ARIMA(1,1,3) with drift         : Inf\n ARIMA(0,1,2)                    : 55.53198\n ARIMA(0,1,1)                    : 55.33664\n ARIMA(1,1,1)                    : 55.19379\n ARIMA(1,1,0)                    : 57.99975\n ARIMA(2,1,1)                    : 57.46972\n ARIMA(1,1,2)                    : 57.48549\n ARIMA(2,1,0)                    : 58.91271\n ARIMA(2,1,2)                    : Inf\n\n Best model: ARIMA(1,1,1)                    \n\n\nCode\nfit.final.sock<-forecast::auto.arima(train.sockeye, approximation = F, stepwise = F)\n\n\nPlot the 5 year forecast for the last part of the dataset compared to the actual data. The real data are represented by the black dots; the forecast is represented by the black line."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#assess-how-well-forecasting-performs-for-sockeye-returns-by-region",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#assess-how-well-forecasting-performs-for-sockeye-returns-by-region",
    "title": "5  Team 3",
    "section": "10.2 Assess how well forecasting performs for sockeye returns by region",
    "text": "10.2 Assess how well forecasting performs for sockeye returns by region\nCreate objects needed for plotting.\n\n\nCode\nregions<-unique(SockByRegion$region)\nregionskey<-c(\"Cook Inlet\", \"E. Kamchatka\", \"Kodiak\", \"Russia\", \"N.British Columbia\",\n              \"Prince William Sound\", \"S. Alaska Pen.\", \"S. British Columbia\", \"SE Alaska\", \"W. Kamchatka\", \"Washington\", \"W. Alaska\")\nnames(regionskey)<-regions\nforecastlevels<-c(5, 10, 20)\nAllcombs<-expand_grid(regions, forecastlevels)\n\n\nPlot ACF and PACF for each region.\n\n\nCode\nACFandPACF<-function(reg){\n  Sockdat<-SockByRegion %>% filter(region == reg)\n  #create time series\n  datts <- ts(Sockdat$lnreturns, start=Sockdat$year[1])\n  return(list(a = acf(datts, plot = FALSE), p = pacf(datts, plot = FALSE)))\n}\n\n\n\n\nCode\nDiagPlots<-lapply(regions, ACFandPACF)\nnames(DiagPlots)<-regions\n\n\nACF plots\n\n\n\n\n\nPACF plots\n\n\n\n\n\nFit ARIMA models to each region.\n\n\nCode\nFitModFunction<-function(reg, forelevel){\n  #filter region\n  Sockdat<-SockByRegion %>% filter(region == reg)\n  #create time series\n  datts <- ts(Sockdat$lnreturns, start=Sockdat$year[1]) #this assumes the first year in data is the start of the time series (they are in order) \n  cutoff<-2015-forelevel\n  train <- window(datts, 1952, cutoff)\n  test <- window(datts, cutoff+1, 2015)\n  \n  mod <- auto.arima(train)\n  \n  #testing to be sure that this is the best model (is the best mode the simplest if it is within 2 AIC values?)\n  trace <- capture.output({\n    # assign so it doesn't pollute the output\n    model <- auto.arima(datts, trace = TRUE)\n  })\n  con    <- textConnection(trace)\n  models <- read.table(con, sep=\":\")\n  close(con)\n  \n  #getting the \"best models\" that are within 2 AIC units\n  BestMods<-models%>% filter(row_number() != nrow(models)) %>% mutate(AIC = replace(V2, V2 == \"Inf\", 99999), AIC = as.numeric(AIC), DeltaAIC = AIC-min(AIC)) %>% filter(DeltaAIC <= 2.0)\n  for(i in 1:nrow(BestMods)){\n    BestMods$Mod[i]<-strsplit(strsplit(strsplit(BestMods$V1[i], \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n    BestMods$npar[i]<-sum(as.numeric(BestMods$Mod[i][[1]][c(1,3)]))\n    if(strsplit(strsplit(BestMods$V1[i], \"[(]\")[[1]][2], \"[)]\")[[1]][2] == \" with drift         \"){\n      BestMods$npar[i] = BestMods$npar[i] + 1\n    }\n  }\n  \n  New<-BestMods %>% filter(npar == min(npar))\n  if(0 %in% New$DeltaAIC){\n      #auto arima picked the best model\n      res<-accuracy(forecast(mod, h=forelevel), test)[2,\"MASE\"] #test set MASE\n  }else{\n      #of the models with the fewest parameters, pick the lowest AIC\n      newmod<-New %>% filter(AIC == min(AIC)) %>% select(Mod)\n      mod<-Arima(train, order = as.numeric(strsplit(newmod$Mod[[1]], \"[,]\")), include.constant = TRUE)\n      res<-accuracy(forecast(mod, h=forelevel), test)[2,\"MASE\"] #test set MASE\n    }\n\n  return(list(Fit = mod, MASE = res, Bm = BestMods)) #include best mods for testing to see that it's doing what I want\n}\nRegionModsSock<-mapply(FitModFunction, Allcombs$regions, Allcombs$forecastlevels, SIMPLIFY = FALSE)\n\n\nExtract MASE for comparisons of models across regions.\n\n\nCode\nRegionMASESock<-sapply(RegionModsSock, function(x){y<-x$MASE})\nRegionBestModSock<-sapply(RegionModsSock, function(x){y<-as.character(x$Fit)})\n\nResultsTableSock<-Allcombs %>% add_column(Model = RegionBestModSock, MASE = RegionMASESock)\n\n\nHow well does auto.arima do in choosing a model? Is it different from what we would choose looking at ACF and PACF? For Cook Inlet, auto.arima selected ARIMA(4,1,1), but PACF has a significant lag at 6 and ACF trails off.\n\n\nCode\nsock.ci<-subset(SockByRegion, region=='ci')\nci.ts<-ts(sock.ci$lnreturns, start=sock.ci$year[1])\nforecast::ndiffs(ci.ts, test='adf')\n\n\n[1] 1\n\n\nCode\nforecast::ndiffs(ci.ts, test='kpss')\n\n\n[1] 1\n\n\nCode\ntrain.ci5<-window(ci.ts, start=1952, end=2010)\ntest.ci5<-window(ci.ts, start=2011, end=2015)\nci.final5<-forecast::auto.arima(train.ci5, approximation = F, stepwise = F)\naccuracy(forecast(ci.final5, h=5), test.ci5)\n\n\n                     ME      RMSE       MAE       MPE     MAPE      MASE\nTraining set 0.02471079 0.3370305 0.2702999 -38.06705 62.87923 0.8967555\nTest set     0.34919358 0.4082214 0.3491936  17.84353 17.84353 1.1584957\n                     ACF1 Theil's U\nTraining set  0.008040561        NA\nTest set     -0.080588177  1.829245\n\n\nCode\n#MASE is just above 1\n\nacf(train.ci5)\n\n\n\n\n\nCode\npacf(train.ci5)\n\n\n\n\n\nCode\n#select ARIMA (6,1,0)\nfit.ci2 <- Arima(train.ci5, order=c(6,1,0), include.mean=TRUE)\naccuracy(forecast(fit, h=5), test.ci5)\n\n\n                     ME      RMSE       MAE       MPE     MAPE      MASE\nTraining set 0.03439583 0.3641608 0.2787817 -40.97753 65.59960 0.9248951\nTest set     0.29776606 0.3308204 0.2977661  15.30517 15.30517 0.9878781\n                     ACF1 Theil's U\nTraining set -0.007356741        NA\nTest set      0.206715703  1.669537\n\n\nCode\n#MASE is very high for the test set.\n\n\nHere are the plots comparing the two models for Cook Inlet. The plots look very similar, but the forecast differs a bit for the last 2 years."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#chum-regional",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#chum-regional",
    "title": "5  Team 3",
    "section": "10.3 Chum: Regional",
    "text": "10.3 Chum: Regional\nLooking at data:\n\n\n\n\n\nGetting a subset of the data (removing regions with no data):\n\n\nCode\n#removing Korea Japan because there's no data\nChumByRegion<-ruggerone_data %>%\n  filter(region != \"japan\") %>%\n  filter(region != \"korea\") %>%\n  group_by(species, region, year) %>%\n  summarize(total = sum(returns, na.rm=TRUE)) %>% \n  mutate(lnreturns = log(total)) %>%\n  filter(species == \"chum\")\n\n\n`summarise()` has grouped output by 'species', 'region'. You can override using\nthe `.groups` argument.\n\n\nCode\nhead(ChumByRegion)\n\n\n# A tibble: 6 × 5\n# Groups:   species, region [1]\n  species region  year total lnreturns\n  <chr>   <chr>  <dbl> <dbl>     <dbl>\n1 chum    ci      1952 1.25     0.226 \n2 chum    ci      1953 1.44     0.363 \n3 chum    ci      1954 1.93     0.656 \n4 chum    ci      1955 0.957   -0.0436\n5 chum    ci      1956 2.11     0.748 \n6 chum    ci      1957 2.76     1.01  \n\n\n\n\nCode\n#making sure all the regions cover all the years (or at least start and end)\nChumByRegion %>% group_by(region) %>% summarise(startyear = min(year), endyear = max(year))\n\n\n# A tibble: 12 × 3\n   region startyear endyear\n   <chr>      <dbl>   <dbl>\n 1 ci          1952    2015\n 2 e_kam       1952    2015\n 3 kod         1952    2015\n 4 m_i         1952    2015\n 5 nbc         1952    2015\n 6 pws         1952    2015\n 7 s_pen       1952    2015\n 8 sbc         1952    2015\n 9 seak        1952    2015\n10 w_kam       1952    2015\n11 wa          1952    2015\n12 wak         1952    2015\n\n\nCode\n#all start in 1952 and end in 2015\n\n\nCreating tibble to loop through:\n\n\nCode\n#regions vector\nregions<-unique(ChumByRegion$region)\n#regions key\nregionskey<-c(\"Cook Inlet\", \"E. Kamchatka\", \"Kodiak\", \"Russia\", \"N.British Columbia\",\n              \"Prince William Sound\", \"S. Alaska Pen.\", \"S. British Columbia\", \"SE Alaska\", \"W. Kamchatka\", \"Washington\", \"W. Alaska\")\nnames(regionskey)<-regions #for plotting\n#forecast levels\nforecastlevels<-c(5, 10, 20)\n#all combinations\nAllcombs<-expand_grid(regions, forecastlevels)\n\n\nFunction for ACF and PACF\n\n\nCode\n#ACF and PACF\nACFandPACF<-function(reg){\n  Chumdat<-ChumByRegion %>% filter(region == reg)\n  #create time series\n  datts <- ts(Chumdat$lnreturns, start=Chumdat$year[1])\n  return(list(a = acf(datts, plot = FALSE), p = pacf(datts, plot = FALSE)))\n}\n#loop through regions/levels\nDiagPlots<-lapply(regions, ACFandPACF)\nnames(DiagPlots)<-regions\n\n\n\n\nCode\n#ACF plots for each region\npar(mfrow=c(3,4))\nfor(r in 1:length(regions)){\n  plot(DiagPlots[[r]][[1]], main = paste0(\"Region: \", regionskey[r]))\n}\n\n\n\n\n\nCode\n#PACF plots for each region\npar(mfrow=c(3,4))\nfor(r in 1:length(regions)){\n  plot(DiagPlots[[r]][[2]], main = paste0(\"Region: \", regionskey[r]))\n}\n\n\n\n\n\n\n\nCode\n#function for ARIMA models\nFitModFunction<-function(reg, forelevel){\n  #This function takes a region and forecast level, subsets the data according to these parameters, then sets up the time series object, and the test and train sets. It uses auto.arima to find the \"best\" model and then this is checked by comparing other models with DeltaAICc < 2 and the number of parameters. If auto.arima picked a the model with the lowest AIC and the fewest parameters, it forecasts using this model and checks forecast accuracy with MASE. If not, it refits the model using Arima and the simpler model, and then checks forecast accuracy with this.\n  #filter region\n  Chumdat<-ChumByRegion %>% filter(region == reg)\n  #create time series\n  datts <- ts(Chumdat$lnreturns, start=Chumdat$year[1]) #this assumes the first year in data is the start of the time series (they are in order) \n  cutoff<-2015-forelevel\n  train <- window(datts, 1952, cutoff)\n  test <- window(datts, cutoff+1, 2015)\n  \n  mod <- auto.arima(train)\n  \n  #testing to be sure that this is the best model (is the best mode the simplest if it is within 2 AIC values?)\n  trace <- capture.output({\n    # assign so it doesn't pollute the output\n    model <- auto.arima(datts, trace = TRUE)\n  })\n  con    <- textConnection(trace)\n  models <- read.table(con, sep=\":\")\n  close(con)\n  \n  #getting the \"best models\" that are within 2 AIC units\n  BestMods<-models%>% filter(row_number() != nrow(models)) %>% mutate(AIC = replace(V2, V2 == \"Inf\", 99999), AIC = as.numeric(AIC), DeltaAIC = AIC-min(AIC)) %>% filter(DeltaAIC <= 2.0)\n  for(i in 1:nrow(BestMods)){\n    BestMods$Mod[i]<-strsplit(strsplit(strsplit(BestMods$V1[i], \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n    BestMods$npar[i]<-sum(as.numeric(BestMods$Mod[i][[1]][c(1,3)]))\n    if(strsplit(strsplit(BestMods$V1[i], \"[(]\")[[1]][2], \"[)]\")[[1]][2] == \" with drift         \"){\n      BestMods$npar[i] = BestMods$npar[i] + 1\n    }\n  }\n  \n  New<-BestMods %>% filter(npar == min(npar))\n  if(0 %in% New$DeltaAIC){\n      #auto arima picked the best model\n      res<-accuracy(forecast(mod, h=forelevel), test)[2,\"MASE\"] #test set MASE\n  }else{\n      #of the models with the fewest parameters, pick the lowest AIC\n      newmod<-New %>% filter(AIC == min(AIC)) %>% select(Mod)\n      mod<-Arima(train, order = as.numeric(strsplit(newmod$Mod[[1]], \"[,]\")), include.constant = TRUE)\n      res<-accuracy(forecast(mod, h=forelevel), test)[2,\"MASE\"] #test set MASE\n    }\n\n  return(list(Fit = mod, MASE = res, Bm = BestMods)) #include best mods for testing to see that it's doing what I want\n}\n\n\n\n\nCode\nRegionModsChum<-mapply(FitModFunction, Allcombs$regions, Allcombs$forecastlevels, SIMPLIFY = FALSE)\n\n\n\n\nCode\nRegionMASEChum<-sapply(RegionModsChum, function(x){y<-x$MASE})\nRegionBestModChum<-sapply(RegionModsChum, function(x){y<-as.character(x$Fit)})\n#combine into tables\nResultsTableChum<-Allcombs %>% add_column(Model = RegionBestModChum, MASE = RegionMASEChum)\nknitr::kable(head(ResultsTableChum))\n\n\n\n\n\nregions\nforecastlevels\nModel\nMASE\n\n\n\n\nci\n5\nARIMA(1,1,1)\n0.4232248\n\n\nci\n10\nARIMA(1,1,1)\n0.3650863\n\n\nci\n20\nARIMA(0,0,2) with non-zero mean\n1.3678453\n\n\ne_kam\n5\nARIMA(1,0,0) with non-zero mean\n2.0352335\n\n\ne_kam\n10\nARIMA(1,0,0) with non-zero mean\n1.6504750\n\n\ne_kam\n20\nARIMA(1,0,0) with non-zero mean\n1.4845904"
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#pink-combined-regions",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#pink-combined-regions",
    "title": "5  Team 3",
    "section": "10.4 Pink: Combined Regions",
    "text": "10.4 Pink: Combined Regions\nSubset the data to look at pink salmon only.\n\n\nCode\n#Filter by species (Pink)\ndat <- ruggerone_data %>%  \n  filter(species==\"pink\" & region==\"ci\") %>% \n  mutate(log.returns = log(returns)) %>% \n  select(year, log.returns)\n\n\nPlot the data\n\n\nCode\n#Plot by region\nruggerone_data %>% \n  filter(species==\"pink\") %>% \n  ggplot(aes(x=year, y=log(returns))) + \n  geom_line() + \n  ggtitle(\"pink salmon log abundance by region\") +\n  facet_wrap(~region)\n\n\n\n\n\nNote that there is no data in Korea, and WA has a lot of 0 values and very low returns. We will filter these regions out. All 0 values (-Inf in log space) were removed.\n\n\nCode\nPinkByRegion<-ruggerone_data %>%\n  filter(region != \"korea\") %>% \n  filter(region != \"wa\") %>%#Remove WA too, it's trouble \n  group_by(species, region, year) %>%\n  summarize(total = sum(returns, na.rm=TRUE)) %>% \n  mutate(lnreturns = log(total)) %>%\n  mutate(lnreturns = ifelse(lnreturns == -Inf, NA, lnreturns)) %>%\n  filter(species == \"pink\")%>% \n  print(n=5)\n\n\n`summarise()` has grouped output by 'species', 'region'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 768 × 5\n# Groups:   species, region [12]\n  species region  year total lnreturns\n  <chr>   <chr>  <dbl> <dbl>     <dbl>\n1 pink    ci      1952  4.36     1.47 \n2 pink    ci      1953  1.30     0.264\n3 pink    ci      1954  4.67     1.54 \n4 pink    ci      1955  2.67     0.981\n5 pink    ci      1956  3.57     1.27 \n# ℹ 763 more rows\n\n\nIdentify start and end years for each region.\n\n\nCode\nPinkByRegion %>% group_by(region) %>% summarise(startyear = min(year), endyear = max(year))\n\n\n# A tibble: 12 × 3\n   region startyear endyear\n   <chr>      <dbl>   <dbl>\n 1 ci          1952    2015\n 2 e_kam       1952    2015\n 3 japan       1952    2015\n 4 kod         1952    2015\n 5 m_i         1952    2015\n 6 nbc         1952    2015\n 7 pws         1952    2015\n 8 s_pen       1952    2015\n 9 sbc         1952    2015\n10 seak        1952    2015\n11 w_kam       1952    2015\n12 wak         1952    2015\n\n\nThe next step is to ID Stationarity with all the pink data. Lets plot the data in aggregate.\n\n\nCode\nPinkByRegion %>%\n  group_by(year) %>%\n  summarize(total = sum(total, na.rm=T)) %>%\n  ggplot(aes(x=year, y=log(total))) +\n  geom_line() +\n  ylab('Log (Returns)') +\n  xlab('Year')\n\n\n\n\n\nNext, a time series object was created and we look at the ACF and PACF\n\n\nCode\ntotal.pink<-PinkByRegion %>%\n  group_by(year) %>%\n  summarize(lntotal=log(sum(total, na.rm=T)))\n\npink.ts<-ts(total.pink$lntotal, \n            start=total.pink$year[1])\nplot(diff(pink.ts)) #something odd happened between 1990 and 2005\n\n\n\n\n\nCode\nacf(diff(pink.ts)) #ruh roh, ACF correlation for entire series \n\n\n\n\n\nThe ACF looks like there is a lot of corelation, that’s probably because Pinks have a very consistent two year cycle.\nLet’s try a forecast model to see what happens.\n\n\nCode\n#Let's train and test with a 10 year period\ntrain.pink<-window(pink.ts, start=1952, end=2005)\ntest.pink<-window(pink.ts, start=2006, end=2015)\n\nfit <- forecast::auto.arima(train.pink, trace=T)\n\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 44.48651\n ARIMA(1,1,0) with drift         : -0.8966894\n ARIMA(0,1,1) with drift         : 18.15923\n ARIMA(0,1,0)                    : 42.45004\n ARIMA(2,1,0) with drift         : -1.222687\n ARIMA(3,1,0) with drift         : -2.155628\n ARIMA(4,1,0) with drift         : 0.3831016\n ARIMA(3,1,1) with drift         : 0.2902468\n ARIMA(2,1,1) with drift         : Inf\n ARIMA(4,1,1) with drift         : Inf\n ARIMA(3,1,0)                    : -4.270823\n ARIMA(2,1,0)                    : -3.360303\n ARIMA(4,1,0)                    : -1.841485\n ARIMA(3,1,1)                    : -1.889482\n ARIMA(2,1,1)                    : Inf\n ARIMA(4,1,1)                    : 0.4019518\n\n Best model: ARIMA(3,1,0)                    \n\n\nCode\nfit.final.pink<-forecast::auto.arima(train.pink, approximation = F, stepwise = F)\n\n#30 year forcast, not so believeable\nfit.final.pink %>%\n  forecast(h=15) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.pink))\n\n\n\n\n\nThe best model was the ARIMA(3,1,0), but the forecast doesn’t look particularly great.\nGiven the life history of pink salmon, let’s parse the data set into two pieces, even and odd years.\n\n\nCode\n#Even Years: Totals \nPinkByRegion_even<-PinkByRegion %>% \n  filter(year %% 2 == 0)\n\n#Odd Years: Totals \nPinkByRegion_odd<-PinkByRegion %>% \n  filter(year %% 2 == 1)\n\n#Trends\nPinkByRegion_even %>%\n  group_by(year) %>%\n  summarize(total = sum(total, na.rm=T)) %>%\n  ggplot(aes(x=year, y=log(total))) +\n  geom_line() +\n  ylab('Log (Returns)') +\n  xlab('Year') +\n  ggtitle('Total Pinks (Even Years)')\n\n\n\n\n\nCode\nPinkByRegion_odd %>%\n  group_by(year) %>%\n  summarize(total = sum(total, na.rm=T)) %>%\n  ggplot(aes(x=year, y=log(total))) +\n  geom_line() +\n  ylab('Log (Returns)') +\n  xlab('Year') +\n  ggtitle('Total Pinks (Odd Years)')\n\n\n\n\n\nLet’s look at the ACF and PACF for even years:\n\n\nCode\n#Even Years -- Total\ntotal.pink_even<-PinkByRegion_even %>%\n  group_by(year) %>%\n  summarize(lntotal=log(sum(total, na.rm=T)))\n\npink.ts_even<-ts(total.pink_even$lntotal, \n            start=total.pink$year[1], frequency = 0.5)\nplot(diff(pink.ts_even)) #Looks pretty stationary\n\n\n\n\n\nCode\nacf(diff(pink.ts_even)) #This looks much better\n\n\n\n\n\nThe differences and the ACF plots here look better than the aggregate data set. Let’s look at a forcast.\n\n\nCode\n#Train and test for a 10 year period\ntrain.pink_even<-window(pink.ts_even, start=1952, end=2004)\ntest.pink_even<-window(pink.ts_even, start=2006, end=2014)\n\nfit <- forecast::auto.arima(train.pink_even, trace=T)\n\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 2.346942\n ARIMA(1,1,0) with drift         : 4.419114\n ARIMA(0,1,1) with drift         : 4.222938\n ARIMA(0,1,0)                    : 0.1554815\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(0,1,0)                    \n\n\nCode\nfit.final.pink_even<-forecast::auto.arima(train.pink_even, approximation = F, stepwise = F)\n\nfit.final.pink_even %>%\n  forecast(h=15) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.pink_even))\n\n\n\n\n\nCode\n#That is a straight line..... not very good.....\n\n\nThe best model was the ARIMA(0,1,0) model. But the forcast doesn’t capture the trend.\nLet’s repeat the next steps for odd years.\n\n\nCode\n#Odd Years -- Total\n\ntotal.pink_odd<-PinkByRegion_odd %>%\n  group_by(year) %>%\n  summarize(lntotal=log(sum(total, na.rm=T)))\n\npink.ts_odd<-ts(total.pink_odd$lntotal, \n                 start=total.pink_odd$year[1], frequency = 0.5)\nplot(diff(pink.ts_odd)) #Looks pretty stationary\n\n\n\n\n\nCode\nacf(diff(pink.ts_odd)) #This also looks better\n\n\n\n\n\nThese look stationary and the ACF looks better.\n\n\nCode\n#Train and test for a 10 year period\ntrain.pink_odd<-window(pink.ts_odd, start=1953, end=2005)\ntest.pink_odd<-window(pink.ts_odd, start=2007, end=2015)\n\nfit <- forecast::auto.arima(train.pink_odd, trace=T)\n\n\n\n ARIMA(2,1,2) with drift         : Inf\n ARIMA(0,1,0) with drift         : 4.01998\n ARIMA(1,1,0) with drift         : 5.551776\n ARIMA(0,1,1) with drift         : 4.461601\n ARIMA(0,1,0)                    : 1.771054\n ARIMA(1,1,1) with drift         : Inf\n\n Best model: ARIMA(0,1,0)                    \n\n\nCode\nfit.final.pink_odd<-forecast::auto.arima(train.pink_odd, approximation = F, stepwise = F)\n\nfit.final.pink_odd %>%\n  forecast(h=15) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.pink_odd))\n\n\n\n\n\nThe best model was the ARIMA(0,1,0) model. But the forcast for only odd years also doesn’t capture the trend."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#sockeye",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#sockeye",
    "title": "5  Team 3",
    "section": "12.1 Sockeye:",
    "text": "12.1 Sockeye:\nPlot MASE for three different forecast periods - 5, 10, and 20 years - across all regions. MASE < 1 is a “good” value.\n\n\n\n\n\nNone of the ARIMA models performed well for the forecasts of 20 years of data. Below is a comparison of the three lengths of forecasted data for South British Columbia where MASE was below 1 for the 5 year forecast but >1 for the 10 and 20 year forecasts.\n\n\nCode\nsock.sbc<-subset(SockByRegion, region=='sbc')\nsbc.ts<-ts(sock.sbc$lnreturns, start=sock.sbc$year[1])\n#create training and test datasets for the 5, 10, and 20 year forecasts\ntrain.sbc5<-window(sbc.ts, start=1952, end=2010)\ntest.sbc5<-window(sbc.ts, start=2011, end=2015)\nsbc.final5<-forecast::auto.arima(train.sbc5, approximation = F, stepwise = F)\n\ntrain.sbc10<-window(sbc.ts, start=1952, end=2005)\ntest.sbc10<-window(sbc.ts, start=2006, end=2015)\nsbc.final10<-forecast::auto.arima(train.sbc10, approximation = F, stepwise = F)\n\ntrain.sbc20<-window(sbc.ts, start=1952, end=1995)\ntest.sbc20<-window(sbc.ts, start=1996, end=2015)\nsbc.final20<-forecast::auto.arima(train.sbc20, approximation = F, stepwise = F)\n\n\nHere are plots of the three forecast scenarios for sockeye in South British Columbia.\n\n\n\n\n\n\n\n\n\n\n\nLooking at stationarity:\n\n\nCode\nNdiff<-sapply(RegionBestModSock, function(x){\n  a<-strsplit(strsplit(strsplit(x, \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n  return(a[[1]][2])}\n)\n\ntibble(Ndiff = Ndiff, region = Allcombs$regions, level = Allcombs$forecastlevels) %>%\n  ggplot() + geom_bar(aes(x = region, y = Ndiff, fill = as.factor(level)), stat = \"identity\", position = \"dodge\") +\n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\", y = \"Number of Differences\") + \n  ggtitle(\"Number of differences to achieve stationarity (Sockeye)\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nFor Sockeye, 6 regions required differencing for all of the three subsets of the data (3 forecasting levels). Two regions required differencing for one subset of the data; four regions were stationary at any level of subsetting.\nNone of the regional models for the 5-year forecast had autocorrelation in the residuals based on the results of the Ljung-Box test (p-value > 0.05)."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#chum",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#chum",
    "title": "5  Team 3",
    "section": "12.2 Chum:",
    "text": "12.2 Chum:\n\n\nCode\nggplot(ResultsTableChum) + \n  geom_bar(aes(x = regions, y = MASE, fill = as.factor(forecastlevels)), stat = \"identity\", position = \"dodge\") + \n  geom_hline(aes(yintercept = 1), linetype = \"dashed\") + \n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\") + \n  ggtitle(\"Chum\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nMany of the 5 and 10 year forecasts for Chum seem to perform well across regions. Models fit to data in Russia do the worst at forecasting in that region. Additionally, forecasts are poor across the different numbers of years tested in E. Kamachatka, SE Alaska and W. Kamachatka.\n20 year forecast for Kodiak:\n\n\nCode\nchum.kod<-subset(ChumByRegion, region=='kod')\nchum.ts<-ts(chum.kod$lnreturns, start=chum.kod$year[1])\n#test datasets for plotting\ntest.kod20<-window(chum.ts, start=1996, end=2015)\nforecast(RegionModsChum[[9]]$Fit, h = 20) %>% autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.kod20))\n\n\n\n\n\n10 year forecast for Russia:\n\n\nCode\nchum.russ<-subset(ChumByRegion, region=='m_i')\nchum.ts<-ts(chum.russ$lnreturns, start=chum.russ$year[1])\n#test datasets for plotting\ntest.russ10<-window(chum.ts, start=2006, end=2015)\nforecast(RegionModsChum[[11]]$Fit, h = 10) %>% autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.russ10))\n\n\n\n\n\nIt looks like returns really increase at the end of the time series in this region, which is likely why ARIMA models don’t forecast this well.\nLooking at stationarity:\n\n\nCode\nNdiff<-sapply(RegionBestModChum, function(x){\n  a<-strsplit(strsplit(strsplit(x, \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n  return(a[[1]][2])}\n)\n\ntibble(Ndiff = Ndiff, region = Allcombs$regions, level = Allcombs$forecastlevels) %>%\n  ggplot() + geom_bar(aes(x = region, y = Ndiff, fill = as.factor(level)), stat = \"identity\", position = \"dodge\") +\n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\", y = \"Number of Differences\") + \n  ggtitle(\"Number of differences to achieve stationarity (Chum)\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nFor Chum, time series for 5 of the regions were stationary (using tests from auto.arima) and 7 required 1 difference to be stationary.\nThere was significant autocorrelation (based on Ljung-Box test) in 4 of the regional models for Chum:\n\n\nCode\nac_mods_chum<-c(26, 27, 31, 32) #indexes of models with autocorrelated residuals\nfor(i in 1:length(ac_mods_chum)){\n  print(paste(regionskey[ResultsTableChum$regions[ac_mods_chum[i]]], ResultsTableChum$forecastlevels[ac_mods_chum[i]]))\n  checkresiduals(RegionModsChum[[ac_mods_chum[i]]]$Fit)\n}\n\n\n[1] \"SE Alaska 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 25.498, df = 9, p-value = 0.002467\n\nModel df: 1.   Total lags used: 10\n\n[1] \"SE Alaska 20\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,0) with non-zero mean\nQ* = 15.578, df = 8, p-value = 0.04884\n\nModel df: 1.   Total lags used: 9\n\n[1] \"NA 5\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)\nQ* = 35.287, df = 9, p-value = 5.302e-05\n\nModel df: 1.   Total lags used: 10\n\n[1] \"NA 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)\nQ* = 34.843, df = 9, p-value = 6.35e-05\n\nModel df: 1.   Total lags used: 10\n\n\nThis suggests that ARIMA models may not be the best fit in this instance."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#pink",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-3_final.html#pink",
    "title": "5  Team 3",
    "section": "12.3 Pink:",
    "text": "12.3 Pink:\nPlot MASE for three different forecast periods - 5, 10, and 20 years - across all regions. MASE < 1 is a “good” value.\n\n\nCode\n#All Years\nggplot(ResultsTable) + \n  geom_bar(aes(x = regions, y = MASE, fill = as.factor(forecastlevels)), stat = \"identity\", position = \"dodge\") + \n  geom_hline(aes(yintercept = 1), linetype = \"dashed\") + \n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\") + \n  ggtitle(\"Pinks all Years\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nCode\n#Even Years \nggplot(ResultsTable_even) + \n  geom_bar(aes(x = regions, y = MASE, fill = as.factor(forecastlevels)), stat = \"identity\", position = \"dodge\") + \n  geom_hline(aes(yintercept = 1), linetype = \"dashed\") + \n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\") + \n  ggtitle(\"Pinks Even Years\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nCode\n#Odd Years \nggplot(ResultsTable_odd) + \n  geom_bar(aes(x = regions, y = MASE, fill = as.factor(forecastlevels)), stat = \"identity\", position = \"dodge\") + \n  geom_hline(aes(yintercept = 1), linetype = \"dashed\") + \n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\") + \n  ggtitle(\"Pinks Odd Years\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nDespite the MASE fits seeming pretty good for the pink model runs some of the forecasts were underwhelming. Two regions were considered for forcasts, Cook Inlet, and SE Alaska with models that included for all years, even years, and odd years.\nThe first region, Cook Inlet, performed poorly (relative to some of the other regions) when looking at MASE values.\n\n\nCode\n#Cook Inlet\n#----------------------------------------------------\n#All Years\npink.ci<-subset(PinkByRegion, region=='ci')\nci.ts<-ts(pink.ci$lnreturns, start=pink.ci$year[1], frequency = 1)\n\n#create training and test datasets for the 5 year forecast \ntrain.ci5<-window(ci.ts, start=1952, end=2010)\ntest.ci5<-window(ci.ts, start=2011, end=2015)\nci.final5<-forecast::auto.arima(train.ci5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.ci10<-window(ci.ts, start=1952, end=2005)\ntest.ci10<-window(ci.ts, start=2006, end=2015)\nci.final10<-forecast::auto.arima(train.ci10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.ci20<-window(ci.ts, start=1952, end=1995)\ntest.ci20<-window(ci.ts, start=1996, end=2015)\nci.final20<-forecast::auto.arima(train.ci20, approximation = F, stepwise = F)\n\n#------------------------------\n#Even Years\npink.ci_even<-subset(PinkByRegion_even, region=='ci')\nci.ts_even<-ts(pink.ci_even$lnreturns, start=pink.ci_even$year[1], frequency = 0.5)\n\n#create training and test datasets for the 5 year forecast \ntrain.ci_even5<-window(ci.ts_even, start=1952, end=2010)\ntest.ci_even5<-window(ci.ts_even, start=2011, end=2014)\nci_even.final5<-forecast::auto.arima(train.ci_even5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.ci_even10<-window(ci.ts_even, start=1952, end=2005)\ntest.ci_even10<-window(ci.ts_even, start=2006, end=2014)\nci_even.final10<-forecast::auto.arima(train.ci_even10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.ci_even20<-window(ci.ts_even, start=1952, end=1995)\ntest.ci_even20<-window(ci.ts_even, start=1996, end=2014)\nci_even.final20<-forecast::auto.arima(train.ci_even20, approximation = F, stepwise = F)\n\n#------------------------------\n#Odd Years\npink.ci_odd<-subset(PinkByRegion_odd, region=='ci')\nci.ts_odd<-ts(pink.ci_odd$lnreturns, start=pink.ci_odd$year[1], frequency = 0.5)\n\n#create training and test datasets for the 5 year forecast \ntrain.ci_odd5<-window(ci.ts_odd, start=1953, end=2009)\ntest.ci_odd5<-window(ci.ts_odd, start=2011, end=2015)\nci_odd.final5<-forecast::auto.arima(train.ci_odd5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.ci_odd10<-window(ci.ts_odd, start=1953, end=2005)\ntest.ci_odd10<-window(ci.ts_odd, start=2007, end=2015)\nci_odd.final10<-forecast::auto.arima(train.ci_odd10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.ci_odd20<-window(ci.ts_odd, start=1953, end=1995)\ntest.ci_odd20<-window(ci.ts_odd, start=1997, end=2015)\nci_odd.final20<-forecast::auto.arima(train.ci_odd20, approximation = F, stepwise = F)\n\n\nLet’s look at forcast plots for the best performing models that consider all data, even years, and odd years.\n\n\nCode\n#Plots\nplot_5 <- ci.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci5))\n\nplot_10 <- ci.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci10))\n\nplot_20 <- ci.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci20))\n\nplot_even_5 <- ci_even.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_even5))\n\nplot_even_10 <- ci_even.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_even10))\n\nplot_even_20 <- ci_even.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_even20))\n\nplot_odd_5 <- ci_odd.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_odd5))\n\nplot_odd_10 <- ci_odd.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_odd10))\n\nplot_odd_20 <- ci_odd.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.ci_odd20))\n\nplot_grid(plot_5, plot_10, plot_20, plot_even_5, plot_even_10, plot_even_20, plot_odd_5, plot_odd_10, plot_odd_20, ncol = 3, nrow = 3)\n\n\n\n\n\nNone of the models fit well. Let’s look at one more region.\n\n\nCode\n#SE AK\n#---------------------------------------------------\n#All Years\npink.seak<-subset(PinkByRegion, region=='seak')\nseak.ts<-ts(pink.seak$lnreturns, start=pink.seak$year[1], frequency = 0.5)\n\n#create training and test datasets for the 5 year forecast \ntrain.seak5<-window(seak.ts, start=1952, end=2010)\ntest.seak5<-window(seak.ts, start=2011, end=2015)\nseak.final5<-forecast::auto.arima(train.seak5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.seak10<-window(seak.ts, start=1952, end=2005)\ntest.seak10<-window(seak.ts, start=2006, end=2015)\nseak.final10<-forecast::auto.arima(train.seak10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.seak20<-window(seak.ts, start=1952, end=1995)\ntest.seak20<-window(seak.ts, start=1996, end=2015)\nseak.final20<-forecast::auto.arima(train.seak20, approximation = F, stepwise = F)\n\n#----------------------------------------------------\n#Even Years\npink.seak_even<-subset(PinkByRegion_even, region=='seak')\nseak.ts_even<-ts(pink.seak_even$lnreturns, start=pink.seak_even$year[1], frequency = 0.5)\n\n#create training and test datasets for the 5 year forecast \ntrain.seak_even5<-window(seak.ts_even, start=1952, end=2010)\ntest.seak_even5<-window(seak.ts_even, start=2012, end=2014)\nseak_even.final5<-forecast::auto.arima(train.seak_even5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.seak_even10<-window(seak.ts_even, start=1952, end=2004)\ntest.seak_even10<-window(seak.ts_even, start=2006, end=2014)\nseak_even.final10<-forecast::auto.arima(train.seak_even10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.seak_even20<-window(seak.ts_even, start=1952, end=1994)\ntest.seak_even20<-window(seak.ts_even, start=1996, end=2014)\nseak_even.final20<-forecast::auto.arima(train.seak_even20, approximation = F, stepwise = F)\n\n#------------------------------\n#Odd Years\npink.seak_odd<-subset(PinkByRegion_odd, region=='seak')\nseak.ts_odd<-ts(pink.seak_odd$lnreturns, start=pink.seak_odd$year[1], frequency = 0.5)\n\n#create training and test datasets for the 5 year forecast \ntrain.seak_odd5<-window(seak.ts_odd, start=1953, end=2009)\ntest.seak_odd5<-window(seak.ts_odd, start=2011, end=2015)\nseak_odd.final5<-forecast::auto.arima(train.seak_odd5, approximation = F, stepwise = F)\n\n#create training and test datasets for the 10 year forecast \ntrain.seak_odd10<-window(seak.ts_odd, start=1953, end=2005)\ntest.seak_odd10<-window(seak.ts_odd, start=2007, end=2015)\nseak_odd.final10<-forecast::auto.arima(train.seak_odd10, approximation = F, stepwise = F)\n\n#create training and test datasets for the 20 year forecast \ntrain.seak_odd20<-window(seak.ts_odd, start=1953, end=1995)\ntest.seak_odd20<-window(seak.ts_odd, start=1997, end=2015)\nseak_odd.final20<-forecast::auto.arima(train.seak_odd20, approximation = F, stepwise = F)\n\n\nLet’s look at forcast plots for the best performing models that consider all data, even years, and odd years.\n\n\nCode\n#Plots \nplot_5 <- seak.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak5))\n\nplot_10 <- seak.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak10))\n\nplot_20 <- seak.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak20))\n\nplot_even_5 <- seak_even.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_even5))\n\nplot_even_10 <- seak_even.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_even10))\n\nplot_even_20 <- seak_even.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_even20))\n\nplot_odd_5 <- seak_odd.final5 %>%\n  forecast(h=5) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_odd5))\n\nplot_odd_10 <- seak_odd.final10 %>%\n  forecast(h=10) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_odd10))\n\nplot_odd_20 <- seak_odd.final20 %>%\n  forecast(h=20) %>%\n  autoplot() + geom_point(aes(x=x, y=y), data=fortify(test.seak_odd20))\n\nplot_grid(plot_5, plot_10, plot_20, plot_even_5, plot_even_10, plot_even_20, plot_odd_5, plot_odd_10, plot_odd_20, ncol = 3, nrow = 3)\n\n\n\n\n\nThese models were all pretty flat and also didn’t seem to capture the trends particularly well.\nNext, the number of models that had a differencing was plotted for all years, even years, and odd years.\n\n\nCode\n#All Years \nNdiff<-sapply(RegionBestMod, function(x){\n  a<-strsplit(strsplit(strsplit(x, \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n  return(a[[1]][2])}\n)\n\ntibble(Ndiff = Ndiff, region = Allcombs$regions, level = Allcombs$forecastlevels) %>%\n  ggplot() + geom_bar(aes(x = region, y = Ndiff, fill = as.factor(level)), stat = \"identity\", position = \"dodge\") +\n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\", y = \"Number of Differences\") + \n  ggtitle(\"Number of differences to achieve stationarity (Pink-All Years)\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nCode\n#Even Years \nNdiff_even<-sapply(RegionBestMod_even, function(x){\n  a<-strsplit(strsplit(strsplit(x, \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n  return(a[[1]][2])}\n)\n\ntibble(Ndiff = Ndiff_even, region = Allcombs$regions, level = Allcombs$forecastlevels) %>%\n  ggplot() + geom_bar(aes(x = region, y = Ndiff, fill = as.factor(level)), stat = \"identity\", position = \"dodge\") +\n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\", y = \"Number of Differences\") + \n  ggtitle(\"Number of differences to achieve stationarity (Pink-Even Years)\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nCode\n#Odd Years \nNdiff_odd<-sapply(RegionBestMod_odd, function(x){\n  a<-strsplit(strsplit(strsplit(x, \"[(]\")[[1]][2], \"[)]\")[[1]][1],\"[,]\")\n  return(a[[1]][2])}\n)\n\ntibble(Ndiff = Ndiff_odd, region = Allcombs$regions, level = Allcombs$forecastlevels) %>%\n  ggplot() + geom_bar(aes(x = region, y = Ndiff, fill = as.factor(level)), stat = \"identity\", position = \"dodge\") +\n  scale_x_discrete(labels = as_labeller(regionskey)) +\n  labs(fill = \"Forecast Levels\", x = \"Region\", y = \"Number of Differences\") + \n  ggtitle(\"Number of differences to achieve stationarity (Pink-Odd Years)\") + theme_bw() + theme(axis.text.x=element_text(angle=-90, hjust = 0, vjust = 0.5 ))\n\n\n\n\n\nWhen considering models that used all data, five regions needed differencing. In models that considered even years only, six regions needed differencing. In models that considered odd years only, ten regions needed differencing.\nFinally we’re going to look at some residuals for models that displayed autocorraltion based on Ljung-Box test. There were only\n\n\nCode\n#Residuals \n#all\nac_mods_Pink<- c(10, 11, 15, 29)\n\nfor(i in 1:length(ac_mods_Pink)){\nprint(paste(regionskey[ResultsTable$regions[ac_mods_Pink[i]]], ResultsTable_even$forecastlevels[ac_mods_Pink[i]]))\ncheckresiduals(RegionMods[[ac_mods_Pink[i]]]$Fit)\n}\n\n\n[1] \"Kodiak 5\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 12.949, df = 5, p-value = 0.02386\n\nModel df: 1.   Total lags used: 6\n\n[1] \"Kodiak 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 13.668, df = 4, p-value = 0.008432\n\nModel df: 1.   Total lags used: 5\n\n[1] \"Russia 20\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 13.669, df = 4, p-value = 0.008429\n\nModel df: 0.   Total lags used: 4\n\n[1] \"SE Alaska 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1) with drift\nQ* = 7.1988, df = 4, p-value = 0.1257\n\nModel df: 1.   Total lags used: 5\n\n\nCode\n#Even\nac_mods_Pink_even<-c(19, 20) \n\nfor(i in 1:length(ac_mods_Pink_even)){\nprint(paste(regionskey[ResultsTable_even$regions[ac_mods_Pink_even[i]]], ResultsTable_even$forecastlevels[ac_mods_Pink_even[i]]))\ncheckresiduals(RegionMods_even[[ac_mods_Pink_even[i]]]$Fit)\n}\n\n\n[1] \"Prince William Sound 5\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 19.847, df = 6, p-value = 0.002949\n\nModel df: 0.   Total lags used: 6\n\n[1] \"Prince William Sound 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,0,0) with non-zero mean\nQ* = 11.944, df = 5, p-value = 0.03556\n\nModel df: 0.   Total lags used: 5\n\n\nCode\n#Odd\nac_mods_Pink_odd<-c(8) \n\nfor(i in 1:length(ac_mods_Pink_odd)){\n  print(paste(regionskey[ResultsTable_odd$regions[ac_mods_Pink_odd[i]]], ResultsTable_odd$forecastlevels[ac_mods_Pink_odd[i]]))\n  checkresiduals(RegionMods_odd[[ac_mods_Pink_odd[i]]]$Fit)\n}\n\n\n[1] \"Japan 10\"\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,0)\nQ* = 11.71, df = 5, p-value = 0.03899\n\nModel df: 0.   Total lags used: 5\n\n\n#———————————————————————"
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html",
    "title": "6  Team 4",
    "section": "",
    "text": "7 Lab 1: ARIMA models\nTeam member names: Terrance Wang (SAFS), Karl Veggerby (SAFS)\nRuggerone & Irvine Data. We will focus on sockeye salmon and all their 15 regional stocks in the North Pacific.\nOverall, the sockeye stocks population trajectories are clearly not stationary. All regions benefit from ARIMA models to understand their underlying temporal dynamics. There is no unifying ARIMA structure that can reliably describe all sockeye populations. This is unsurprising because of the wide spectrum of biological and environmental forces that impact sockeye across its species range. Scattered across the North Pacific are 3 sockeye ecotypes (kokanee, lake, sea/river) that often occur together in the same watershed. Some regions, such as Southern British Columbia, also undergo more human disturbance than other more “pristine” regions, such as Western Alaska.\nAlaska regional stocks seem to share similar temporal dynamics and this is especially true for wak, ci, and pws stocks. We do not what the mechanisms for the shared pattern of these 3 stocks, which are not spatially adjacent to each other. We did not detect reliably, representative ARIMA structures for both the West Coast and East Asia stocks. The low sample size of 3 for both areas is a likely reason for the inconclusiveness.\nInterestingly, the area-wide ARIMA structures did not confirm the area-summarized regional ARIMA ones. Summing the scaled totals by area seems to wash away the temporal dynamics within each region and do not describe the general ARIMA structure and diversity of structures within areas. A next step would explore the potential area-wide ARIMA model candidates for each area since we looked only at the best fitting ones.\nTerrance did most of it, Karl did stationarity section."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html#regional-arima-models",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html#regional-arima-models",
    "title": "6  Team 4",
    "section": "12.1 Regional ARIMA models",
    "text": "12.1 Regional ARIMA models\nWe fit ARIMA models to each individual regional stock and report the fits and diagnostics in the table below.\n\n\n\n\n\n\nARIMA fitting results and residual diagnostics for all sockeye regions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narea\nregion\np\nd\nq\nar1\nar2\nma1\nma2\nresid_p\n\n\n\n\nAlaska\nci\n1\n1\n1\n0.3771937\n0.0000000\n-0.7575114\n0.0000000\n0.0955948\n\n\nAlaska\nkod\n0\n1\n1\n0.0000000\n0.0000000\n-0.6049560\n0.0000000\n0.3682442\n\n\nAlaska\npws\n1\n1\n1\n0.4031980\n0.0000000\n-0.9583822\n0.0000000\n0.0312119\n\n\nAlaska\nseak\n0\n1\n1\n0.0000000\n0.0000000\n-0.4807931\n0.0000000\n0.3015960\n\n\nAlaska\ns_pen\n0\n1\n1\n0.0000000\n0.0000000\n-0.7605650\n0.0000000\n0.9076421\n\n\nAlaska\nwak\n2\n1\n2\n0.5174071\n-0.9318466\n-0.7103177\n0.7039975\n0.2357500\n\n\nEast_Asia\ne_kam\n1\n0\n0\n0.7956410\n0.0000000\n0.0000000\n0.0000000\n0.4879928\n\n\nEast_Asia\nm_i\n1\n0\n0\n0.5291796\n0.0000000\n0.0000000\n0.0000000\n0.5479562\n\n\nEast_Asia\nw_kam\n0\n1\n1\n0.0000000\n0.0000000\n-0.3667696\n0.0000000\n0.0992328\n\n\nWC\nnbc\n1\n0\n1\n0.9296554\n0.0000000\n-0.7239860\n0.0000000\n0.3154644\n\n\nWC\nsbc\n0\n0\n0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0015210\n\n\nWC\nwc\n1\n0\n2\n-0.9320727\n0.0000000\n1.2724536\n0.4421506\n0.6338888\n\n\n\n\n\nThe best fitting ARIMA models show a wide diversity of structure. Similarities and differences within and among areas will be discussed in more detail in the next section. Residuals are generally stationary, meaning acceptable ARIMA fits, with a few exceptions (e.g., kod, sbc). Below, the example of w_kam shows that residuals show signs of stationarity like a stable mean, normal distribution of values, and little autocorrelation. Though there is some temporal pattern in the variance.\n\n\n\n\n\nExample of residual diagnostics of one of the regions\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)\nQ* = 14.709, df = 9, p-value = 0.09923\n\nModel df: 1.   Total lags used: 10\n\n\n\n\n\n\n\nARIMA structure by area\n\n\n\n\n\n\n\nAR parameters by area\n\n\n\n\n\n\n\nMA parameters by area\n\n\n\n\n\n12.1.1 Comparing regional ARIMA models within and among area\nThe ARIMA structure for all sockeye stocks (ignoring area) do not show a clear pattern in AR, differencing, and MA. A slight majority of stocks support first order AR, differencing, and MA. When we look closer at the parameter values, there is a small tendency for sockeye to have positive AR1 values and negative MA1 values. This suggests sockeye populations are loosely related to the previous time step and deviate around the general trajectory with a 2 year period.\nAlaska shows a consistent ARIMA pattern for all of its regions. The best fit ARIMA models for AK regions all predict first difference. AK strongly supports a first order of the moving average part. Additionally, all AK regions have negative MA1 values. There is some substructure of ARIMA properties within AK. AK shows no area-wide consensus on the order of the autoregressive part, but Looking more closely at the autoregressive parameter values of Alaska regions, we see only positive AR1 values for the regions with at least 1 order of AR (wak,ci,pws). Wak, ci, and pws populations tend to be more related to the previous year than other AK regions are.\nWest Coast regions do not have a consensus on ARIMA structure, with an exception of 0 differencing. AR1 and MA1 parameters range from negative to positive. This inconclusiveness is partly explained by the low sample size (n=3). East Asia regions are also inconsistent on the predicted order number of the moving average and autoregressive components. With only 3 East Asia regions with data, it is difficult to construe any pattern."
  },
  {
    "objectID": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html#area-arima-models",
    "href": "Lab-1/Final_Write_ups/Lab-1-team-4_final.html#area-arima-models",
    "title": "6  Team 4",
    "section": "12.2 Area ARIMA models",
    "text": "12.2 Area ARIMA models\nWe fit ARIMA models to each area stock (scaled, summed, and logged) and report the fits and diagnostics in the table below.\n\n\n\n\n\n\nARIMA fitting results and residual diagnostics for summed scaled sockeye areas\n\n\n\n\n\n\n\n\n\n\n\n\n\narea\np\nd\nq\nar1\nar2\nma1\nma2\nresid_p\n\n\n\n\nAlaska\n2\n1\n2\n0.5975743\n-0.8201475\n-0.9625597\n0.7736959\n0.5803041\n\n\nEast_Asia\n1\n1\n0\n-0.2890606\n0.0000000\n0.0000000\n0.0000000\n0.6259541\n\n\nWC\n0\n0\n0\n0.0000000\n0.0000000\n0.0000000\n0.0000000\n0.0265574\n\n\n\n\n\n\n12.2.1 Comparing regional ARIMA models to area ARIMA models\nThe area-wide ARIMA structures did not match their regional counterparts. The best fitting AK ARIMA model was a 2 order AR and MA and 1 order difference structure, which contrasts with the <2 order AR and 1 order MA of the summarized ARIMA structure of the regional stocks. The East Asia ARIMA model has some semblance to the regional E Asia stocks, but this is inconclusive because of the low sample size. West Coast model had no ARIMA structure which does not to capture the non-stationarity of some NA WC regional stocks."
  },
  {
    "objectID": "Lab-2/Lab2-MARSS.html#teams",
    "href": "Lab-2/Lab2-MARSS.html#teams",
    "title": "7  Lab Intro",
    "section": "7.1 Teams",
    "text": "7.1 Teams\n\nLower Columbia River Chinook: Zoe Rand (QERM), Emma Timmins-Schiffman (Genome Sci), Maria Kuruvilla (QERM)\nLower Columbia River Steelhead: Eric French (Civil), Liz Elmstrom (SAFS), Terrance Wang (SAFS)\nLower Columbia River Coho: Nick Chambers (SAFS), Karl Veggerby (SAFS), Miranda Mudge (Molecular & Cellular)\nMiddle Columbia River Steelhead: Madison Shipley (SAFS), Dylan Hubl (Env & Forest Sci)"
  },
  {
    "objectID": "Lab-2/Lab2-MARSS.html#lower-columbia-river-salmon-spawner-data",
    "href": "Lab-2/Lab2-MARSS.html#lower-columbia-river-salmon-spawner-data",
    "title": "7  Lab Intro",
    "section": "7.2 Lower Columbia River salmon spawner data",
    "text": "7.2 Lower Columbia River salmon spawner data\nThese data are from the Coordinated Assessments Partnership (CAP) and downloaded using the rCAX R client for the CAX (the CAP database) API. The data are saved in Lab-2/Data_Images/columbia-river.rda.\n\n\n\nThe data set has data for fi endangered and threatened ESU (Evolutionary Significant Units) in the Lower Columbia River.\n\n\n[1] \"Steelhead (Middle Columbia River DPS)\"     \n[2] \"Steelhead (Upper Columbia River DPS)\"      \n[3] \"Steelhead (Lower Columbia River DPS)\"      \n[4] \"Salmon, coho (Lower Columbia River ESU)\"   \n[5] \"Salmon, Chinook (Lower Columbia River ESU)\"\n\n\n\n\n\n\n\nFigure from ESA recovery plan for Lower Columbia River Coho salmon, Lower Columbia River Chinook salmon, Columbia River Chum salmon, and Lower Columbia River steelhead. 2013. NMFS NW Region. https://repository.library.noaa.gov/view/noaa/16002\n\n\n\n\n\n7.2.1 Data structure\nThe dataset has the following columns\n\n\n[1] \"species\"       \"esu_dps\"       \"majorpopgroup\" \"esapopname\"   \n[5] \"commonpopname\" \"run\"           \"spawningyear\"  \"value\"        \n[9] \"value_type\"   \n\n\n\nspecies: Chinook, Coho, Steelhead\nesu_dps: name of the ESU\nmajorpopgroup: biological major group\ncommonpopname: common population name, generally a stream or river\nrun: run-timing\nspawningyear: the year that the spawners were counted on the spawning grounds\nvalue: total (natural-born and hatchery-born) spawners on the spawning ground. Generally some type of redd-count expansion or some other stream count of spawners. Redd = a gravel nest.\n\n\n\n7.2.2 Data plots\nLet’s load one ESU and make a plot. Create a function."
  },
  {
    "objectID": "Lab-2/Lab2-MARSS.html#tasks-for-each-group",
    "href": "Lab-2/Lab2-MARSS.html#tasks-for-each-group",
    "title": "7  Lab Intro",
    "section": "7.3 Tasks for each group",
    "text": "7.3 Tasks for each group\n\nCreate estimates of spawner abundance for all missing years and provide estimates of the decline from the historical abundance.\nEvaluate support for the major population groups. Are the populations in the groups more correlated than outside the groups?\nEvaluate the evidence of cycling in the data. We will talk about how to do this on the Tuesday after lab.\n\n\n7.3.1 Tips\nSimplify\nIf your ESU has many populations, start with a smaller set of 4-7 populations.\nAssumptions\nYou can assume that R=\"diagonal and equal\" and A=\"scaling\". Assume that “historical” means the earliest years available for your group.\nStates\nYour abundance estimate is the “x” or “state” estimates. You can get this from\nfit$states\nor\ntsSmooth(fit)\nwhere fit is from fit <- MARSS()\nplotting\nEstimate of the mean of the spawner counts based on your x model.\nautoplot(fit, plot.type=\"fitted.ytT\")\ndiagnostics\nautoplot(fit, plot.type=\"residuals\")\n\n\n7.3.2 Address the following in your methods\n\nDescribe your assumptions about the x and how the data time series are related to x.\n\nHow are the x and y (data) related? 1 x for 1 y or will you assume 1 x for all y or 1 x for each major population group? How will you choose?\nWhat will you assume about the U for the x’s?\nWhat will you assume about the Q matrix?\n\nWrite out your assumptions as different models in matrix form, fit each and then compare these with AIC or AICc.\nDo your estimates differ depending on the assumptions you make about the structure of the data, i.e. you assumptions about the x’s, Q, and U."
  },
  {
    "objectID": "Lab-2/Lab2-MARSS.html#sample-code",
    "href": "Lab-2/Lab2-MARSS.html#sample-code",
    "title": "7  Lab Intro",
    "section": "7.4 Sample code",
    "text": "7.4 Sample code\nHere I show how I might analyze the Upper Columbia Steelhead data.\n\n\n\n\n\nFigure from 2022 5-Year Review: Summary & Evaluation of Upper Columbia River Spring-run Chinook Salmon and Upper Columbia River Steelhead. NMFS. West Coast Region. https://doi.org/10.25923/p4w5-dp31\n\n\n\n\nSet up the data. We need the time series in a matrix with time across the columns.\nLoad the data.\n\n\n\nWrangle the data.\n\n\n\nClean up the row names\n\n\n\nSpecify a model\n\n\n\nFit the model. In this case, a BFGS algorithm is faster.\n\n\nSuccess! Converged in 235 iterations.\nFunction MARSSkfas used for likelihood calculation.\n\nMARSS fit is\nEstimation method: BFGS \nEstimation converged in 235 iterations. \nLog-likelihood: -109.4078 \nAIC: 256.8155   AICc: 262.1676   \n \n               Estimate\nR.diag          0.00997\nU.X.Entiat      0.02182\nU.X.Methow      0.01852\nU.X.Okanogan    0.00140\nU.X.Wenatchee  -0.02222\nQ.(1,1)         0.28016\nQ.(2,1)         0.12303\nQ.(3,1)         0.14275\nQ.(4,1)         0.23415\nQ.(2,2)         0.31642\nQ.(3,2)         0.30806\nQ.(4,2)         0.19061\nQ.(3,3)         0.31031\nQ.(4,3)         0.18852\nQ.(4,4)         0.52813\nx0.X.Entiat     4.61647\nx0.X.Methow     6.43401\nx0.X.Okanogan   6.47217\nx0.X.Wenatchee  8.04868\nInitial states (x0) defined at t=0\n\nStandard errors have not been calculated. \nUse MARSSparamCIs to compute CIs and bias estimates.\n\n\nHmmmmm, the Q variance is so high that it perfectly fits the data. That doesn’t seem right.\n\n\nMARSSresiduals.tT reported warnings. See msg element or attribute of returned residuals object.\n\n\n\n\n\nplot.type = fitted.ytT \n\n\n\n\n\nFinished plots.\n\n\nLet’s look at the corrplot. Interesting. The Methow and Entiat are almost perfectly correlated while the Entiat and Wenatchee are somewhat correlated. That makes sense if you look at a map.\n\n\ncorrplot 0.92 loaded\n\n\n\n\n\nI need to use the EM algorithm (remove method=\"BFGS\") because the BFGS algorithm doesn’t allow constraints on the Q matrix.\n\n\nSuccess! abstol and log-log tests passed at 794 iterations.\nAlert: conv.test.slope.tol is 0.5.\nTest with smaller values (<0.1) to ensure convergence.\n\nMARSS fit is\nEstimation method: kem \nConvergence test: conv.test.slope.tol = 0.5, abstol = 0.001\nEstimation converged in 794 iterations. \nLog-likelihood: -120.6028 \nAIC: 263.2057   AICc: 264.9657   \n \n               Estimate\nR.diag           0.1290\nU.X.Entiat       0.0257\nU.X.Methow       0.0311\nU.X.Okanogan     0.0166\nU.X.Wenatchee   -0.0282\nQ.diag           0.2632\nQ.offdiag        0.2631\nx0.X.Entiat      4.2026\nx0.X.Methow      5.9042\nx0.X.Okanogan    5.8359\nx0.X.Wenatchee   8.0703\nInitial states (x0) defined at t=0\n\nStandard errors have not been calculated. \nUse MARSSparamCIs to compute CIs and bias estimates.\n\n\n\n\nMARSSresiduals.tT reported warnings. See msg element or attribute of returned residuals object.\n\n\n\n\n\nplot.type = fitted.ytT \n\n\n\n\n\nFinished plots.\n\n\nNow I want try something different. I will treat the Methow-Okanogan as one state and the Entiat-Wenatchee as another. I’ll let these be correlated together. Interesting, these two are estimated to be perfectly correlated.\n\n\nWarning! Reached maxit before parameters converged. Maxit was 500.\n neither abstol nor log-log convergence tests were passed.\n\nMARSS fit is\nEstimation method: kem \nConvergence test: conv.test.slope.tol = 0.5, abstol = 0.001\nWARNING: maxit reached at  500  iter before convergence.\n Neither abstol nor log-log convergence test were passed.\n The likelihood and params are not at the ML values.\n Try setting control$maxit higher.\nLog-likelihood: -137.532 \nAIC: 295.064   AICc: 296.5209   \n \n            Estimate\nA.Okanogan  -0.68779\nA.Wenatchee  1.54127\nR.diag       0.18062\nU.ew        -0.02175\nU.mo         0.00374\nQ.(1,1)      0.22050\nQ.(2,1)      0.22103\nQ.(2,2)      0.22164\nx0.ew        6.51468\nx0.mo        7.33795\nInitial states (x0) defined at t=0\n\nStandard errors have not been calculated. \nUse MARSSparamCIs to compute CIs and bias estimates.\n\nConvergence warnings\n Warning: the  logLik  parameter value has not converged.\n Type MARSSinfo(\"convergence\") for more info on this warning.\n\n\n\n\n\nplot.type = fitted.ytT \n\n\n\n\n\nFinished plots.\n\n\nFinally, let’s look at the AIC values. Fit1 was very flexible and can put a line through the data so I know I have at least one model in the set that can fit the data. Well, the most flexible model is the best. At this point, I’d like to look just at data after 1980 or so. I don’t like the big dip that happened in the Wenatchee River. I’d want to talk to the biologists to find out what happened, especially because I know that there might be hatchery releases in this system.\n\n\n[1]  0.00000  2.79807 34.35331\n\n\n\n7.4.1 Including cycling\nLet’s just look at the data after 1987 to eliminate that string of NAs in the 3 rivers.\n\n\n\nLet’s look the acf to look for evidence of cycling. Due to the nature of their life-cycle where they tend to return back to their spawning grounds after a certain numbers of years, we might expect some cycling although steelhead aren’t really known for this (unlike sockeye, chinook and pink).\nWell no obvious cycles.\n\n\n\n\n\nBut let’s go through how we might include cycles. We are going to include cycles with frequency 3, 4, and 5, choosem to reflect steelhead returning after 3, 4 or 5 years.\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nNow let’s fit a model with these covariates. Let’s analyze the populations separately, so Q is diagonal.\n\n\n\n\n\nSuccess! abstol and log-log tests passed at 78 iterations.\nAlert: conv.test.slope.tol is 0.5.\nTest with smaller values (<0.1) to ensure convergence.\n\nMARSS fit is\nEstimation method: kem \nConvergence test: conv.test.slope.tol = 0.5, abstol = 0.001\nEstimation converged in 78 iterations. \nLog-likelihood: -55.48472 \nAIC: 196.9694   AICc: 238.5519   \n \n                   Estimate\nR.diag              0.00841\nU.X.Entiat         -0.01592\nU.X.Methow          0.00629\nU.X.Okanogan       -0.01331\nU.X.Wenatchee      -0.06327\nQ.(1,1)             0.21426\nQ.(2,1)             0.10446\nQ.(3,1)             0.12493\nQ.(4,1)             0.12760\nQ.(2,2)             0.21888\nQ.(3,2)             0.21364\nQ.(4,2)             0.13562\nQ.(3,3)             0.22037\nQ.(4,3)             0.13483\nQ.(4,4)             0.31566\nx0.X.Entiat         6.34777\nx0.X.Methow         7.39581\nx0.X.Okanogan       7.02470\nx0.X.Wenatchee      8.65239\nD.(Entiat,S1-3)    -0.03464\nD.(Methow,S1-3)    -0.12969\nD.(Okanogan,S1-3)  -0.11592\nD.(Wenatchee,S1-3) -0.01482\nD.(Entiat,C1-3)     0.02784\nD.(Methow,C1-3)    -0.08604\nD.(Okanogan,C1-3)  -0.09585\nD.(Wenatchee,C1-3)  0.05808\nD.(Entiat,S1-4)    -0.11286\nD.(Methow,S1-4)    -0.13983\nD.(Okanogan,S1-4)  -0.09480\nD.(Wenatchee,S1-4) -0.06365\nD.(Entiat,C1-4)     0.02030\nD.(Methow,C1-4)    -0.09692\nD.(Okanogan,C1-4)  -0.08208\nD.(Wenatchee,C1-4) -0.08237\nD.(Entiat,S1-5)    -0.19272\nD.(Methow,S1-5)     0.05745\nD.(Okanogan,S1-5)   0.07723\nD.(Wenatchee,S1-5) -0.18255\nD.(Entiat,C1-5)    -0.01818\nD.(Methow,C1-5)     0.17916\nD.(Okanogan,C1-5)   0.15510\nD.(Wenatchee,C1-5) -0.02965\nInitial states (x0) defined at t=0\n\nStandard errors have not been calculated. \nUse MARSSparamCIs to compute CIs and bias estimates.\n\n\nLet’s plot the estimates. broom::tidy() will get a data frame with the terms, estimates and CIs.\n\n\n\nWe can then plot this. Interesting. Some support for 5 year cycles.\n\n\n\n\n\nLet’s compare some other models.\n\n\n\nHmm model without cyles is much better (lower AICc). Even if we only have the 5 year cycles (covariates[5:6,]), the AICc is larger than for the models with cycles.\n\n\n[1]  0.00000 56.99612 11.66091 56.99461"
  },
  {
    "objectID": "Lab-2/Lab2-MARSS.html#resources",
    "href": "Lab-2/Lab2-MARSS.html#resources",
    "title": "7  Lab Intro",
    "section": "7.5 Resources",
    "text": "7.5 Resources\nChapter 7 MARSS models. ATSA Lab Book. https://atsa-es.github.io/atsa-labs/chap-mss.html\nChapter 8 MARSS models with covariate. ATSA Lab Book. https://atsa-es.github.io/atsa-labs/chap-msscov.html\nChapter 16 Modeling cyclic sockeye https://atsa-es.github.io/atsa-labs/chap-cyclic-sockeye.html"
  }
]