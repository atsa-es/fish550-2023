---
title: Team 4 - Lab 2
subtitle: Lab 2 MARSS models
author: "Madison Heller-Shipley, Dylan Hubl"
output: 
  html_document:
    code-folding: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Data

We are examining the sockeye population within the Middle Columbia River System. Within this system there are four major population groups. The Cascades, John Day, Walla Walla, and Yakima. The John Day group has the longest running dataset with records reaching back to 1959. The other major population groups generally start their datasets in the 1980's. A noteable exception is the Umatilla River within the Walla Walla group which also has data beginning in the 1960s. In general all of the salmon running times occur in the summer in the Middle Columbia River System.


```{r}
library(tidyr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(forecast)
library(MARSS)
library(corrplot)
library(knitr)
load(here::here("Lab-2", "Data_Images", "columbia-river.rda"))
```


We are only interested in the rivers in the Middle Columbia River Unit


```{r}

#plot the unique Rivers in Middle Columbia
dat <- columbia.river
esuname <- unique(dat$esu_dps)
years<-length(unique(dat$spawningyear))
plotesu <- function(esuname){
  df <- dat %>% subset(esu_dps %in% esuname)
  ggplot(df, aes(x=spawningyear, y=log(value), color=majorpopgroup)) + 
    geom_point(size=1, na.rm = TRUE) + 
    theme(strip.text.x = element_text(size = 8)) +
    theme(axis.text.x = element_text(size = 8, angle = 90)) +
    facet_wrap(~esapopname) +
    ggtitle(paste0(esuname, collapse="\n"))
}
#plot the unique Rivers in Middle Columbia
plotesu(esuname[1])
```


Next, the data are arranged so the columns are the years and rows are unique rivers


```{r}
esuname <- esuname[1]
dat <- columbia.river %>% 
  subset(esu_dps == esuname) %>% # get only this ESU
  mutate(log.spawner = log(value)) %>% # create a column called log.spawner
  dplyr::select(esapopname, spawningyear, log.spawner) %>% # get just the columns that I need
  pivot_wider(names_from = "esapopname", values_from = "log.spawner") %>% 
  column_to_rownames(var = "spawningyear") %>% # make the years rownames
  as.matrix() %>% # turn into a matrix with year down the rows
  t() # make time across the columns
# MARSS complains if I don't do this
dat[is.na(dat)] <- NA
any(is.null(dat))
any(is.infinite(dat))
dat[is.infinite(dat)] <- NA
```


Let's take a look at the Middle Columbia River area and formulate some hypotheses:


```{r}

here::here("Lab-2", "Team-4", "Middle Columbia River sockeye.png") |>
  knitr::include_graphics()

```


# General Questions

Each group has the same general tasks, but you will adapt them as you work on the data.

1.  Create estimates of spawner abundance for all missing years and provide estimates of the decline from the historical abundance.

2.  Evaluate support for the major population groups. Are the populations in the groups more correlated than outside the groups?

3.  Evaluate the evidence of cycling in the data.

## Data Notes

Make some assumptions about underlying population structure. This can help you fill in missing data areas.

Adult run timing (when they're coming into fresh water, look at run timing--any correlation?)

John Day Data set spans the entire time period, and we will look at the appropriatness of drawing inference from these data to fill in other missing values.

# Methods

Address the following in your methods

-   Describe your assumptions about the x and how the data time series are related to x.

    -   How are the x and y (data) related? 1 x for 1 y or will you assume 1 x for all y or 1 x for each major population group? How will you choose?
    -   What will you assume about the U for the x's?
    -   What will you assume about the Q matrix?

-   Write out your assumptions as different models **in matrix form**, fit each and then compare these with AIC or AICc.

-   Do your estimates differ depending on the assumptions you make about the structure of the data, i.e. you assumptions about the x's, Q, and U.

## Hypotheses

There were four main hypotheses explored in this modeling exercise.

-   Hypothesis 1: All underlying states are the same and one underlying population.

-   Hypothesis 2: There are four underlying states, each associated with one of the main distinct population centers (DPC), the Cascades, John Day, Walla Walla, and Yakima tributaries.

-   Hypothesis 3: There are two underlying states, one representing the northern area (Walla Walla and Yakima) and on representing the southern area (John Day and Cascades).

-   Hypothesis 4: There are two underlying states, Yakama and the rest of the areas. Salmon swim eastward to a bend in the river where salmon can choose to go north to the Yakama DPC, or south to other DPCs.

For Hypothesis 1, only one model was tested that assumed the Q matrix was diagonal and equal. We only tested this as a baseline for simplicity and time sake, as it is the model we had the least amount of confidence in (and was primarily used for conceptualization and initial MARSS model testing). For Hypotheses 2-4 four sub-hypotheses based on the Q matrix were tested.

Hypotheses:

-   X.1 = Diagonal and Equal

-   X.2 = Diagonal and Unequal

-   X.3 = Equal variance and covariance

-   X.4 = Unconstrained

This allowed us to get a better idea of the impacts of changing the amount of correlation in the process errors for each of these systems.

#### Other Assumptions

You can assume that `R="diagonal and equal"` and `A="scaling"`. Assume that "historical" means the earliest years available for your group.

**States**

Your abundance estimate is the "x" or "state" estimates.

## Pick best Hypothesis

We will compare AICs, all models should be comparable.

## Evidence of cycling

We will see which hypothesis performs the best, and then explore cycling assumptions with a simple cycling model, and some variant on periodicity with our best performing model to see if we can improve fits and AICc.

### Tips

**Assumptions**

or

    tsSmooth(fit)

where `fit` is from `fit <- MARSS()`

**plotting**

Estimate of the mean of the spawner counts based on your x model.

    autoplot(fit, plot.type="fitted.ytT")

**diagnostics**

    autoplot(fit, plot.type="residuals")

# Results

## Hypothesis 1

Hypothesis 1 assumes that there is a single hidden state (X) for each stream (n=15) in the time series. The Q matrix for the variance of process errors is "diagonal and equal" meaning each state (x) model has the same variance but they are not correlated to each other.

$$
\text{Hypothesis One}:
\begin{bmatrix}
y_1\\
y_2\\
y_3\\
y_4\\
y_5\\
y_6\\
y_7\\
y_8\\
y_9\\
y_{10}\\
y_{11}\\
y_{12}\\
y_{13}\\
y_{14}\\
y_{15}\\
\end{bmatrix}_t=
\begin{bmatrix}
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
1 \\
\end{bmatrix}*
\begin{bmatrix}
x_1\\
\end{bmatrix}_t+
\begin{bmatrix}
a_1\\
a_2\\
a_3\\
a_4\\
a_5\\
a_6\\
a_7\\
a_8\\
a_9\\
a_{10}\\
a_{11}\\
a_{12}\\
a_{13}\\
a_{14}\\
a_{15}\\
\end{bmatrix}+
\begin{bmatrix}
w_1\\
w_2\\
w_3\\
w_4\\
w_5\\
w_6\\
w_7\\
w_8\\
w_9\\
w_{10}\\
w_{11}\\
w_{12}\\
w_{13}\\
w_{14}\\
w_{15}\\
\end{bmatrix}_t
$$ $$
\text{Where }w \sim MVN
\begin{pmatrix}
\text{0,}\begin{bmatrix}
R
\end{bmatrix}
\end{pmatrix}
$$


```{r}
mod.list1 <- list(
  U = "unequal", #each of the rivers are estimated separately (different U)
  R = "diagonal and equal", #Process errors are all assumed to be the same 
  Q = "diagonal and equal" #Observation error 
)

m1 <- MARSS(dat, model=mod.list1, method="BFGS")

```


The model converged! Let's take a look at the plots:


```{r}
autoplot(m1)
```


This model doesn't perform very well in areas that lack data, and, related, some of the QQ plots don't hold assumptions of normality. This makes sense, given that stream missing data have nothing to inform them. In the states plots, the areas with missing data are characterized by confidence intervals that balloon out. Let's look at the abundance estimates for this model.


```{r}

print(fit1_smooth<-tsSmooth(m1))

```


Finally, let's look at the correlation plot.


```{r}

Q1 <- coef(m1, type = "matrix")$Q
corrmat1 <- diag(1/sqrt(diag(Q1))) %*% Q1 %*% diag(1/sqrt(diag(Q1)))
corrplot(corrmat1)
 
```


## Hypothesis 2

Hypothesis two assumes that the four main DPCs form separate sub-populations. In this hypothesis we are utilizing 4 separate underlying states to model the observations from each of the main population groups. For each of the four models that we are comparing for this hypothesis, we are allowing the random walks to drift independent of one another based on the supplied "U" matrix.

$$
\text{Hypothesis Two}:
\begin{bmatrix}
y_1\\
y_2\\
y_3\\
y_4\\
y_5\\
y_6\\
y_7\\
y_8\\
y_9\\
y_{10}\\
y_{11}\\
y_{12}\\
y_{13}\\
y_{14}\\
y_{15}\\
\end{bmatrix}_t=
\begin{bmatrix}
1 & 0 & 0 & 0\\
1 & 0 & 0 & 0\\
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 1\\
0 & 0 & 0 & 1\\
\end{bmatrix}*
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4\\
\end{bmatrix}_t+
\begin{bmatrix}
a_1\\
a_2\\
a_3\\
a_4\\
a_5\\
a_6\\
a_7\\
a_8\\
a_9\\
a_{10}\\
a_{11}\\
a_{12}\\
a_{13}\\
a_{14}\\
a_{15}\\
\end{bmatrix}+
\begin{bmatrix}
w_1\\
w_2\\
w_3\\
w_4\\
w_5\\
w_6\\
w_7\\
w_8\\
w_9\\
w_{10}\\
w_{11}\\
w_{12}\\
w_{13}\\
w_{14}\\
w_{15}\\
\end{bmatrix}_t $$

$$
\text{Where }w \sim MVN
\begin{pmatrix}
\text{0,}\begin{bmatrix}
R
\end{bmatrix}
\end{pmatrix}
$$

Set up the U and Z matrices


```{r}
#give U values names to make it easier to read results
#this hypothesis has 4 hidden states based on major groups
U_mat2 <- matrix(c("Cascades","JohnDay","Walla","Yakima"),4,1)
#make Z matrix correspond to 4 hidden states
Z_mat2 <- matrix(c(rep(c(1,0,0,0),3),
                  rep(c(0,1,0,0),5),
                  rep(c(0,0,1,0),3),
                  rep(c(0,0,0,1),4)),15,4, byrow=TRUE)
```


###Hypothesis 2.1 The Q matrix for the variance of process errors is "diagonal and equal" meaning each state (x) model has the same process error but they are not correlated to each other.


```{r}

mod.list2.1 <- list(
  U = U_mat2,
  R = "diagonal and equal",
  Q = "diagonal and equal",
  Z = Z_mat2
)
m2.1 <- MARSS(dat, model = mod.list2.1)
```


The model converged with a better AICc than Hypothesis 1.


```{r}
autoplot(m2.1)
```


There are larged ballooned CIs on the missing data in hidden states fitted CI have the same balloon shaped CIs on missing data.There also appears to be some cyclic structure in the residuals. Yakima (X4) is the only system with a positive drift value on the hidden state's random walk. There is only one Q value output as all hidden states have the same one and there is no covariance/correlation between states. This model likely will not be a top contender when we evaluate based on AICs. Let's look at the estimates.


```{r}
print(fit2.1_smooth<-tsSmooth(m2.1))
```


And let's look at corrplot, it should be very familiar.


```{r}
Q2.1 <- coef(m2.1, type = "matrix")$Q
corrmat2.1 <- diag(1/sqrt(diag(Q2.1))) %*% Q2.1 %*% diag(1/sqrt(diag(Q2.1)))
corrplot(corrmat2.1)
#As expected output displays only diagonal as we told it diagonal and equal

```


The Confidence Intervals in the sections of the underlying states (x) were very large in the sections where data was missing. This was also reflected in the plots showing the fitted values. Some structuring may also be present in the residuals. Six of the river systems have multiple significant lags when examining the ACF plots indicating the residuals display autocorrelation. The corrplot is fairly uninformative as we forced the model to be equal variance with no correlation. One interesting thing to note is that we allowed the "U" values to varying independently of each other and the Yakima group is the only one with a positive U value, indicating it is the only system with positive growth or at least increasing number of adults counted over time.

------------------------------------------------------------------------

### Hypothesis 2.2

The Q matrix for the variance of process errors is "diagonal and unequal" meaning each of the four underlying states' process error can be different but they are not correlated to each other.


```{r}

mod.list2.2 <- list(
  U = U_mat2,
  R = "diagonal and equal",
  Q = "diagonal and unequal",
  Z = Z_mat2
)
m2.2 <- MARSS(dat, model = mod.list2.2)
```


Our model converged with an AICc value that is a little better than the model where Q was diagonal and equal, indicating that allowing Q to vary improved the model fits to data.


```{r}
autoplot(m2.2)
```


We still see large CIs on the missing data in hidden states 1 (Cascades) and 4 (Yakima). The CI are tight in the John Day region, which is the most data rich stream. Again Yakima is the only positive drift value on the hidden state's random walk

The 4 varied Q values indicate that the hidden states are uncorrelated, and the variance of the state variables varies over time.

Next let's looks at the estimates:


```{r}
print(fit2.1_smooth<-tsSmooth(m2.2))
```


Lets look at the correlation plots


```{r}
Q2.2 <- coef(m2.2, type = "matrix")$Q
corrmat2.2 <- diag(1/sqrt(diag(Q2.2))) %*% Q2.2 %*% diag(1/sqrt(diag(Q2.2)))
corrplot(corrmat2.2)

```


Again we see large balloon shaped confidence intervals in the sections of rivers that are missing data. This appears in both the estimated underlying states and the fitted value plots. The Walla Walla groups seems to have the widest confidence intervals of all of the river systems. Again six of the rivers have ACF plots with multiple significant lags. The Yakima Population group continues to be the only group with an underlying state which is estimated to have a positive drift. The variance-covariance matrix was allowed to vary the variance of each underlying state independently of one another, but we see that it estimated each to be equal.

------------------------------------------------------------------------

### Hypothesis 2.3

The Q matrix for the variance of process errors is "equal variance and covariance" so they each have equal variance and they are all correlated equally to one another.


```{r}

mod.list2.3 <- list(
  U = U_mat2,
  R = "diagonal and equal",
  Q = "equalvarcov",
  Z = Z_mat2
)
m2.3 <- MARSS(dat, model = mod.list2.3)
```


This model seemed to improve performance. Let's take a look at some plots:


```{r}
autoplot(m2.3)
```


This model fits each of the four states quite well, which indicates that the variability and the relationships between the different state variables are correlated.

Let's looks at the estimates


```{r}
print(fit2.1_smooth<-tsSmooth(m2.3))
```


And the corrplot:


```{r}
Q2.3 <- coef(m2.3, type = "matrix")$Q
corrmat2.3 <- diag(1/sqrt(diag(Q2.3))) %*% Q2.3 %*% diag(1/sqrt(diag(Q2.3)))
corrplot(corrmat2.3)
#corrplot mirrors what we told MARSS to use as a Q matrix (equal variance and covariance)

```


This is the first set of models in the Hypothesis Two group that has not generated balloon shaped confidence intervals on the underlying states or the fitted values plots. Indicating that we have a better model when we allow the models to be correlated with one another. We potentially see some structuring in the residuals. Fewer of the ACF plots show strong structuring in the residuals, some of the plots with significant lags onlt have a few and we see less of the sine wave shaped plots than in the previous Hypothesis Two models. The variance covariate plot was forced to be equal, but we see that correlation between the major groups is estimated to be quite high.

------------------------------------------------------------------------

### Hypothesis 2.4

The Q matrix for the variance of process errors is "unconstrained". Meaning that each hidden state is allowed to vary separately as is the correlation between the underlying states.


```{r}

mod.list2.4 <- list(
  U = U_mat2,
  R = "diagonal and equal",
  Q = "unconstrained",
  Z = Z_mat2
)
m2.4 <- MARSS(dat, model = mod.list2.4, method="BFGS")

```


This model, with the unconstrained Q matrix, had a hard time converging, thus the Broyden-Fletcher-Goldfarb-Shanno method was used to help with optimization. Thus far, this model has the lowest AICc.


```{r}
autoplot(m2.4)
```


These model fits looks pretty well, with tight confidence intervals and the model is fitting the data well. All of the residuals looks like they are normal, and standardized residuals may show a bit of structure in a few graphs but otherwise white noise. Again X4 (Yakima) is the only positive drift value. On the hidden state's random walk John Day and Yakima have strongest correlation and then John Day and Cascades I expect this to be seen in the corrplot.

Lets look at estimates:


```{r}
print(fit2.1_smooth<-tsSmooth(m2.4))
```


look at corrplot:


```{r}
Q2.4 <- coef(m2.4, type = "matrix")$Q
corrmat2.4 <- diag(1/sqrt(diag(Q2.4))) %*% Q2.4 %*% diag(1/sqrt(diag(Q2.4)))
corrplot(corrmat2.4)

```


All groups are highly correlated with each other, which means there is likely a lot of connectivity between these four DPCs.

Again we see that confidence intervals have some shape to them and fit the predicted values better than the balloon shaped confidence intervals seen in previous Hypotheis Two plots. Plots of the residuals look very similar to the other plots from this Hypothesis group. ACF plots are similar to the Hypothesis 2.3 and do not show as much structuring as previous plots.

The Q matrix was allowed to be unconstrained. We see very different variances estimated by the MARSS model, ranging from 0.03 to .21. Covariance between the underlying states allowed for better fits to data and realistic estimates for streams with missing data.

------------------------------------------------------------------------

## Hypothesis 3

Description of H3: There are two underlying states, one representing the northern area (Walla Walla and Yakima) and one representing the southern area (John Day and Cascades).

$$
\text{Hypothesis Three}:
\begin{bmatrix}
y_1\\
y_2\\
y_3\\
y_4\\
y_5\\
y_6\\
y_7\\
y_8\\
y_9\\
y_{10}\\
y_{11}\\
y_{12}\\
y_{13}\\
y_{14}\\
y_{15}\\
\end{bmatrix}_t=
\begin{bmatrix}
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
\end{bmatrix}*
\begin{bmatrix}
x_1\\
x_2\\
\end{bmatrix}_t+
\begin{bmatrix}
a_1\\
a_2\\
a_3\\
a_4\\
a_5\\
a_6\\
a_7\\
a_8\\
a_9\\
a_{10}\\
a_{11}\\
a_{12}\\
a_{13}\\
a_{14}\\
a_{15}\\
\end{bmatrix}+
\begin{bmatrix}
w_1\\
w_2\\
w_3\\
w_4\\
w_5\\
w_6\\
w_7\\
w_8\\
w_9\\
w_{10}\\
w_{11}\\
w_{12}\\
w_{13}\\
w_{14}\\
w_{15}\\
\end{bmatrix}_t
$$

$$
\text{Where }w \sim MVN
\begin{pmatrix}
\text{0,}\begin{bmatrix}
R
\end{bmatrix}
\end{pmatrix}
$$

We start by establishing our U matrix and our Z matrix.


```{r}
U_mat3 <- matrix(c("North","South"),2,1)
#make Z matrix correspond to 2 hidden states
Z_mat3 <- matrix(c(rep(c(0,1),8),
                     rep(c(1,0),7)),15,2, byrow=TRUE)
                     
```


### Hypothesis 3.1

The Q matrix for the variance of process errors is "diagonal and equal" meaning each state (x) model has the same process error but they are not correlated to each other.


```{r}
mod.list3.1 <- list(
  U = U_mat3,
  R = "diagonal and equal",
  Q = "diagonal and equal",
  Z = Z_mat3
)
m3.1 <- MARSS(dat, model = mod.list3.1)
```


This AICc is bad compared to Hypothesis 2. This is either because there is coorelation between the hidden states, as supported by hypothesis two, or the assumption that there are only two underlying states is incorrect. Plots


```{r}
autoplot(m3.1)
```


The southern area (John Day and Cascades) are more informed by data and the fits look ok. The northern area (Yakima and Walla Walla) have large confidence intercals in the early period. The models are fitting data pretty well for individual streams, and while residuals don't seem to have too much structure, some outliers seem to be present for the southern area. The Residuals normality tests are a little wobbly, which is troubling.

Let's look at estimates:


```{r}
print(fit3.1_smooth<-tsSmooth(m3.1))
```


Our corrplots are as expected.


```{r}
Q3.1 <- coef(m3.1, type = "matrix")$Q
corrmat3.1 <- diag(1/sqrt(diag(Q3.1))) %*% Q3.1 %*% diag(1/sqrt(diag(Q3.1)))
corrplot(corrmat3.1)
```


This model probably isn't it. It's failing our normality tests, and while it seems to fit the data ok, it didn't perform as well as hypothesis 2. Let's see how our models improve with different, but uncorrelated process errors.

### Hypothesis 3.2

The Q matrix for the variance of process errors is "diagonal and unequal" meaning each of the four underlying states' process error can be different but they are not correlated to each other.


```{r}
mod.list3.2 <- list(
  U = U_mat3,
  R = "diagonal and equal",
  Q = "diagonal and unequal",
  Z = Z_mat3
)
m3.2 <- MARSS(dat, model = mod.list3.2)
```


This model also has a higher AICc than some of the other models, indicating that the assumption that process errors ARE correlated is likely a better assumption than the diagonal and unequal assumption for the Q matrix.

Let's look at some plots:


```{r}
autoplot(m3.1)
```


This model isn't performing great, which is unsurprising given the lack of correlation in the process errors. The curvy QQ plots remain, and the model CIs are high where there is a lack of data.

What are the estimates


```{r}
print(fit3.2_smooth<-tsSmooth(m3.2))
```


And the corr plot is as expected.


```{r}
Q3.2 <- coef(m3.2, type = "matrix")$Q
corrmat3.2 <- diag(1/sqrt(diag(Q3.2))) %*% Q3.2 %*% diag(1/sqrt(diag(Q3.2)))
corrplot(corrmat3.2)
```


### Hypothesis 3.3

The Q matrix for the variance of process errors is "equal variance and covariance" so they each have equal variance and they are all correlated equally to one another. I would guess this model performs better than the other too, let's see!


```{r}
mod.list3.3 <- list(
  U = U_mat3,
  R = "diagonal and equal",
  Q = "equalvarcov",
  Z = Z_mat3
)
m3.3 <- MARSS(dat, model = mod.list3.3)
```


The AICc is a little better! It seems our correlation hunch is further supported! Let's look at plots:


```{r}
autoplot(m3.3)
```


This model looks ok! The confidence intervals are wider where there is a lack of data, but we are not seeing them balloon out! The residuals don't seem to have clear structure, but there are some outliers, and generally the qq plots by stream appear to be pretty normal, but the two states have lifting at the left tail.

Let's look at estimates:


```{r}
print(fit3.3_smooth<-tsSmooth(m3.3))
```


Let's look at the corrplots:


```{r}
Q3.3 <- coef(m3.3, type = "matrix")$Q
corrmat3.3 <- diag(1/sqrt(diag(Q3.3))) %*% Q3.3 %*% diag(1/sqrt(diag(Q3.3)))
corrplot(corrmat3.3)
```


### Hypothesis 3.4

The Q matrix for the variance of process errors is "unconstrained". Meaning that each hidden state is allowed to vary separately as is the correlation between the underlying states.

I'd expect this model to be the best of hypothesis three, as allowing correlation between the two states seems to improve performance.


```{r}
mod.list3.4 <- list(
  U = U_mat3,
  R = "diagonal and equal",
  Q = "unconstrained",
  Z = Z_mat3
)
m3.4 <- MARSS(dat, model = mod.list3.4)
```


This model performs the best of hypothesis 3 in terms of AICc.

Let's look at plots.


```{r}
autoplot(m3.4)
```


This model isn't fitting all the data particularly well, and there is CLEAR structure in the residuals in X2 (John Day and Cascades). This model isn't gonna cut it, but let's look at the estimates:


```{r}
print(fit3.4_smooth<-tsSmooth(m3.4))
```


And finally the corrplots:


```{r}
Q3.4 <- coef(m3.4, type = "matrix")$Q
corrmat3.4 <- diag(1/sqrt(diag(Q3.4))) %*% Q3.4 %*% diag(1/sqrt(diag(Q3.4)))
corrplot(corrmat3.4)
```


This hypothesis didn't perform as well as anticipated. The two underlying states of nature didn't seem to inform each other very well, and while model fits seemed to improve when the process errors were allowed to correlate, some of the residuals had structure, and residuals didn't appear to be normal. While this hypothesis explored the north and south areas as being separate, hypothesis 2, with four distinct DPCs performed better.

## Hypothesis 4:

Salmon of the Yakima group have to swim the furthest to reach their spawning ground, including a large bend in the river that heads back west. They are the most isolated group and thus may have their own hidden state while the other 3 major population groups maybe more closely linked to each other due to their closer geographic proximity. Thus, we hypothesize that there may be two underlying states describing the entire system. The first describing just the Yakima group while the second describes the Cascades, John Day, and Walla Walla groups.

$$
\text{Hypothesis Four}:
\begin{bmatrix}
y_1\\
y_2\\
y_3\\
y_4\\
y_5\\
y_6\\
y_7\\
y_8\\
y_9\\
y_{10}\\
y_{11}\\
y_{12}\\
y_{13}\\
y_{14}\\
y_{15}\\
\end{bmatrix}_t=
\begin{bmatrix}
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
1 & 0 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
\end{bmatrix}*
\begin{bmatrix}
x_1\\
x_2\\
\end{bmatrix}_t+
\begin{bmatrix}
a_1\\
a_2\\
a_3\\
a_4\\
a_5\\
a_6\\
a_7\\
a_8\\
a_9\\
a_{10}\\
a_{11}\\
a_{12}\\
a_{13}\\
a_{14}\\
a_{15}\\
\end{bmatrix}+
\begin{bmatrix}
w_1\\
w_2\\
w_3\\
w_4\\
w_5\\
w_6\\
w_7\\
w_8\\
w_9\\
w_{10}\\
w_{11}\\
w_{12}\\
w_{13}\\
w_{14}\\
w_{15}\\
\end{bmatrix}_t
$$ $$
\text{Where }w \sim MVN
\begin{pmatrix}
\text{0,}\begin{bmatrix}
R
\end{bmatrix}
\end{pmatrix}
$$

$$
\text{Where }w \sim MVN
\begin{pmatrix}
\text{0,}\begin{bmatrix}
R
\end{bmatrix}
\end{pmatrix}
$$ Hypothesis 4.1: Q matrix is "diagonal and equal" meaning the two hidden, underlying states will have equal variance but will not be correlated to each other.

### Hypothesis 4.1

The Q matrix for the variance of process errors is "diagonal and equal" meaning each state (x) model has the same process error but they are not correlated to each other.


```{r}
U_mat4 <- matrix(c("South_group","Yakima"),2,1)
#make Z matrix correspond to 4 hidden states
Z_mat4 <- matrix(c(rep(c(1,0),3),
                  rep(c(1,0),5),
                  rep(c(1,0),3),
                  rep(c(0,1),4)),15,2, byrow=TRUE)

mod.list4.1 <- list(
  U = U_mat4,
  R = "diagonal and equal",
  Q = "diagonal and equal",
  Z = Z_mat4
)
m4.1 <- MARSS(dat, model = mod.list4.1)
```


On first look, this AICc does ok. Let's look at our plots.


```{r}
autoplot(m4.1)
```


HUGE CIs on hidden state of Yakima group where data is missing. Let's makes sense because with no correlation, the Yakima group isn't being informed by anything.

Yakima continues its positive drift, collective group shows negative drift

QQ plots for Yakima are clearly not normal, but this is likely because of so much missing data.

Let's look at estimates:


```{r}
print(fit4.1_smooth<-tsSmooth(m4.1))
```


The corrplot is as expected.


```{r}
Q4.1 <- coef(m4.1, type = "matrix")$Q
corrmat4.1 <- diag(1/sqrt(diag(Q4.1))) %*% Q4.1 %*% diag(1/sqrt(diag(Q4.1)))
corrplot(corrmat4.1)
#As expected for this Q call

```


The confidence intervals on the underlying state and the fitted values have really big balloon shapes to them where data is missing from each system. The Yakima system, which was assumed to have its own underlying state in this hypothesis, has much large confidence intervals than all the other systems in the fitted values plot. The ACF plots do show that about half of the systems disply autocorrelation in their residuals. The Residuals normality test for the underlying states, X1 (all but Yakima) and X2 (Yakima), show that the residuals for the X2 are not normally distributed as they vary from the qqline to a great degree. The corrplot is relatively uninformative as we forced the Q matrix to be diagonal and equal.

------------------------------------------------------------------------

### Hypothesis 4.2

Q matrix is "diagonal and unequal", meaning the two hidden, underlying states will have the same variance but will not be allowed to be correlated to one another.


```{r}
mod.list4.2 <- list(
  U = U_mat4,
  R = "diagonal and equal",
  Q = "diagonal and unequal",
  Z = Z_mat4
)
m4.2 <- MARSS(dat, model = mod.list4.2)
```


This AICc isn't looking very promising.


```{r}
autoplot(m4.2)
```


This model looks pretty similarly to the last model, which is to say not great. There continues to be very large CIs on hidden state of Yakima group where data is missing, again because there is not data or any correlation from the other underlying state to inform it. The CIs for fitted values show the same pattern qqplots show more variation in the Yakima group.

Let's look at the estimates:


```{r}
print(fit4.2_smooth<-tsSmooth(m4.2))
```


Let's look at the corrplot


```{r}
Q4.2 <- coef(m4.2, type = "matrix")$Q
corrmat4.2 <- diag(1/sqrt(diag(Q4.2))) %*% Q4.2 %*% diag(1/sqrt(diag(Q4.2)))
corrplot(corrmat4.2)
#As expected for this Q call

```


This model, like the previous one, did not perform well with very large confidence intervals for X2 (Yakima), which is not surprising given that there wasn't much informing X2. The Yakima group only has large balloon shaped confidence intervals on its fitted values while the other river systems have some structure to their confidence intervals in sections with missing data. Very similar ACF plots to the other Hypothesis Four models, showing structuring and multiple significant lags in approximately half of the plots. The variance was allowed to vary independently between the two underlying states but they were estimated to be very similar to one another

------------------------------------------------------------------------

### Hypothesis 4.3

The Q matrix is "equal variance and covariance". This will result in both of the hidden, underlying states having the same variance and they will be correlated to one another. This model should perform better than the previous models.


```{r}
mod.list4.3 <- list(
  U = U_mat4,
  R = "diagonal and equal",
  Q = "equalvarcov",
  Z = Z_mat4
)
m4.3 <- MARSS(dat, model = mod.list4.3)
```


This model did in fact perform better based on AICc! Let's look at our plots:


```{r}
autoplot(m4.3)
```


This model looks much better, with tighter confidence levels that are being informed with the correlated process errors. However, there is a clear residual pattern in X2 (Yakima) which also has a wiggly QQ plot. Meanwhile X1 has a fat left tail.

Let's look at the estimates:


```{r}
print(fit4.3_smooth<-tsSmooth(m4.3))
```


Let's look at the corrplots


```{r}
Q4.3 <- coef(m4.3, type = "matrix")$Q
corrmat4.3 <- diag(1/sqrt(diag(Q4.3))) %*% Q4.3 %*% diag(1/sqrt(diag(Q4.3)))
corrplot(corrmat4.3)
```


The confidence intervals for the underlying states and the fitted values now fit the estimated abundance in each river well rather than being oval shaped over any missing values. There were very similar ACF plots to the other models in this model with about half of them showing sine wave patterns. The variance-covariance matrix was forced to be equal.

------------------------------------------------------------------------

### Hypothesis 4.4

The Q matrix is "unconstrained". Meaning the two hidden, underlying states will be allowed to vary independently of one another and correlation is allowed to vary between the two states.


```{r}
mod.list4.4 <- list(
  U = U_mat4,
  R = "diagonal and equal",
  Q = "unconstrained",
  Z = Z_mat4
)
m4.4 <- MARSS(dat, model = mod.list4.4)
```


This model did just a little worse than the model with a U matrix that had equal variance and covariance. Let's look at plots:


```{r}
autoplot(m4.4)
```


While this model does ok in some streams, it's missing data in places, X2 (Yakima) has a clear residual structure and the QQ plot is very wiggly. X1 (the rest) does ok, but there are some outliers and the QQ plot continues to have a fat left tail.

Let's look at estimates:


```{r}
print(fit4.4_smooth<-tsSmooth(m4.4))
```


Finally we'll look at corrplots. As hinted at by the model output there is very high correlation even though this was an unconstrained model.


```{r}
Q4.4 <- coef(m4.4, type = "matrix")$Q
corrmat4.4 <- diag(1/sqrt(diag(Q4.4))) %*% Q4.4 %*% diag(1/sqrt(diag(Q4.4)))
corrplot(corrmat4.4)

```


The confidence intervals on the underlying state and the fitted values fit the estimated abundances well in areas with missing data. QQplots for X1 (all but Yakima) had a fat left tail and X2 (Yakima) had a lot of structure in the residuals and wiggly QQ plots. The AFC plots show many of the streams have autocorrelated residuals. Even though this hypothesis allowed the Q matrix to be unconstrained, it still estimated variances and covariances that were essentially equal to the "equal variance and covariance" hypothesis.

------------------------------------------------------------------------

## AICc Results and Selected Model


```{r}
mods <- c("1","2.1","2.2","2.3","2.4","3.1","3.2", "3.3", "3.4","4.1","4.2","4.3","4.4")
aic <- c(m1$AICc, m2.1$AICc, m2.2$AICc, m2.3$AICc, m2.4$AICc,m3.1$AICc, m3.2$AICc, m3.3$AICc, m3.4$AICc, m4.1$AICc, m4.2$AICc, m4.3$AICc, m4.4$AICc)
daic <- aic-min(aic)
tab <- cbind.data.frame(mods, aic, daic)
kable(tab, col.names = c("Hypothesis", "AICc", "delta AICc"))
```


The best model is Hypothesis 2.4 where it is assumed that the four main population groups form separate sub-populations. In this hypothesis we are utilizing 4 separate underlying states to model the observations from each of the main population groups. The Q matrix for the variance of process errors is "unconstrained". Meaning that each hidden state is allowed to vary separately as is the correlation between the underlying states.

## Cycling considerations for best model

### Simple Cycling

First we try a simple approach as outlined in example code and assume a periodicity of about four years, as seen in some of the ACF plots.


```{r}

TT <- years
p <- 4 #try a period of 4

Z <- array(1, dim = c(15, 3, TT))
Z[1, 2, ] <- sin(2 * pi * (1:TT)/p)
Z[1, 3, ] <- cos(2 * pi * (1:TT)/p)

mod.list_test <- list(U = "zero", 
                      Q = "diagonal and unequal", 
                      Z = Z, 
                      A = "zero")

m <- dim(Z)[2]
m_test <- MARSS(dat, model = mod.list_test, inits = list(x0 = matrix(0,m, 1)))
```


This model struggled to converge and did pretty poorly in terms of AICc.

Let's look at some plots:


```{r}
plot_test<-autoplot(m_test)
```


To be honest, with the U matrix equal to 0, I'm unsure what states we're looking at. But they get worse as we go from X1, to X2, to X3 in terms of CI, residual patterns and QQ plots. Additionally, some of the models are completly missing data.

Corrplot is as expectd with the Q matrix set to diagonal and unequal.


```{r}
Qtest <- coef(m_test, type = "matrix")$Q
corrmat_test <- diag(1/sqrt(diag(Qtest))) %*% Qtest %*% diag(1/sqrt(diag(Qtest)))
corrplot(corrmat_test)
```


This model isn't it. Let's move onto a model based on our best performer with cycling considerations.

### Hypthothesis 2.4 with Cycling

For this section, we're going to explore 2 cycling options, 4 years and 9 years, as these are period where salmon are generally known to cycle (I think....need a source).

#### Four Years

We'll use the U and Z matrices from Hypothesis 2:


```{r}
U_cyl <- matrix(c("Cascades","JohnDay","Walla","Yakima"),4,1)

Z_cyl <- matrix(c(rep(c(1,0,0,0),3),
                  rep(c(0,1,0,0),5),
                  rep(c(0,0,1,0),3),
                  rep(c(0,0,0,1),4)),15,4, byrow=TRUE)
```


And we'll set up a co-variate matrix to allow for some cycling and set up our model list with Q unconstrained, and D unconstrained.


```{r}
d_cyl <- matrix(0,2,TT)

d_cyl[1,] <- sin(2 * pi * (1:TT)/p)
d_cyl[2,] <- cos(2 * pi * (1:TT)/p)


 
mod.list <- list(U = U_cyl, 
                 Q = "unconstrained",
                 Z = Z_cyl, 
                 A = "zero",
                 D="unconstrained",
                 d = d_cyl) 

m <- dim(Z_cyl)[2]
m_cyl_4 <- MARSS(dat, model = mod.list, inits = list(x0 = matrix(0, m, 1)))
```


Wow, this model AICc is BAD.


```{r}
autoplot(m_cyl_4)
```


Well, this model does very poorly. The model is missing data, there are residual patterns in all four states, the QQ plots aren't all terrible but not totally normal and there is some temporal correlation in the ACFs.

Let's look at the corrplot:


```{r}
Q_4 <- coef(m_cyl_4, type = "matrix")$Q
corrmat_4 <- diag(1/sqrt(diag(Q_4))) %*% Q_4 %*% diag(1/sqrt(diag(Q_4)))
corrplot(corrmat_4)
```


The unconstrained Q matrix shows that there is a fair amount of correlation between states. This model overall is MUCH WORSE than no cycling.

Will different cycling assumptions perform any better?

#### Nine Years

And we'll set up a co-variate matrix and change the p to 9.


```{r}
d_cyl <- matrix(0,2,TT)

p<-9

d_cyl[1,] <- sin(2 * pi * (1:TT)/p)
d_cyl[2,] <- cos(2 * pi * (1:TT)/p)


 
mod.list <- list(U = U_cyl, 
                 Q = "unconstrained",
                 Z = Z_cyl, 
                 A = "zero",
                 D="unconstrained",
                 d = d_cyl) 

m <- dim(Z_cyl)[2]
m_cyl_9 <- MARSS(dat, model = mod.list, inits = list(x0 = matrix(0, m, 1)))
```


This model converged, but still has a bad AIC. this model AICc is BAD.


```{r}
autoplot(m_cyl_9)
```


This model performs similarly to the last model. Cycling my 9 years doesn't seem to have improved anything.

Let's look at the corrplot: They are pretty similar to the last model.


```{r}
Q_9 <- coef(m_cyl_9, type = "matrix")$Q
corrmat_9 <- diag(1/sqrt(diag(Q_9))) %*% Q_9 %*% diag(1/sqrt(diag(Q_9)))
corrplot(corrmat_9)
```


### AICc Results for Cycling


```{r}
mods_cyl <- c("2.4","m_test","m_cyl_4", "m_cyl_9")
aic_cyl <- c(m2.4$AICc, m_test$AICc, m_cyl_4$AICc, m_cyl_9$AICc)
daic_cyl <- aic_cyl-min(aic_cyl)
tab2 <- cbind.data.frame(mods_cyl, aic_cyl, daic_cyl)
kable(tab2, col.names = c("Hypothesis", "AICc", "delta AICc"))
```


The cycling assumptions tested in this excersize clearly worsened model fits.

# Discussion

Ultimately the most informative model for streams with missing data was the model tested in hypothesis 2.4, which assumed four underlying states, one for each of the main distinct population centers (DPC), the Cascades, John Day, Walla Walla, and Yakima tributaries, where the Q matrix was unconstrained allowing for correlation in the process errors.

Based on initial results, cycling only worsened fits, but only one method and two periods, 4 and 9 were tests, so perhaps with more exploraiton cycling considerations would have improved model fits.

Ultimately, the model that assumed four states performed the best, and from this we can interpret that while salmon generally return to their native streams, there is correlation in the systems, and allowing the models to explore that correlation in process error freely resulting in the best model fits and lowest confidence intervals.

# Description of each team member's contributions

Dylan: Hypothesis conceptualization, code for hypothesis 2 and 4, matrix display code, and AICc comparison methods. Madison: Hypothesis 1 and 3, cycling code, and Rmarkdown formatting.

Both Dylan and Madi helped to write the report.

