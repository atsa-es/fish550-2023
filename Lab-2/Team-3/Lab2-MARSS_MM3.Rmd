---
title: Lab 2 Analyzing multivariate salmon data
author: E Holmes
date: April 13, 2023
output: 
  html_document:
    code-folding: true
    toc: true
    toc_float: true
---

```{r message=FALSE}
library(tidyverse)
options(dplyr.summarise.inform = FALSE)
```
## Objective 

For this lab you will use multivariate auto-regressive state-space (MARSS) to analyze multivariate salmon data from the Columbia River. These data are noisy and gappy. They are estimates of total spawner abundance and might include hatchery spawners.


## Team 3 

Lower Columbia River Coho: Nick Chambers (SAFS), Karl Veggerby (SAFS), Miranda Mudge (Molecular & Cellular)


## Lower Columbia River salmon spawner data

These data are from the [Coordinated Assessments Partnership (CAP)](https://www.streamnet.org/cap/about-cap/) and downloaded using the [rCAX R client](https://nwfsc-math-bio.github.io/rCAX/) for the CAX (the CAP database) API. The data are saved in `Lab-2/Data_Images/columbia-river.rda`.

```{r}
load(here::here("Lab-2", "Data_Images", "columbia-river.rda"))
```

The data set has data for fi endangered and threatened ESU (Evolutionary Significant Units) in the Lower Columbia River.

```{r}
esu <- unique(columbia.river$esu_dps)
esu
```

```{r echo=FALSE, out.width="50%", eval = FALSE, fig.cap="Figure from ESA recovery plan for Lower Columbia River Coho salmon, Lower Columbia River Chinook salmon, Columbia River Chum salmon, and Lower Columbia River steelhead. 2013. NMFS NW Region.  https://repository.library.noaa.gov/view/noaa/16002"}
knitr::include_graphics("Data_Images/LCR-chinook-regions.png")
```

### Data structure

The dataset has the following columns

```{r}
colnames(columbia.river)
```

-   species: Chinook, Coho, Steelhead
-   esu_dps: name of the ESU
-   majorpopgroup: biological major group
-   commonpopname: common population name, generally a stream or river
-   run: run-timing
-   spawningyear: the year that the spawners were counted on the spawning grounds
-   value: total (natural-born and hatchery-born) spawners on the spawning ground. Generally some type of redd-count expansion or some other stream count of spawners. Redd = a gravel nest.

### Data plots

Let's load one ESU and make a plot. Create a function.

```{r}
plotesu <- function(esuname){
  df <- columbia.river %>% subset(esu_dps %in% esuname)
ggplot(df, aes(x=spawningyear, y=log(value), color=majorpopgroup)) + 
  geom_point(size=0.2, na.rm = TRUE) + 
  theme(strip.text.x = element_text(size = 3)) +
  theme(axis.text.x = element_text(size = 5, angle = 90)) +
  facet_wrap(~esapopname) +
  ggtitle(paste0(esuname, collapse="\n"))
}
```

The following plot was created to visualize the data and select regions to train a model on. Su
```{r}
plotesu(esu[4])
```


```{r}
df <- columbia.river %>% subset(species == "Coho salmon")
ggplot(df, aes(x=spawningyear, y=log(value), color=run)) + 
  geom_point(size=0.2, na.rm = TRUE) +
  theme(strip.text.x = element_text(size = 3)) +
  theme(axis.text.x = element_text(size = 5, angle = 90)) + 
  facet_wrap(~esapopname)
```

## Tasks for each group

1.  Create estimates of spawner abundance for all missing years and provide estimates of the decline from the historical abundance.

2.  Evaluate support for the major population groups. Are the populations in the groups more correlated than outside the groups?

3.  Evaluate the evidence of cycling in the data. *We will talk about how to do this on the Tuesday after lab.*

### Tips

**Simplify**

If your ESU has many populations, start with a smaller set of 4-7 populations.

**Assumptions**

You can assume that `R="diagonal and equal"` and `A="scaling"`. Assume that "historical" means the earliest years available for your group.

**States**

Your abundance estimate is the "x" or "state" estimates. You can get this from

```         
fit$states
```
```{r}
fit$states
```

or

```         
tsSmooth(fit)
```

where `fit` is from `fit <- MARSS()`

**plotting**

Estimate of the mean of the spawner counts based on your x model.

```         
autoplot(fit, plot.type="fitted.ytT")
```

**diagnostics**

```         
autoplot(fit, plot.type="residuals")
```

### Address the following in your methods

-   Describe your assumptions about the x and how the data time series are related to x.

    -   How are the x and y (data) related? 1 x for 1 y or will you assume 1 x for all y or 1 x for each major population group? How will you choose?
    -   What will you assume about the U for the x's?
    -   What will you assume about the Q matrix?

-   Write out your assumptions as different models **in matrix form**, fit each and then compare these with AIC or AICc.

-   Do your estimates differ depending on the assumptions you make about the structure of the data, i.e. you assumptions about the x's, Q, and U.

## Sample code

Here I show how I might analyze the Upper Columbia Steelhead data.

```{r echo=FALSE, out.width="50%", eval = FALSE, fig.cap="Figure from 2022 5-Year Review: Summary & Evaluation of Upper Columbia River Spring-run Chinook Salmon and Upper Columbia River Steelhead. NMFS. West Coast Region. https://doi.org/10.25923/p4w5-dp31"}
knitr::include_graphics("Data_Images/UCR-Steelhead-regions.png")
```

Set up the data. We need the time series in a matrix with time across the columns.

Load the data.

```{r}
load(here::here("Lab-2", "Data_Images", "columbia-river.rda"))
```

Data was formatted for visualization. 

```{r}
library(dplyr)
esuname <- esu[4]

dat <- columbia.river %>% 
  subset(esu_dps == esuname) %>% # get only this ESU
  mutate(log.spawner = log(value)) %>% # create a column called log.spawner
  select(esapopname, spawningyear, log.spawner) %>% # get just the columns that I need
  pivot_wider(names_from = "esapopname", values_from = "log.spawner") %>% 
  column_to_rownames(var = "spawningyear") %>% # make the years rownames
  as.matrix() %>% # turn into a matrix with year down the rows
  t() # make time across the columns
# MARSS complains if I don't do this
dat[is.na(dat)] <- NA
```

Clean up the row names

```{r}
tmp <- rownames(dat)
tmp <- stringr::str_replace(tmp, "Salmon, coho [(]Lower Columbia River ESU[)]", "")
tmp <- stringr::str_trim(tmp)
rownames(dat) <- tmp
```

Select a subset of rivers to test

```{r}
mod_rivers <- c("Sandy River - early and late", 
           "Grays and Chinook Rivers - late", 
           "Clatskanie River - late", 
           "Lower Gorge Tributaries - late", 
           "Tilton River - early and late" , 
           "Oregon Upper Gorge Tributaries and Hood River - early")

sub_dat <- dat[rownames(dat) %in% mod_rivers, ] 
```

Specify a model

```{r}
# Model 1: all regions are behaving independently but observations were collected similarly
## each region has it's own drift where U = unequal 
## variance is diagonal and equal due to similar methods for collecting observations
mod.list1 <- list(
  U = "unequal",
  R = "diagonal and equal",
  Q = "unconstrained"
)

# Model 2: all regions are reflecting 1 underlying state with equal variance
## 1 underlying state where U = equal
## variance is diagonal and equal due to similar methods for collecting observations
mod.list2 <- list(
  U = "equal",
  R = "diagonal and equal",
  Q = "unconstrained"
)

# Model 3: flexible model with unequal observation variance and a matrix for drift and state variance
## set scaling on B as 1
## U bias is matrix
## variance Q is matrix 
## variance R is diagonal and unequal to account for potential differences in observation error, ie different methods
## A intercept can change as needed 
## Z matrix ... 
mod.list3 <- list(B = matrix(1), 
                   U = matrix("u"), 
                   Q = matrix("q"), # 1 X
                   Z = matrix(1, 6, 1), 
                   A = "scaling", # default
                   R = "diagonal and unequal", # single column of 1s for Y
                   x0 = matrix("mu"), 
                   tinitx = 0)

# Model 4: flexible model for independent regions
## B and Z scale to size of matrix, all 1's
## U = bias = independent matrix set to size of dataframe
## Q = variance in state = independent variances
## R variance is diagonal and equal due to similar methods for collecting observations
mod.list4 <- list(B = diag(1,6), 
                  U = matrix("u",6,1), 
                  Q = "diagonal and unequal", 
                  Z = diag(1,6), 
                  A = "scaling", # default
                  R = "diagonal and equal", 
                  x0 = "unequal", 
                  tinitx = 0)

# Model 5: keep it simple. Each region has an independent state, observation variance is the same, and one process variance with one covariance. 
mod.list5 <- list(
  U = "unequal",
  R = "diagonal and equal",
  Q = "equalvarcov"
)

```
Notes for Miranda: 

The a parameter has a special option, "scaling", which is the default
behavior. In this case, a is treated like a scaling parameter. If there is only
one y row associated with an x row, then the corresponding a element is
0. If there are more than one y rows associated with an x row, then the
first a element is set to 0 and the others are estimated. 

Q="unconstrained": There are values on the diagonal and the off-diagonals
of Q and the variances and covariances are all different. 

Q="equalvarcov": There is one process variance and one covariance:


-----------------------------------------------------------------------------------


Fit the model. In this case, a BFGS algorithm is faster.

```{r}
library(MARSS)
fit1 <- MARSS(sub_dat, model=mod.list1, method="BFGS")
fit2 <- MARSS(sub_dat, model=mod.list2, method="BFGS")
fit3 <- MARSS(sub_dat, model=mod.list3)
fit4 <- MARSS(sub_dat, model=mod.list4)
fit5 <- MARSS(sub_dat, model=mod.list5, control = list(maxit=1000))

```

Plot fits

```{r}
plot.mod1 <- autoplot(fit1, plot.type="fitted.ytT")
plot.mod2 <- autoplot(fit2, plot.type="fitted.ytT")
plot.mod3 <- autoplot(fit3, plot.type="fitted.ytT")
plot.mod4 <- autoplot(fit4, plot.type = "fitted.ytT")
plot.mod5 <- autoplot(fit5, plot.type="fitted.ytT")
```

Evaluate correlation between regions

```{r}
# change fit# to evaluate correlation between regions in different models 

library(corrplot)
Q <- coef(fit1, type="matrix")$Q
corrmat <- diag(1/sqrt(diag(Q))) %*% Q %*% diag(1/sqrt(diag(Q)))
corrplot(corrmat)

```
Note: Correlation matrix of 6 test regions shows high correlation between Clatskanie River and Grays and Chinook Rivers, indicating the potential of these regions behaving as 1 sub-population. This will be tested in the next section. 

------------------
AICc 

```{r}
aic <- c(fit1$AICc, fit2$AICc, fit3$AICc, fit4$AICc, fit5$AICc )
aic-min(aic) #delta AICc 
```

----------------------------------------------------------------
### note: not sure if we need this section (295-305)
Evaluating fit of states by looking at plots and residuals


```{r}
fit5$states
tsSmooth(fit5)
autoplot(fit5, plot.type="fitted.ytT")
 # autoplot(fit3, plot.type="residuals") # not sure if we need this...
```
----------------------------------------------------------------

# Test different regions as sub-groups: 
We also wanted to look into the potential of regions behaving as sub-populations based on major population group, our initial correlation analysis, and some geographic assumptions after looking at a map of the rivers and thinking about salmon swimming patterns. 

Comparing 3 sub-populations: cascade, coast, and gorge
```{r}
mod.list6 <- list(#B = matrix(1), # B = "identity" 3x3 matrix
                  # U = matrix("u"), #needs 3 rows U = "equal" or "unequal" # default = unequal
                   Q = "unconstrained", # 1 X
                   Z = factor(c("cascade", "cascade", 
                                "coast", "coast", 
                                "gorge", "gorge")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   #x0 = matrix("mu"), # x0 = default 
                   tinitx = 0)


fit6 <- MARSS(sub_dat, model = mod.list6)
autoplot(fit6, plot.type="fitted.ytT")
```
 
Based on the correlation plot, the grays and chinook rivers and the lower gorge tributaries are highly correlated. We want to evaluate a model with these regions as a sub-population. 

Comparing 2 sub-populations: grays/chinook rivers and lower gorge "GCL" and all other test regions "STCU"
```{r}
mod.list7 <- list(Q = "unconstrained", # 1 X
                  Z = factor(c("STCU", "STCU", 
                                "STCU", "GCL", 
                                "GCL", "STCU")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   tinitx = 0)


fit7 <- MARSS(sub_dat, model = mod.list7)
autoplot(fit7, plot.type="fitted.ytT")
```

While the description "cascades" only describes a couple regions in our test set, we decided to test a model separating the general cascades from the 2 coast regions (Clatskaine and Gray/Chinook) because geographically there is a large separation. 

Comparing 2 sub-populations: coast "coast" and all other test regions "casgor"
```{r}
mod.list8 <- list(Q = "unconstrained", # 1 X
                  Z = factor(c("casgor", "casgor", 
                                "coast", "coast", 
                                "casgor", "casgor")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   tinitx = 0)


fit8 <- MARSS(sub_dat, model = mod.list8)
autoplot(fit8, plot.type="fitted.ytT")
```

## compare the new models using AICc

```{r}
aic <- c(fit3$AICc, fit6$AICc, fit7$AICc, fit8$AICc )
aic-min(aic) #delta AICc 
```

Our new analysis of sub-populations indicates that some of the regions do behave as some populations. The new best model builds off of the predictions from the correlation analysis, with the Grays/Chinook Rivers and the Lower Gorge Tributaries behaving as 1 sub-population. Additionally, the model treating major populaton groups as sub-populations perfomred better than our original model, suggesting that incorporating your knowledge of the system (biological and geographic) can help inform your model. 

---------------------------------------------------------------
### Including cycling - using our coho data, full time series

Because we know that salmon have spawning cycles, we wanted to consider incorporating the idea that this underlying seasonality could allow us to generate a better fitting model. To do this, we incorporated seasonality as a covariate in a new model below. We tested 5 and 10 year cycles after looking back at our data, specifically of the Sandy River which has good ESU coverage across the testing regions. 


Cycling possible in Tilton River. 
```{r}
par(mfrow=c(2,2))
for(i in 1:4){
  acf(sub_dat[i,], na.action=na.pass, main=rownames(sub_dat)[i])
}
```

## evidence of cycling in Tilton

Based on looking at the data, we decided to test for cycling with frequency 5 or 10 years. 

```{r}
TT <- dim(sub_dat)[2] #number of time steps
covariates <- rbind(
  forecast::fourier(ts(1:TT, freq=5), K=1) |> t(),
  forecast::fourier(ts(1:TT, freq=10), K=1) |> t()
)
str(TT)
```

## note renaming model
Now let's fit a model with these covariates. Let's analyze the populations separately, so Q is diagonal.
```{r}
mod.list9 <- list(
  Q = "unconstrained", # different varcov
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates
)

mod.list10 <- list(
  Q = "equalvarcov",
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates
)
```
  
```{r acf-entiat}
fit9 <- MARSS(sub_dat, model=mod.list9)
fit10 <- MARSS(sub_dat, model=mod.list10)


plot.mod9 <- autoplot(fit9, plot.type="fitted.ytT")
plot.mod10 <- autoplot(fit10, plot.type="fitted.ytT")

```

------------------------------------------------------------------------
## This part doesn't work yet
Let's plot the estimates. `broom::tidy()` will get a data frame with the terms, estimates and CIs.

Here we're looking at Model 9. 
```{r}
library(broom)
df <- tidy(fit9) %>% #confidence estimates
  subset(stringr::str_sub(term,1,1)=="D") #only D parameters
df$lag <- as.factor(rep(c(5,10), each=12)) #label lags
df$river <- as.factor(rep(rownames(sub_dat),4)) #rownames on repeat
df$sc <- rep(rep(c("S", "C"), each=6), 2) #each sin cos 6 times, 2 test freq
df$type <- paste0(df$sc,df$lag)
```

We can then plot this. Interesting. Some support for 5 year cycles.
```{r}
ggplot(df, aes(x=type, y=estimate, col=lag)) + 
  geom_point() +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.up), width=.2, position=position_dodge(.9)) +
  geom_hline(yintercept = 0) +
  facet_wrap(~river) +
  ggtitle("The cycle estimates for Model 9")
```
The cosine estimates, particularly for the Upper Gorge Tributaries and Hood River, indicate the potentia for a seasonal cycle that peaks every 10 years. We encountered a Hessian error in our code that prevented us from plotting confidence intervals for this data, but decided not to address further after consulting with Eli. 

Here we're looking at Model 10. 
```{r}
df <- tidy(fit10) %>% #confidence estimates
  subset(stringr::str_sub(term,1,1)=="D") #only D parameters
df$lag <- as.factor(rep(c(5,10), each=12)) #label lags
df$river <- as.factor(rep(rownames(sub_dat),4)) #rownames on repeat
df$sc <- rep(rep(c("S", "C"), each=6), 2) #each sin cos 6 times, 2 test freq
df$type <- paste0(df$sc,df$lag)
```

```{r}
ggplot(df, aes(x=type, y=estimate, col=lag)) + 
  geom_point() +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.up), width=.2, position=position_dodge(.9)) +
  geom_hline(yintercept = 0) +
  facet_wrap(~river) +
  ggtitle("The cycle estimates for Model 10")
```
The same analysis but with an equal variance covariance matrix estimated for Q still highlights the potential for a 10 year cycle, this time with the Tilton River. 

------------------------------------------------------------------------
Evaluate AICc for seasonality against our current best model 7. 

```{r}
aic <- c(fit7$AICc, fit9$AICc, fit10$AICc )
aic-min(aic) #delta AICc 
```

The equal variance covariance matrix for Q was better, but still not as good as our current best model. Now we'll try building a model with just the 10 year cycle as that best explains the potential seasonality in the data, using the same code from above. 

```{r}
TT <- dim(sub_dat)[2] #number of time steps
covariates_10 <- rbind(
  forecast::fourier(ts(1:TT, freq=10), K=1) |> t()
)
str(TT)

mod.list11 <- list(
  Q = "equalvarcov",
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates_10
)

fit11 <- MARSS(sub_dat, model=mod.list11)
```

```{r}
aic <- c(fit7$AICc, fit11$AICc )
aic-min(aic) #delta AICc 
```
Narrowing down to just a 10 year cycle improved the model, but the seasonality still doesn't help the model as a covariate. 

Ultimately, the best model for predicting historical data for Coho salmon is Model 7: sub-grouping the grays and chinook rivers and the lower gorge tributaries based on a correlation analysis. 

# Fit the best model

Here we predict historical data for all regions using our best model from the initial analysis. One caveat to this approach is that our correlation analysis was performed on a test set, with model 7 specifying Z based on this data. This yields the best model, but is more difficult to fit to historical data based on the information available to us now. 

Future directions should include evaluating the correlation between all the regions to evaluate if other regions would fit into the same sub-group as the grays/chinook and lower gorge. Because there isn't an obvious indicator variable that separates these regions from other regions in our test set, more analysis is needed to identify what is driving this separation of states. 



## Miranda's attempt at fitting our best model...but probably shouldn't include because it isn't complete and doesn't really make biological sense to continue without further work detailed above. 
```{r}
mod.list.test <- list(B = matrix(1), 
                   U = matrix("u"), 
                   Q = matrix("q"), # 1 X
                   Z = matrix(1, 23, 1), 
                   A = "scaling", # default
                   R = "diagonal and unequal", # single column of 1s for Y
                   x0 = matrix("mu"), 
                   tinitx = 0)

mod.list.full <- list(Q = "unconstrained", # 1 X
                  Z = factor(c("STCU", "STCU", 
                                "STCU", "GCL", 
                                "GCL", "STCU")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   tinitx = 0)


fit.test <- MARSS(dat, model = mod.list.test)
fit_full <- MARSS(dat, model = mod.list.full, control = list(maxit=1000))

#autoplot(fit7, plot.type="fitted.ytT")
```


----------------------------------------------------------------


## Contributions - add your contributions! 

We tackled this lab by having multiple group meetings to brainstorm strategies, test code, and plan progress. Miranda adapted code from the Lab2-MARSS document to the Coho data, acted as scribe for testing code during group meetings, contributed ideas for selecting models to test, and annotated many of the models for report generation. 
