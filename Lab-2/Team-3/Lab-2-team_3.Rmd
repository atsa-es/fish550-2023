# Lab 2: MARSS models

Team member names: Miranda Mudge, Karl Veggerby, Nick Chambers

# Data

We were assigned the Lower Columbia Coho data set. We selected two rivers from each Major Population Group (MPG) to test the performance of several models. The selected populations are:

Cascade MPG - 
Tilton and Sandy Rivers

Gorge MPG
Upper and Lower Gorge Tributaries

Coast MPG
Clatskanie, and Grays/Chinook Rivers

```{r, echo=TRUE}
library(tidyverse)
library(MARSS)

# Load the data
load(here::here("Lab-2", "Data_Images", "columbia-river.rda"))
```


```{r, echo=TRUE}
#plot the data
esu <- unique(columbia.river$esu_dps)
plotesu <- function(esuname){
  df <- columbia.river %>% subset(esu_dps %in% esuname)
ggplot(df, aes(x=spawningyear, y=log(value), color=majorpopgroup)) + 
  geom_point(size=0.2, na.rm = TRUE) + 
  theme(strip.text.x = element_text(size = 3)) +
  theme(axis.text.x = element_text(size = 5, angle = 90)) +
  facet_wrap(~esapopname) +
  ggtitle(paste0(esuname, collapse="\n"))
}

plotesu(esu[4])

```

Wrangle the data.

```{r, echo=TRUE}

#format for visualization

library(dplyr)
esuname <- esu[4]

dat <- columbia.river %>% 
  subset(esu_dps == esuname) %>% # get only this ESU
  mutate(log.spawner = log(value)) %>% # create a column called log.spawner
  select(esapopname, spawningyear, log.spawner) %>% # get just the columns that I need
  pivot_wider(names_from = "esapopname", values_from = "log.spawner") %>% 
  column_to_rownames(var = "spawningyear") %>% # make the years rownames
  as.matrix() %>% # turn into a matrix with year down the rows
  t() # make time across the columns
# MARSS complains if I don't do this
dat[is.na(dat)] <- NA
```

Clean up the row names

```{r}
tmp <- rownames(dat)
tmp <- stringr::str_replace(tmp, "Salmon, coho [(]Lower Columbia River ESU[)]", "")
tmp <- stringr::str_trim(tmp)
rownames(dat) <- tmp
```

Select a subset of rivers to test

```{r}
mod_rivers <- c("Sandy River - early and late", 
           "Grays and Chinook Rivers - late", 
           "Clatskanie River - late", 
           "Lower Gorge Tributaries - late", 
           "Tilton River - early and late" , 
           "Oregon Upper Gorge Tributaries and Hood River - early")

sub_dat <- dat[rownames(dat) %in% mod_rivers, ] 
```

# Methods
You can assume that `R="diagonal and equal"` and `A="scaling"`.

Address the following in your methods

* Describe your assumptions about the x and how the data time series are related to x.

   - How are the x and y (data) related? 1 x for 1 y or will you assume 1 x for all y or 1 x for each major population group? How will you choose? 
   - What will you assume about the U for the x's?
   - What will you assume about the Q matrix?
   
* Write out your assumptions as different models **in matrix form**, fit each and then compare these with AIC or AICc.

* Do your estimates differ depending on the assumptions you make about the structure of the data, i.e. you assumptions about the x's, Q, and U.



Here took our assumptions and used them to generate five models to test

```{r}

# Model 1: all regions are behaving independently but observations were collected similarly
## each region has it's own drift where U = unequal 
## variance is diagonal and equal due to similar methods for collecting observations
mod.list1 <- list(
  U = "unequal",
  R = "diagonal and equal",
  Q = "unconstrained"
)

# Model 2: all regions are reflecting 1 underlying state with equal variance
## 1 underlying state where U = equal
## variance is diagonal and equal due to similar methods for collecting observations
mod.list2 <- list(
  U = "equal",
  R = "diagonal and equal",
  Q = "unconstrained"
)

# Model 3: flexible model with unequal observation variance and a matrix for drift and state variance
## set scaling on B as 1
## U bias is matrix
## variance Q is matrix 
## variance R is diagonal and unequal to account for potential differences in observation error, ie different methods
## A intercept can change as needed 
## Z matrix ... 
mod.list3 <- list(B = matrix(1), 
                   U = matrix("u"), 
                   Q = matrix("q"), # 1 X
                   Z = matrix(1, 6, 1), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   x0 = matrix("mu"), 
                   tinitx = 0)

# Model 4: flexible model for independent regions
## B and Z scale to size of matrix, all 1's
## U = bias = independent matrix set to size of dataframe
## Q = variance in state = independent variances
## R variance is diagonal and equal due to similar methods for collecting observations

mod.list4 <- list(B = diag(1,6), 
                  U = matrix("u",6,1), 
                  Q = "diagonal and unequal", 
                  Z = diag(1,6), 
                  A = "scaling", 
                  R = "diagonal and equal", 
                  x0 = "unequal", 
                  tinitx = 0)

# Model 5: keep it simple. Each region has an independent state, observation variance is the same, and one process variance with one covariance. 
mod.list5 <- list(
  U = "unequal",
  R = "diagonal and equal",
  Q = "equalvarcov"
)
```


Here we fit the model. ##In this case, a BFGS algorithm is faster##
Is the BFGS text leftover from Eli ? I see we only used it on two models.

```{r}
library(MARSS)
fit1 <- MARSS(sub_dat, model=mod.list1, method="BFGS")
fit2 <- MARSS(sub_dat, model=mod.list2, method="BFGS")
fit3 <- MARSS(sub_dat, model=mod.list3)
fit4 <- MARSS(sub_dat, model=mod.list4)
fit5 <- MARSS(sub_dat, model=mod.list5, control = list(maxit=1000))

```

Here we plot the fit of the models to visually check the model performance

```{r}
plot.mod1 <- autoplot(fit1, plot.type="fitted.ytT")
plot.mod2 <- autoplot(fit2, plot.type="fitted.ytT")
plot.mod3 <- autoplot(fit3, plot.type="fitted.ytT")
plot.mod4 <- autoplot(fit4, plot.type = "fitted.ytT")
plot.mod5 <- autoplot(fit5, plot.type="fitted.ytT")
```


Here we further tested the model fit by examining the corrplot to see which rivers were most closely correlated to see if that fit with our assumptions.

```{r}
# change fit# to evaluate correlation between regions in different models 

library(corrplot)
Q <- coef(fit1, type="matrix")$Q
corrmat <- diag(1/sqrt(diag(Q))) %*% Q %*% diag(1/sqrt(diag(Q)))
corrplot(corrmat)

```
Note: Correlation matrix of 6 test regions shows high correlation between Clatskanie River and Grays and Chinook Rivers, indicating the potential of these regions behaving as 1 sub-population. This will be tested in the next section. 

**diagnostics**

Testing for model performance using AICc

```{r}
aic <- c(fit1$AICc, fit2$AICc, fit3$AICc, fit4$AICc, fit5$AICc)
aic-min(aic) #delta AICc 
```

A comparison of delta AICc indicates that model 3 is the best fit for the data. There are no other models within delta AICc of 2.0 or less. There are two alternative models within delta AICc of 5.0, but no compelling reason to use those over the cearly top model. Model 3 was the best out of the five models tested, so we'll use that one to estimate historical abundances. This is not to say that model 3 is the best model possible for this data, only that it's the best model out of the 5 that we compared. 


We then valuated the fit of states by looking at plots and residuals

```{r}
#model 3
fit3$states
tsSmooth(fit3)
autoplot(fit3, plot.type="fitted.ytT")
autoplot(fit3, plot.type="residuals")


```

# Test different regions as sub-groups: 

We also examined the potential for region to behave as sub-populations based on major population group, our initial correlation analysis, and some geographic assumptions about physical proximity and climate. 

Comparing 3 sub-populations: cascade, coast, and gorge based on their designated MPG
```{r}
mod.list6 <- list(#B = matrix(1), # B = "identity" 3x3 matrix
                  # U = matrix("u"), #needs 3 rows U = "equal" or "unequal" # default = unequal
                   Q = "unconstrained", # 1 X
                   Z = factor(c("cascade", "cascade", 
                                "coast", "coast", 
                                "gorge", "gorge")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   #x0 = matrix("mu"), # x0 = default 
                   tinitx = 0)


fit6 <- MARSS(sub_dat, model = mod.list6)
autoplot(fit6, plot.type="fitted.ytT")
```
 
Based on the correlation plot, the grays and chinook rivers and the lower gorge tributaries are highly correlated. We want to evaluate a model with these regions as a sub-population. 

Comparing 2 sub-populations: grays/chinook rivers and lower gorge "GCL" and all other test regions "STCU"
```{r}
mod.list7 <- list(Q = "unconstrained", # 1 X
                  Z = factor(c("STCU", "STCU", 
                                "STCU", "GCL", 
                                "GCL", "STCU")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   tinitx = 0)


fit7 <- MARSS(sub_dat, model = mod.list7)
autoplot(fit7, plot.type="fitted.ytT")
```

While the description "cascades" only describes a couple regions in our test set, we decided to test a model separating the general cascades from the 2 coast regions (Clatskaine and Gray/Chinook) because geographically there is a large separation. 

Comparing 2 sub-populations: coast "coast" and all other test regions "casgor"

```{r}
mod.list8 <- list(Q = "unconstrained", # 1 X
                  Z = factor(c("casgor", "casgor", 
                                "coast", "coast", 
                                "casgor", "casgor")), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   tinitx = 0)


fit8 <- MARSS(sub_dat, model = mod.list8)
autoplot(fit8, plot.type="fitted.ytT")
```

## compare the new models using AICc

```{r}
aic <- c(fit3$AICc, fit6$AICc, fit7$AICc, fit8$AICc )
aic-min(aic) #delta AICc 
```

Our new analysis of grouped populations indicates that some of the regions do behave as sub populations. The new best model builds off of the predictions from the correlation analysis, with the Grays/Chinook Rivers and the Lower Gorge Tributaries behaving as 1 sub-population. Additionally, the model treating major populaton groups as sub-populations performed better than our original model providing some possible evidence that grouping by MPG can improve the model fit to the data. However, the AICc value was only 1.56 better than our model without the grouping by MPG so it is not significantly better. 


### Including cycling - using our coho data, full time series

Because we know that coho abundance can be influenced by broad patterns in climate and ocean conditions we tested for underlying seasonality by looking for cycling in the data set and evaluated whether this might generate a better fitting model.To accomplish this, we incorporated seasonality as a covariate in a new model below. We tested 5 and 10 year cycles after looking back at our data, specifically of the Sandy River which has good the fewest missing values of the time series data. 


# Plot the ACF and look for evidence of cycling
```{r}
par(mfrow=c(2,2))
for(i in 1:4){
  acf(sub_dat[i,], na.action=na.pass, main=rownames(sub_dat)[i])
}
```

Based on the acf plots and the pattern in the Tilton with significant autocorrelation at 5 years with a possible cyclic pattern, we decided to test for cycling with frequency 5 or 10 years. 

```{r}
TT <- dim(sub_dat)[2] #number of time steps
covariates <- rbind(
  forecast::fourier(ts(1:TT, freq=5), K=1) |> t(),
  forecast::fourier(ts(1:TT, freq=10), K=1) |> t()
)
str(TT)
```

## note renaming model
Now let's fit a model with these covariates. Let's analyze the populations separately, so Q is diagonal.
```{r}
mod.list9 <- list(
  Q = "unconstrained", # different varcov
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates
)

mod.list10 <- list(
  Q = "equalvarcov",
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates
)
```


```{r}
fit9 <- MARSS(sub_dat, model=mod.list9)
fit10 <- MARSS(sub_dat, model=mod.list10)


plot.mod9 <- autoplot(fit9, plot.type="fitted.ytT")
plot.mod10 <- autoplot(fit10, plot.type="fitted.ytT")

```


Here we look at Model 9. 
```{r}
library(broom)
df <- tidy(fit9) %>% #confidence estimates
  subset(stringr::str_sub(term,1,1)=="D") #only D parameters
df$lag <- as.factor(rep(c(5,10), each=12)) #label lags
df$river <- as.factor(rep(rownames(sub_dat),4)) #rownames on repeat
df$sc <- rep(rep(c("S", "C"), each=6), 2) #each sin cos 6 times, 2 test freq
df$type <- paste0(df$sc,df$lag)
```

# Plot the CI's and look for evidence of cycling
```{r}
ggplot(df, aes(x=type, y=estimate, col=lag)) + 
  geom_point() +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.up), width=.2, position=position_dodge(.9)) +
  geom_hline(yintercept = 0) +
  facet_wrap(~river) +
  ggtitle("The cycle estimates for Model 9")
```

The cosine estimates, particularly for the Upper Gorge Tributaries and Hood River, indicate the potentia for a seasonal cycle that peaks every 10 years. We encountered a Hessian error in our code that prevented us from plotting confidence intervals for this data, but decided not to address further after consulting with Eli. 

Here we're looking at Model 10. 
```{r}
df <- tidy(fit10) %>% #confidence estimates
  subset(stringr::str_sub(term,1,1)=="D") #only D parameters
df$lag <- as.factor(rep(c(5,10), each=12)) #label lags
df$river <- as.factor(rep(rownames(sub_dat),4)) #rownames on repeat
df$sc <- rep(rep(c("S", "C"), each=6), 2) #each sin cos 6 times, 2 test freq
df$type <- paste0(df$sc,df$lag)
```

```{r}
ggplot(df, aes(x=type, y=estimate, col=lag)) + 
  geom_point() +
  geom_errorbar(aes(ymin=conf.low, ymax=conf.up), width=.2, position=position_dodge(.9)) +
  geom_hline(yintercept = 0) +
  facet_wrap(~river) +
  ggtitle("The cycle estimates for Model 10")
```

The same analysis but with an equal variance covariance matrix estimated for Q still highlights the potential for a 10 year cycle, this time with the Tilton River. 

------------------------------------------------------------------------
Evaluate AICc for seasonality against our current best model 3. 

```{r}
aic <- c(fit3$AICc, fit9$AICc, fit10$AICc )
aic-min(aic) #delta AICc 
```

The equal variance covariance matrix for Q was better, but still not as good as our current best model. Now we'll try building a model with just the 10 year cycle as that best explains the potential seasonality in the data, using the same code from above. 

```{r}
TT <- dim(sub_dat)[2] #number of time steps
covariates_10 <- rbind(
  forecast::fourier(ts(1:TT, freq=10), K=1) |> t()
)
str(TT)

mod.list11 <- list(
  Q = "equalvarcov",
  U = "unequal",
  R = "diagonal and equal",
  D = "unconstrained",
  d = covariates_10
)

fit11 <- MARSS(sub_dat, model=mod.list11, control = list(maxit=1000) )
```

```{r}
aic <- c(fit3$AICc, fit11$AICc )
aic-min(aic) #delta AICc 
```

Narrowing down to just a 10 year cycle improved the model, but the seasonality still doesn't help the model as a covariate. 

Ultimately, the best model for predicting historical data for Coho salmon is Model 3 which treats all populations idependently. 

# Fit the best model

Here we predict historical data for all regions using our best model from the initial analysis. One caveat to this approach is that our correlation analysis was performed on a test set, with model 7 specifying Z based on this data. This yields the best model, but is more difficult to fit to historical data based on the information available to us now. 

Future directions should include evaluating the correlation between all the regions to evaluate if other regions would fit into the same sub-group as the grays/chinook and lower gorge. Because there isn't an obvious indicator variable that separates these regions from other regions in our test set, more analysis is needed to identify what is driving this separation of states. 

## Miranda's attempt at fitting our best model...but probably shouldn't include because it isn't complete and doesn't really make biological sense to continue without further work detailed above. 
```{r}

mod.list.full <- list(B = matrix(1), 
                   U = matrix("u"), 
                   Q = matrix("q"), # 1 X
                   Z = matrix(1, 23, 1), 
                   A = "scaling", 
                   R = "diagonal and unequal", # single column of 1s for Y
                   x0 = matrix("mu"), 
                   tinitx = 0)

fit_full <- MARSS(dat, model = mod.list.full, control = list(maxit=5000))

autoplot(fit_full, plot.type="fitted.ytT")
```


#States

Your abundance estimate is the "x" or "state" estimates. You can get this from
```{r}
fit$states
```
or 
```
tsSmooth(fit)
```
where `fit` is from `fit <- MARSS()`

Estimate of the mean of the spawner counts based on your x model.
```
autoplot(fit, plot.type="fitted.ytT")
```

# Results


### General Questions

Each group has the same general tasks, but you will adapt them as you work on the data.

1. Create estimates of spawner abundance for all missing years and provide estimates of the decline from the historical abundance.

2. Evaluate support for the major population groups. Are the populations in the groups more correlated than outside the groups?

# Discussion

 Assume that "historical" means the earliest years available for your group.
----------------------------------------------------------------


## Contributions - add your contributions! 

We tackled this lab by having multiple group meetings to brainstorm strategies, test code, and plan progress. Miranda adapted code from the Lab2-MARSS document to the Coho data, acted as scribe for testing code during group meetings, contributed ideas for selecting models to test, and annotated many of the models for report generation. 
